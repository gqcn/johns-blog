#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Markdown å›¾ç‰‡å¼•ç”¨è½¬æ¢è„šæœ¬
åœ¨æ„å»ºå‰å°†æ™®é€š Markdown å›¾ç‰‡è¯­æ³•è½¬æ¢ä¸º ideal-image ç»„ä»¶

åŠŸèƒ½ï¼š
1. æ‰«ææ‰€æœ‰ Markdown æ–‡ä»¶ï¼Œè½¬æ¢ä¸º MDX æ ¼å¼
2. æŸ¥æ‰¾ ![alt](image.png) æ ¼å¼çš„å›¾ç‰‡å¼•ç”¨
3. è½¬æ¢ä¸º <Image img={require('image.png')} alt="alt" /> æ ¼å¼
4. è‡ªåŠ¨æ·»åŠ  Image ç»„ä»¶å¯¼å…¥è¯­å¥
5. åˆ©ç”¨ Docusaurus ideal-image æ’ä»¶è‡ªåŠ¨ç”Ÿæˆå“åº”å¼å›¾ç‰‡

ä½¿ç”¨æ–¹æ³•ï¼š
  python3 convert_images_for_build.py          # è½¬æ¢æ‰€æœ‰ç›®å½•
  python3 convert_images_for_build.py blog     # åªè½¬æ¢ blog ç›®å½•
  python3 convert_images_for_build.py --revert # æ¢å¤åŸå§‹æ–‡ä»¶
"""

import os
import re
import sys
import shutil
from pathlib import Path
from datetime import datetime
from urllib.parse import unquote

# åˆ‡æ¢åˆ°é¡¹ç›®æ ¹ç›®å½•ï¼ˆè„šæœ¬æ‰€åœ¨ç›®å½•çš„çˆ¶ç›®å½•ï¼‰
SCRIPT_DIR = Path(__file__).resolve().parent
PROJECT_ROOT = SCRIPT_DIR.parent
os.chdir(PROJECT_ROOT)

# å¤‡ä»½ç›®å½•
BACKUP_DIR = ".build-backup"
# Image ç»„ä»¶å¯¼å…¥è¯­å¥
IMAGE_IMPORT = "import Image from '@theme/IdealImage';\n\n"

def convert_image_syntax(md_content, md_file_path):
    """
    è½¬æ¢ Markdown ä¸­çš„å›¾ç‰‡è¯­æ³•ä¸º ideal-image ç»„ä»¶
    
    ![alt](image.png) -> <Image img={require('./image.png')} alt="alt" />
    
    ç‰¹æ®Šå¤„ç†ï¼š
    - ./attachments/ æˆ– /attachments/ è·¯å¾„ -> æ˜ å°„åˆ° /static/attachments/
    """
    conversions = 0
    has_images = False
    
    # åŒ¹é… Markdown å›¾ç‰‡è¯­æ³•: ![alt](path) æˆ– ![alt](<path>)
    # æ”¯æŒå¸¦è§’æ‹¬å·çš„è·¯å¾„ï¼ˆMarkdown å¤„ç†ç©ºæ ¼è·¯å¾„çš„æ ‡å‡†è¯­æ³•ï¼‰
    # ä½¿ç”¨ .+? éè´ªå©ªåŒ¹é…ç›´åˆ°æ‰¾åˆ°å›¾ç‰‡æ‰©å±•åï¼Œæ”¯æŒè·¯å¾„ä¸­çš„æ‹¬å·ã€&ç­‰ç‰¹æ®Šå­—ç¬¦
    pattern = r'!\[([^\]]*)\]\(<?(.*?\.(?:png|jpg|jpeg|webp|gif))>?\)'
    
    def replace_image(match):
        nonlocal conversions, has_images
        alt_text = match.group(1)
        image_path = match.group(2).strip()
        
        has_images = True
        conversions += 1
        
        # URL è§£ç è·¯å¾„ï¼ˆå¤„ç† %20 ç­‰ç¼–ç å­—ç¬¦ï¼‰
        image_path = unquote(image_path)
        
        # ç‰¹æ®Šå¤„ç† attachments è·¯å¾„
        if 'attachments/' in image_path:
            # ç§»é™¤è·¯å¾„å‰çš„ ./ æˆ– /
            clean_path = image_path.lstrip('./')
            # ä½¿ç”¨ @site åˆ«åå¼•ç”¨ static ç›®å½•
            return f"<Image img={{require('@site/static/{clean_path}')}} alt=\"{alt_text}\" />"
        
        # æ™®é€šç›¸å¯¹è·¯å¾„å¤„ç†
        # ç§»é™¤å¼€å¤´çš„ /ï¼ˆé¿å… .// åŒæ–œæ ï¼‰
        image_path = image_path.lstrip('/')
        
        # è½¬æ¢ä¸º ideal-image ç»„ä»¶è¯­æ³•
        # å¤„ç†è·¯å¾„ä¸­çš„ç‰¹æ®Šå­—ç¬¦
        escaped_path = image_path.replace("'", "\\'")
        
        # æ·»åŠ  ./ å‰ç¼€ï¼ˆrequire éœ€è¦ç›¸å¯¹è·¯å¾„ï¼‰
        if not escaped_path.startswith('./'):
            escaped_path = './' + escaped_path
        
        return f"<Image img={{require('{escaped_path}')}} alt=\"{alt_text}\" />"
    
    new_content = re.sub(pattern, replace_image, md_content)
    
    # å¦‚æœæœ‰å›¾ç‰‡è½¬æ¢ï¼Œéœ€è¦æ·»åŠ  import è¯­å¥
    if has_images and conversions > 0:
        # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰ import è¯­å¥
        if IMAGE_IMPORT.strip() not in new_content:
            # åœ¨æ–‡ä»¶å¼€å¤´æ·»åŠ  importï¼ˆåœ¨ frontmatter ä¹‹åï¼‰
            # æ£€æŸ¥æ˜¯å¦æœ‰ frontmatter
            if new_content.startswith('---'):
                # æ‰¾åˆ°ç¬¬äºŒä¸ª ---
                parts = new_content.split('---', 2)
                if len(parts) >= 3:
                    new_content = f"---{parts[1]}---\n{IMAGE_IMPORT}{parts[2]}"
                else:
                    new_content = IMAGE_IMPORT + new_content
            else:
                new_content = IMAGE_IMPORT + new_content
    
    return new_content, conversions

def backup_file(file_path, backup_dir):
    """å¤‡ä»½æ–‡ä»¶"""
    # å°†æ–‡ä»¶è·¯å¾„è½¬ä¸ºç»å¯¹è·¯å¾„ï¼Œå¹¶å°è¯•è·å–ç›¸å¯¹äºå½“å‰å·¥ä½œç›®å½•çš„è·¯å¾„
    abs_file_path = Path(file_path).resolve()
    cwd = Path.cwd()
    
    try:
        rel_path = abs_file_path.relative_to(cwd)
    except ValueError:
        # å¦‚æœæ–‡ä»¶ä¸åœ¨å½“å‰å·¥ä½œç›®å½•ä¸‹ï¼Œä½¿ç”¨æ–‡ä»¶å
        rel_path = abs_file_path.name
    
    backup_path = Path(backup_dir) / rel_path
    backup_path.parent.mkdir(parents=True, exist_ok=True)
    shutil.copy2(file_path, backup_path)

def safe_relative_path(file_path, base_path):
    """å®‰å…¨åœ°è·å–ç›¸å¯¹è·¯å¾„ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å›æ–‡ä»¶å"""
    try:
        return Path(file_path).relative_to(base_path)
    except ValueError:
        return Path(file_path).name

def convert_referencing_files(target_dirs, renamed_files, backup_root, iteration=1):
    """
    è½¬æ¢é‚£äº›å¼•ç”¨äº†è¢«é‡å‘½åæ–‡ä»¶çš„ .md æ–‡ä»¶
    è¿™äº›æ–‡ä»¶æœ¬èº«å¯èƒ½æ²¡æœ‰å›¾ç‰‡ï¼Œä½†å› ä¸ºå¼•ç”¨äº†è¢«è½¬æ¢çš„æ–‡ä»¶ï¼Œé“¾æ¥ä¼šå¤±æ•ˆ
    æ‰€ä»¥ä¹Ÿéœ€è¦å°†å®ƒä»¬è½¬æ¢ä¸º .mdx å¹¶æ›´æ–°é“¾æ¥
    è¿”å›ï¼šæ–°è½¬æ¢çš„æ–‡ä»¶åˆ—è¡¨ [(old_path, new_path), ...]
    """
    if not renamed_files:
        return []
    
    if iteration == 1:
        print("\nğŸ”— å¤„ç†å¼•ç”¨äº†è¢«è½¬æ¢æ–‡ä»¶çš„å…¶ä»–æ–‡æ¡£...")
        print("=" * 80)
    else:
        print(f"\nğŸ”— ç¬¬ {iteration} è½®ï¼šå¤„ç†æ–°çš„å¼•ç”¨å…³ç³»...")
        print("=" * 80)
    
    # åˆ›å»ºè¢«é‡å‘½åæ–‡ä»¶çš„æ˜ å°„ï¼šæ–‡ä»¶å -> æ–°æ–‡ä»¶å
    rename_map = {}
    for old_path, new_path in renamed_files:
        old_name = old_path.name
        new_name = new_path.name
        rename_map[old_name] = new_name
    
    converted_count = 0
    link_pattern = r'\[([^\]]+)\]\(([^)]+\.md)\)'
    newly_renamed = []  # æ–°è½¬æ¢çš„æ–‡ä»¶åˆ—è¡¨
    
    # æ‰«ææ‰€æœ‰å‰©ä½™çš„ .md æ–‡ä»¶å’Œå·²å­˜åœ¨çš„ .mdx æ–‡ä»¶
    for target_dir in target_dirs:
        if not target_dir.exists():
            continue
        
        # å¤„ç† .md æ–‡ä»¶
        for file_path in target_dir.rglob('*.md'):
            # è·³è¿‡å¤‡ä»½ç›®å½•
            if BACKUP_DIR in file_path.parts or '.backup' in file_path.parts:
                continue
            if 'hidden' in file_path.parts:
                continue
            
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # æ£€æŸ¥æ˜¯å¦å¼•ç”¨äº†è¢«é‡å‘½åçš„æ–‡ä»¶
                has_reference = False
                for match in re.finditer(link_pattern, content):
                    link_path = match.group(2)
                    from urllib.parse import unquote
                    decoded_path = unquote(link_path)
                    file_name = Path(decoded_path).name
                    
                    if file_name in rename_map:
                        has_reference = True
                        break
                
                # å¦‚æœå¼•ç”¨äº†è¢«è½¬æ¢çš„æ–‡ä»¶ï¼Œå°†æ­¤æ–‡ä»¶ä¹Ÿè½¬æ¢ä¸º .mdx
                if has_reference:
                    # å¤‡ä»½åŸå§‹æ–‡ä»¶
                    backup_file(file_path, backup_root)
                    
                    # é‡å‘½åä¸º .mdx
                    mdx_file = file_path.with_suffix('.mdx')
                    
                    # æ›´æ–°é“¾æ¥
                    def replace_link(match):
                        link_text = match.group(1)
                        link_path = match.group(2)
                        from urllib.parse import unquote
                        decoded_path = unquote(link_path)
                        file_name = Path(decoded_path).name
                        
                        if file_name in rename_map:
                            new_path = link_path.replace('.md', '.mdx')
                            return f'[{link_text}]({new_path})'
                        return match.group(0)
                    
                    updated_content = re.sub(link_pattern, replace_link, content)
                    
                    # å†™å…¥æ–°æ–‡ä»¶
                    with open(mdx_file, 'w', encoding='utf-8') as f:
                        f.write(updated_content)
                    
                    # åˆ é™¤åŸ .md æ–‡ä»¶
                    file_path.unlink()
                    
                    newly_renamed.append((file_path, mdx_file))  # è®°å½•æ–°è½¬æ¢çš„æ–‡ä»¶
                    converted_count += 1
                    # print(f"  âœ… {safe_relative_path(file_path, target_dir)} â†’ {mdx_file.name}: å·²æ›´æ–°é“¾æ¥")
            
            except Exception as e:
                print(f"  âŒ å¤„ç†å¤±è´¥ {file_path.name}: {e}")
    
    if converted_count > 0:
        print(f"\nğŸ“Š é¢å¤–è½¬æ¢: {converted_count} ä¸ªæ–‡ä»¶å› å¼•ç”¨å…³ç³»è¢«è½¬æ¢")
        print("=" * 80)
    
    return newly_renamed

def update_markdown_links(target_dirs, renamed_files):
    """
    æ›´æ–°å…¶ä»–æ–‡æ¡£ä¸­æŒ‡å‘å·²é‡å‘½åæ–‡ä»¶çš„é“¾æ¥
    å°† .md é“¾æ¥æ›´æ–°ä¸º .mdx é“¾æ¥
    """
    if not renamed_files:
        return
    
    print("\nğŸ”— æ›´æ–°æ–‡æ¡£é“¾æ¥...")
    print("=" * 80)
    
    # åˆ›å»ºé‡å‘½åæ˜ å°„å­—å…¸ï¼šç›¸å¯¹è·¯å¾„ -> æ–°æ‰©å±•å
    rename_map = {}
    for old_path, new_path in renamed_files:
        # ä½¿ç”¨æ–‡ä»¶åä½œä¸ºé”®ï¼ˆå› ä¸ºé“¾æ¥é€šå¸¸æ˜¯ç›¸å¯¹è·¯å¾„ï¼‰
        old_name = old_path.name
        new_name = new_path.name
        rename_map[old_name] = new_name
    
    updated_files = 0
    updated_links = 0
    
    # åªæ‰«æ MDX æ–‡ä»¶ï¼ˆå·²è½¬æ¢çš„æ–‡ä»¶ï¼‰ï¼Œä¸ä¿®æ”¹æº .md æ–‡ä»¶
    for target_dir in target_dirs:
        if not target_dir.exists():
            continue
        
        for file_path in target_dir.rglob('*.mdx'):
            # è·³è¿‡å¤‡ä»½ç›®å½•
            if BACKUP_DIR in file_path.parts or '.backup' in file_path.parts:
                continue
            if 'hidden' in file_path.parts:
                continue
            
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                original_content = content
                file_updated = False
                
                # æŸ¥æ‰¾æ‰€æœ‰ Markdown é“¾æ¥ï¼š[text](path)
                # åŒ¹é… .md æ–‡ä»¶é“¾æ¥
                link_pattern = r'\[([^\]]+)\]\(([^)]+\.md)\)'
                
                def replace_link(match):
                    nonlocal file_updated, updated_links
                    link_text = match.group(1)
                    link_path = match.group(2)
                    
                    # æå–æ–‡ä»¶å
                    from urllib.parse import unquote
                    decoded_path = unquote(link_path)
                    file_name = Path(decoded_path).name
                    
                    # æ£€æŸ¥æ˜¯å¦åœ¨é‡å‘½åæ˜ å°„ä¸­
                    if file_name in rename_map:
                        # æ›¿æ¢æ‰©å±•å
                        new_path = link_path.replace('.md', '.mdx')
                        file_updated = True
                        updated_links += 1
                        return f'[{link_text}]({new_path})'
                    
                    return match.group(0)
                
                # æ‰§è¡Œæ›¿æ¢
                content = re.sub(link_pattern, replace_link, content)
                
                # å¦‚æœæœ‰æ›´æ–°ï¼Œå†™å›æ–‡ä»¶
                if file_updated:
                    with open(file_path, 'w', encoding='utf-8') as f:
                        f.write(content)
                    updated_files += 1
                    # print(f"  âœ… {safe_relative_path(file_path, target_dir)}: æ›´æ–°äº† {content.count('.mdx') - original_content.count('.mdx')} ä¸ªé“¾æ¥")
            
            except Exception as e:
                print(f"  âŒ æ›´æ–°å¤±è´¥ {file_path.name}: {e}")
    
    print(f"\nğŸ“Š é“¾æ¥æ›´æ–°æ±‡æ€»:")
    print(f"  å·²æ›´æ–°æ–‡ä»¶: {updated_files}")
    print(f"  å·²æ›´æ–°é“¾æ¥: {updated_links}")
    print("=" * 80)

def convert_markdown_files(target_dirs, backup_root):
    """è½¬æ¢æŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰ Markdown æ–‡ä»¶ä¸º MDX æ ¼å¼"""
    total_files = 0
    converted_files = 0
    total_images = 0
    renamed_files = []
    
    print("ğŸ”„ å¼€å§‹è½¬æ¢ Markdown å›¾ç‰‡å¼•ç”¨ä¸º ideal-image ç»„ä»¶...")
    print(f"ğŸ“¦ å¤‡ä»½ç›®å½•: {backup_root}")
    print("=" * 80)
    
    for target_dir in target_dirs:
        if not target_dir.exists():
            print(f"âš ï¸  è·³è¿‡ï¼šç›®å½•ä¸å­˜åœ¨ - {target_dir}")
            continue
        
        print(f"\nğŸ“ å¤„ç†ç›®å½•: {target_dir}")
        
        # éå†æ‰€æœ‰ Markdown æ–‡ä»¶ï¼ˆåŒ…æ‹¬ .md å’Œ .mdxï¼‰
        for md_file in list(target_dir.rglob('*.md')) + list(target_dir.rglob('*.mdx')):
            # è·³è¿‡å¤‡ä»½ç›®å½•
            if BACKUP_DIR in md_file.parts or '.backup' in md_file.parts:
                continue
            
            # è·³è¿‡ hidden ç›®å½•ï¼ˆä¸ docusaurus.config.ts çš„ ignorePatterns ä¸€è‡´ï¼‰
            if 'hidden' in md_file.parts:
                continue
            
            total_files += 1
            
            try:
                # è¯»å–æ–‡ä»¶
                with open(md_file, 'r', encoding='utf-8') as f:
                    original_content = f.read()
                
                # è½¬æ¢å›¾ç‰‡è¯­æ³•
                new_content, conversions = convert_image_syntax(original_content, md_file)
                
                if conversions > 0:
                    # å¤‡ä»½åŸå§‹æ–‡ä»¶
                    backup_file(md_file, backup_root)
                    
                    # å¦‚æœæ˜¯ .md æ–‡ä»¶ï¼Œé‡å‘½åä¸º .mdx
                    if md_file.suffix == '.md':
                        mdx_file = md_file.with_suffix('.mdx')
                        renamed_files.append((md_file, mdx_file))
                        
                        # å†™å…¥æ–°å†…å®¹åˆ° .mdx æ–‡ä»¶
                        with open(mdx_file, 'w', encoding='utf-8') as f:
                            f.write(new_content)
                        
                        # åˆ é™¤åŸ .md æ–‡ä»¶
                        md_file.unlink()
                        
                        converted_files += 1
                        total_images += conversions
                        # print(f"  âœ… {safe_relative_path(md_file, target_dir)} â†’ {mdx_file.name}: {conversions} å¼ å›¾ç‰‡å·²è½¬æ¢")
                    else:
                        # å·²ç»æ˜¯ .mdx æ–‡ä»¶ï¼Œç›´æ¥è¦†ç›–
                        with open(md_file, 'w', encoding='utf-8') as f:
                            f.write(new_content)
                        
                        converted_files += 1
                        total_images += conversions
                        # print(f"  âœ… {safe_relative_path(md_file, target_dir)}: {conversions} å¼ å›¾ç‰‡å·²è½¬æ¢")
            
            except Exception as e:
                print(f"  âŒ å¤„ç†å¤±è´¥ {md_file.name}: {e}")
    
    print("\n" + "=" * 80)
    print("ğŸ“Š è½¬æ¢æ±‡æ€»:")
    print(f"  æ‰«ææ–‡ä»¶æ•°: {total_files}")
    print(f"  å·²è½¬æ¢æ–‡ä»¶: {converted_files}")
    print(f"  å·²è½¬æ¢å›¾ç‰‡: {total_images}")
    print(f"  .md â†’ .mdx: {len(renamed_files)}")
    print(f"  æœªè½¬æ¢æ–‡ä»¶: {total_files - converted_files}")
    print("=" * 80)
    
    # å¤„ç†å¼•ç”¨äº†è¢«è½¬æ¢æ–‡ä»¶çš„å…¶ä»– .md æ–‡ä»¶
    # éœ€è¦è¿­ä»£å¤„ç†ï¼Œå› ä¸ºå¯èƒ½å­˜åœ¨é“¾å¼å¼•ç”¨å…³ç³»
    if renamed_files:
        all_newly_renamed = []
        iteration = 1
        while True:
            newly_renamed = convert_referencing_files(target_dirs, renamed_files, backup_root, iteration)
            if not newly_renamed:
                break  # æ²¡æœ‰æ–°çš„æ–‡ä»¶è¢«è½¬æ¢ï¼Œåœæ­¢è¿­ä»£
            
            all_newly_renamed.extend(newly_renamed)
            renamed_files.extend(newly_renamed)  # å°†æ–°è½¬æ¢çš„æ–‡ä»¶åŠ å…¥åˆ—è¡¨ï¼Œä¾›ä¸‹ä¸€è½®ä½¿ç”¨
            iteration += 1
        
        converted_files += len(all_newly_renamed)
        
        # æ›´æ–°æ‰€æœ‰ .mdx æ–‡ä»¶ä¸­çš„é“¾æ¥
        update_markdown_links(target_dirs, renamed_files)
    
    return converted_files > 0

def revert_files(backup_root):
    """ä»å¤‡ä»½æ¢å¤åŸå§‹æ–‡ä»¶"""
    if not backup_root.exists():
        print("âš ï¸  æ²¡æœ‰æ‰¾åˆ°å¤‡ä»½ç›®å½•ï¼Œæ— éœ€æ¢å¤")
        return
    
    print("ğŸ”„ å¼€å§‹æ¢å¤åŸå§‹æ–‡ä»¶...")
    print(f"ğŸ“¦ å¤‡ä»½ç›®å½•: {backup_root}")
    print("=" * 80)
    
    restored_count = 0
    mdx_deleted_count = 0
    
    # é¦–å…ˆåˆ é™¤æ‰€æœ‰ .mdx æ–‡ä»¶ï¼ˆè¿™äº›æ˜¯è½¬æ¢ç”Ÿæˆçš„ï¼‰
    for target_dir in [Path.cwd() / 'blog', Path.cwd() / 'docs']:
        if target_dir.exists():
            for mdx_file in target_dir.rglob('*.mdx'):
                if BACKUP_DIR not in mdx_file.parts and '.backup' not in mdx_file.parts:
                    # æ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”çš„å¤‡ä»½ .md æ–‡ä»¶
                    md_file = mdx_file.with_suffix('.md')
                    backup_md = backup_root / md_file.relative_to(Path.cwd())
                    
                    if backup_md.exists():
                        try:
                            mdx_file.unlink()
                            mdx_deleted_count += 1
                            print(f"  ğŸ—‘ï¸  å·²åˆ é™¤è½¬æ¢æ–‡ä»¶: {safe_relative_path(mdx_file, Path.cwd())}")
                        except Exception as e:
                            print(f"  âŒ åˆ é™¤å¤±è´¥ {mdx_file.name}: {e}")
    
    # éå†å¤‡ä»½ç›®å½•ï¼Œæ¢å¤æ‰€æœ‰æ–‡ä»¶
    for backup_file_path in backup_root.rglob('*'):
        if backup_file_path.is_file():
            # è®¡ç®—åŸå§‹æ–‡ä»¶è·¯å¾„
            relative_path = backup_file_path.relative_to(backup_root)
            original_file = Path.cwd() / relative_path
            
            try:
                # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
                original_file.parent.mkdir(parents=True, exist_ok=True)
                
                # æ¢å¤æ–‡ä»¶
                shutil.copy2(backup_file_path, original_file)
                restored_count += 1
                # print(f"  âœ… å·²æ¢å¤: {relative_path}")
            except Exception as e:
                print(f"  âŒ æ¢å¤å¤±è´¥ {relative_path}: {e}")
    
    # åˆ é™¤å¤‡ä»½ç›®å½•
    try:
        shutil.rmtree(backup_root)
        print(f"\nâœ… å·²åˆ é™¤å¤‡ä»½ç›®å½•: {backup_root}")
    except Exception as e:
        print(f"\nâš ï¸  åˆ é™¤å¤‡ä»½ç›®å½•å¤±è´¥: {e}")
    
    print("\n" + "=" * 80)
    print(f"ğŸ“Š æ¢å¤æ±‡æ€»:")
    print(f"  å·²æ¢å¤ .md æ–‡ä»¶: {restored_count}")
    print(f"  å·²åˆ é™¤ .mdx æ–‡ä»¶: {mdx_deleted_count}")
    print("=" * 80)

def main():
    """ä¸»å‡½æ•°"""
    # ä½¿ç”¨é¡¹ç›®æ ¹ç›®å½•è€Œéè„šæœ¬ç›®å½•
    backup_root = Path(BACKUP_DIR)
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯æ¢å¤æ¨¡å¼
    if '--revert' in sys.argv or '-r' in sys.argv:
        revert_files(backup_root)
        return
    
    # ç¡®å®šè¦å¤„ç†çš„ç›®å½•
    if len(sys.argv) > 1 and not sys.argv[1].startswith('--'):
        target_dirs = [Path(arg) for arg in sys.argv[1:] if not arg.startswith('--')]
    else:
        target_dirs = [
            Path('blog'),
            Path('docs'),
        ]
    
    print("ğŸ–¼ï¸  Markdown å›¾ç‰‡å¼•ç”¨è½¬æ¢å·¥å…·ï¼ˆideal-image æ¨¡å¼ï¼‰")
    print(f"â° å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ“‚ å¾…å¤„ç†ç›®å½•æ•°: {len(target_dirs)}")
    
    # è½¬æ¢æ–‡ä»¶
    has_changes = convert_markdown_files(target_dirs, backup_root)
    
    if has_changes:
        print("\nğŸ’¡ æç¤º:")
        print("  - åŸå§‹ .md æ–‡ä»¶å·²å¤‡ä»½åˆ°:", backup_root)
        print("  - å·²å°†åŒ…å«å›¾ç‰‡çš„æ–‡ä»¶è½¬æ¢ä¸º .mdx æ ¼å¼")
        print("  - ideal-image æ’ä»¶ä¼šè‡ªåŠ¨ç”Ÿæˆå“åº”å¼å›¾ç‰‡")
        print("  - æ„å»ºå®Œæˆåè¿è¡Œä»¥ä¸‹å‘½ä»¤æ¢å¤åŸå§‹æ–‡ä»¶:")
        print(f"    python3 {Path(__file__).name} --revert")
        print("\nğŸ“ é…ç½®è¯´æ˜:")
        print("  - å¯åœ¨ docusaurus.config.ts ä¸­è°ƒæ•´ ideal-image æ’ä»¶é…ç½®")
        print("  - quality: å›¾ç‰‡è´¨é‡ (1-100)")
        print("  - max: PCç«¯æœ€å¤§å®½åº¦")
        print("  - min: ç§»åŠ¨ç«¯æœ€å°å®½åº¦")
        print("  - steps: ç”Ÿæˆçš„å°ºå¯¸ç‰ˆæœ¬æ•°é‡")
    else:
        print("\nğŸ’¡ æ²¡æœ‰æ‰¾åˆ°éœ€è¦è½¬æ¢çš„å›¾ç‰‡")
    
    print(f"\nâ° å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

if __name__ == '__main__':
    main()
