<!doctype html><html lang=en dir=ltr class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-docs/AI技术/训练微调/AI模型训练技术详解" data-has-hydrated=false><meta charset=UTF-8><meta name=generator content="Docusaurus v3.6.3"><title data-rh=true>AI模型训练技术详解 | John's Blog</title><meta data-rh=true name=viewport content="width=device-width,initial-scale=1.0"><meta data-rh=true name=twitter:card content=summary_large_image><meta data-rh=true property=og:url content=https://johng.cn/ai/training><meta data-rh=true property=og:locale content=en><meta data-rh=true name=docusaurus_locale content=en><meta data-rh=true name=docsearch:language content=en><meta data-rh=true name=author content="John Guo"><meta data-rh=true property=og:image content=https://johng.cn/img/favicon.png><meta data-rh=true name=docusaurus_version content=current><meta data-rh=true name=docusaurus_tag content=docs-default-current><meta data-rh=true name=docsearch:version content=current><meta data-rh=true name=docsearch:docusaurus_tag content=docs-default-current><meta data-rh=true property=og:title content="AI模型训练技术详解 | John's Blog"><meta data-rh=true name=description content=深入讲解AI模型训练的核心技术与实践方法。通过猜数字游戏等通俗易懂的例子，阐述模型训练的基本概念和核心流程，包括数据准备、前向传播、损失计算、反向传播、参数更新等关键步骤。详细介绍预训练和增量预训练两种主流训练方法的原理、流程、成本对比及应用场景，涵盖著名模型案例、技术要点和实际应用。帮助读者掌握AI模型训练的完整知识体系，为实际项目开发提供指导和参考。><meta data-rh=true property=og:description content=深入讲解AI模型训练的核心技术与实践方法。通过猜数字游戏等通俗易懂的例子，阐述模型训练的基本概念和核心流程，包括数据准备、前向传播、损失计算、反向传播、参数更新等关键步骤。详细介绍预训练和增量预训练两种主流训练方法的原理、流程、成本对比及应用场景，涵盖著名模型案例、技术要点和实际应用。帮助读者掌握AI模型训练的完整知识体系，为实际项目开发提供指导和参考。><meta data-rh=true name=keywords content=AI训练,模型训练,预训练,增量预训练,参数优化,训练流程,梯度下降,反向传播,大模型训练,基座模型,训练成本,GPU训练,分布式训练,训练数据,损失函数,学习率,批次训练,轮次迭代,模型收敛,训练方法><link data-rh=true rel=icon href=/img/favicon.ico><link data-rh=true rel=canonical href=https://johng.cn/ai/training><link data-rh=true rel=alternate href=https://johng.cn/ai/training hreflang=en><link data-rh=true rel=alternate href=https://johng.cn/ai/training hreflang=x-default><link data-rh=true rel=preconnect href=https://XGS1CPQERK-dsn.algolia.net crossorigin><link rel=alternate type=application/rss+xml href=/blog/rss.xml title="John's Blog RSS Feed"><link rel=alternate type=application/atom+xml href=/blog/atom.xml title="John's Blog Atom Feed"><link rel=search type=application/opensearchdescription+xml title="John's Blog" href=/opensearch.xml><script src=https://hm.baidu.com/hm.js?6b4ae23dc83ee5efe875b7172af6c7c1 async></script><link rel=stylesheet href=/assets/css/styles.d14e1eeb.css><script src=/assets/js/runtime~main.a992bf30.js defer></script><script src=/assets/js/main.239609ed.js defer></script><body class=navigation-with-keyboard><script>!function(){var t,e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t=null!==e?e:"light",document.documentElement.setAttribute("data-theme",t)}(),function(){try{for(var[t,e]of new URLSearchParams(window.location.search).entries())if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id=__docusaurus><div role=region aria-label="Skip to main content"><a class=skipToContent_fXgn href=#__docusaurus_skipToContent_fallback>Skip to main content</a></div><nav aria-label=Main class="navbar navbar--fixed-top"><div class=navbar__inner><div class=navbar__items><button aria-label="Toggle navigation bar" aria-expanded=false class="navbar__toggle clean-btn" type=button><svg width=30 height=30 viewBox="0 0 30 30" aria-hidden=true><path stroke=currentColor stroke-linecap=round stroke-miterlimit=10 stroke-width=2 d="M4 7h22M4 15h22M4 23h22"/></svg></button><a class=navbar__brand href=/><b class="navbar__title text--truncate">John's Blog</b></a><a aria-current=page class="navbar__item navbar__link navbar__link--active" href=/ai>AI技术</a><a class="navbar__item navbar__link" href=/cloud-native>云原生</a><a class="navbar__item navbar__link" href=/notes>日常笔记</a><a class="navbar__item navbar__link" href=/programming>开发语言</a><a class="navbar__item navbar__link" href=/architecture>技术架构</a><a class="navbar__item navbar__link" href=/observability>可观测性</a><a class="navbar__item navbar__link" href=/life>生活笔记</a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href=/aboutme>关于我</a><a class="navbar__item navbar__link" href=/blog>博客</a><a href=https://goframe.org/ target=_blank rel="noopener noreferrer" class="navbar__item navbar__link header-goframe-link"></a><a href=https://github.com/gqcn target=_blank rel="noopener noreferrer" class="navbar__item navbar__link header-github-link"></a><div class=navbarSearchContainer_Bca1><button type=button class="DocSearch DocSearch-Button" aria-label="Search (Command+K)"><span class=DocSearch-Button-Container><svg width=20 height=20 class=DocSearch-Search-Icon viewBox="0 0 20 20" aria-hidden=true><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke=currentColor fill=none fill-rule=evenodd stroke-linecap=round stroke-linejoin=round /></svg><span class=DocSearch-Button-Placeholder>Search</span></span><span class=DocSearch-Button-Keys></span></button></div></div></div><div role=presentation class=navbar-sidebar__backdrop></div></nav><div id=__docusaurus_skipToContent_fallback class="main-wrapper mainWrapper_z2l0"><div class=docsWrapper_hBAB><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type=button></button><div class=docRoot_UBD9><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class=sidebarViewport_aRkj><div class=sidebar_njMd><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--active" href=/ai>AI技术</a><button aria-label="Collapse sidebar category 'AI技术'" aria-expanded=true type=button class="clean-btn menu__caret"></button></div><ul style=display:block;overflow:visible;height:auto class=menu__list><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--sublist-caret" role=button aria-expanded=false tabindex=0 href=/ai/agents-deep-dive-from-llm-to-autonomous-agents>智能体</a></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--sublist-caret" role=button aria-expanded=false tabindex=0 href=/ai/copilot-skills-guide>应用开发</a></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--sublist-caret" role=button aria-expanded=false tabindex=0 href=/ai/online-offline-batch-inference>推理服务</a></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role=button aria-expanded=true tabindex=0 href=/ai/hpc-development-training-platform>训练微调</a></div><ul style=display:block;overflow:visible;height:auto class=menu__list><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--sublist-caret" role=button aria-expanded=false tabindex=0 href=/ai/hpc-development-training-platform>开发训练平台</a></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--sublist-caret" role=button aria-expanded=false tabindex=0 href=/ai/pytorch-intro>开发训练框架</a></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--sublist-caret" role=button aria-expanded=false tabindex=0 href=/ai/kubeflow-trainer-in-hpc>Kubeflow Trainer</a></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--sublist-caret" role=button aria-expanded=false tabindex=0 href=/ai/ray-distributed-computing>Ray分布式计算引擎</a></div><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/ai/machine-learning-fundamentals>AI模型与机器学习</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current=page tabindex=0 href=/ai/training>AI模型训练技术详解</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/ai/fine-tuning>AI模型微调技术详解</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/ai/training-parallel-strategies>AI模型训练并行策略介绍</a></ul><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" tabindex=0 href=/ai/model-development>模型开发</a><button aria-label="Expand sidebar category '模型开发'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--sublist-caret" role=button aria-expanded=false tabindex=0 href=/ai/rdma-brief>基础架构</a></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--sublist-caret" role=button aria-expanded=false tabindex=0 href=/ai/basic-terminology>入门知识</a></div></ul><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/cloud-native>云原生</a><button aria-label="Expand sidebar category '云原生'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/notes>日常笔记</a><button aria-label="Expand sidebar category '日常笔记'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/programming>开发语言</a><button aria-label="Expand sidebar category '开发语言'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/architecture>技术架构</a><button aria-label="Expand sidebar category '技术架构'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/management>技术管理</a><button aria-label="Expand sidebar category '技术管理'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/observability>可观测性</a><button aria-label="Expand sidebar category '可观测性'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/database-and-middleware>数据库与中间件</a><button aria-label="Expand sidebar category '数据库与中间件'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/operating-systems-and-networks>操作系统和网络</a><button aria-label="Expand sidebar category '操作系统和网络'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/life>生活笔记</a><button aria-label="Expand sidebar category '生活笔记'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div></ul></nav></div></div></aside><main class=docMainContainer_TBSr><div class="container padding-top--md padding-bottom--lg"><div class=row><div class="col docItemCol_VOVn"><div class=docItemContainer_Djhp><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label=Breadcrumbs><ul class=breadcrumbs itemscope itemtype=https://schema.org/BreadcrumbList><li class=breadcrumbs__item><a aria-label="Home page" class=breadcrumbs__link href=/><svg viewBox="0 0 24 24" class=breadcrumbHomeIcon_YNFT><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill=currentColor /></svg></a><li itemscope itemprop=itemListElement itemtype=https://schema.org/ListItem class=breadcrumbs__item><a class=breadcrumbs__link itemprop=item href=/ai><span itemprop=name>AI技术</span></a><meta itemprop=position content=1><li class=breadcrumbs__item><span class=breadcrumbs__link>训练微调</span><meta itemprop=position content=2><li itemscope itemprop=itemListElement itemtype=https://schema.org/ListItem class="breadcrumbs__item breadcrumbs__item--active"><span class=breadcrumbs__link itemprop=name>AI模型训练技术详解</span><meta itemprop=position content=3></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type=button class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><p>本文将深入介绍<code>AI</code>模型训练的核心技术和方法，帮助你理解从零开始训练模型和增量预训练的完整过程。</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>前置知识</div><div class=admonitionContent_BuS1><p>本文重点讲解<code>AI</code>模型训练技术。建议先提前了解<code>AI</code>模型的本质(参数、架构等)以及机器学习基础概念(如机器学习、深度学习、神经网络等)，请参考 <a href=/ai/machine-learning-fundamentals>AI模型与机器学习</a>。</div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id=ai模型训练的基本概念>AI模型训练的基本概念<a href=#ai模型训练的基本概念 class=hash-link aria-label="Direct link to AI模型训练的基本概念" title="Direct link to AI模型训练的基本概念">​</a></h2>
<p><strong>训练</strong>就是通过大量数据和反复调整，让神经网络学习并优化其内部参数(权重和偏置)，让模型从"随机猜测"进化到"精准预测"，使其能够完成特定任务的过程。</p>
<p>在了解具体的训练方法之前，让我们通过一个简单的猜数字游戏来理解训练过程：</p>
<p><strong>游戏规则</strong>：我心里想一个<code>1</code>到<code>100</code>之间的数字（假设是<code>42</code>），你来猜。每次猜完，我会告诉你"太大了"还是"太小了"。</p>
<p><strong>第1次</strong>：你随机猜<code>50</code>（这就像<strong>模型初始化</strong>，参数是随机的）</p>
<ul>
<li>我说"太大了"（这就是<strong>计算损失</strong>，发现预测错了）</li>
<li>你意识到要往小的方向调整（这就是<strong>反向传播</strong>，计算梯度）</li>
</ul>
<p><strong>第2次</strong>：你猜<code>30</code>（这就是<strong>参数更新</strong>）</p>
<ul>
<li>我说"太小了"</li>
<li>你知道答案在<code>30-50</code>之间</li>
</ul>
<p><strong>第3次</strong>：你猜<code>40</code></p>
<ul>
<li>我说"太小了"</li>
<li>范围缩小到<code>40-50</code></li>
</ul>
<p><strong>第4-5次</strong>：你继续调整，猜<code>42</code></p>
<ul>
<li>我说"答对了！"（这就是<strong>收敛</strong>，找到了正确答案）</li>
</ul>
<p>这个过程完美展示了<code>AI</code>训练的核心思想：</p>
<ol>
<li><strong>随机开始</strong>：一开始什么都不知道，随便猜</li>
<li><strong>获得反馈</strong>：根据结果知道自己错在哪里</li>
<li><strong>调整策略</strong>：往正确的方向修正</li>
<li><strong>反复迭代</strong>：多次尝试逐步逼近答案</li>
<li><strong>达到目标</strong>：最终找到正确答案</li>
</ol>
<p><strong>训练的本质</strong>：</p>
<p>通过不断调整神经网络中数十亿个参数的值，让模型的预测结果越来越接近真实答案，最终让模型学会解决特定问题的能力。就像猜数字游戏一样，通过反复尝试和调整，最终找到那个"正确答案"。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id=ai模型训练的常见方法>AI模型训练的常见方法<a href=#ai模型训练的常见方法 class=hash-link aria-label="Direct link to AI模型训练的常见方法" title="Direct link to AI模型训练的常见方法">​</a></h2>
<p>理解了训练的基本原理后，你可能会想：现实中是不是每次都要从零开始训练一个模型？答案是否定的。就像盖房子，我们可以从地基开始盖（从零预训练），也可以在已有建筑基础上扩建（增量预训练）。不同的训练策略适用于不同的场景，成本和效果也大相径庭。让我们看看业界主要采用哪些训练方法。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=预训练-pre-training-pt>预训练 (Pre-Training, PT)<a href=#预训练-pre-training-pt class=hash-link aria-label="Direct link to 预训练 (Pre-Training, PT)" title="Direct link to 预训练 (Pre-Training, PT)">​</a></h3>
<p><strong>预训练</strong>是指在海量通用数据上从零开始训练一个大模型的过程，这个模型会学习到广泛的知识和能力，成为后续任务的基础。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=核心特点>核心特点<a href=#核心特点 class=hash-link aria-label="Direct link to 核心特点" title="Direct link to 核心特点">​</a></h4>
<p><strong>通俗理解</strong>：就像培养一个孩子的通识教育阶段，让他从小学到大学学习语文、数学、物理、化学、历史、地理等各种知识，建立广泛的知识体系和思维能力。</p>
<p><strong>关键要素</strong>：</p>
<ul>
<li><strong>数据量超大</strong>：通常使用整个互联网的文本、图片等数据，规模可达<code>TB</code>甚至<code>PB</code>级</li>
<li><strong>训练目标通用</strong>：不针对特定任务，而是学习通用的表示能力</li>
<li><strong>资源消耗巨大</strong>：需要数百到数千块<code>GPU</code>，训练时间从数周到数月</li>
<li><strong>一次性投入</strong>：通常由大公司或研究机构完成，训练完成后可被广泛复用</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=常见的预训练任务>常见的预训练任务<a href=#常见的预训练任务 class=hash-link aria-label="Direct link to 常见的预训练任务" title="Direct link to 常见的预训练任务">​</a></h4>
<p>不同类型的模型有不同的预训练方式：</p>
<table><thead><tr><th>模型类型<th>预训练任务<th>训练目标<th>通俗理解<tbody><tr><td><strong>语言模型<br><code>GPT</code>系列</strong><td>下一个词预测<br><code>Next Token Prediction</code><td>给定前面的文本，预测下一个词<td>给你半句话，让你猜下一个字<tr><td><strong>掩码语言模型<br><code>BERT</code></strong><td>掩码词预测<br><code>Masked Language Modeling</code><td>遮盖句子中的部分词，让模型预测<td>完形填空题<tr><td><strong>图像模型<br><code>ResNet</code>、<code>ViT</code></strong><td>图像分类<br><code>Image Classification</code><td>在大规模图像数据集上学习视觉特征<td>看大量图片学习识别物体<tr><td><strong>多模态模型<br><code>CLIP</code></strong><td>图文对齐<br><code>Image-Text Matching</code><td>学习图像和文本的对应关系<td>学习图片和文字描述的匹配</table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=预训练的产物基座模型>预训练的产物：基座模型<a href=#预训练的产物基座模型 class=hash-link aria-label="Direct link to 预训练的产物：基座模型" title="Direct link to 预训练的产物：基座模型">​</a></h4>
<p>预训练完成后得到的模型称为<strong>基座模型</strong>（<code>Base Model</code>）或<strong>预训练模型</strong>（<code>Pre-trained Model</code>），它具备以下特征：</p>
<p>✅ <strong>通用知识丰富</strong>：学习了大量的语言、常识、推理能力<br>
<!-- -->✅ <strong>迁移能力强</strong>：可以通过微调适应各种下游任务<br>
<!-- -->✅ <strong>开箱即用</strong>：即使不微调也能完成一些基础任务<br>
<!-- -->✅ <strong>社区共享</strong>：通常会开源供大家使用（如<code>BERT</code>、<code>LLaMA</code>、<code>GPT-2</code>等）</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=著名的预训练模型>著名的预训练模型<a href=#著名的预训练模型 class=hash-link aria-label="Direct link to 著名的预训练模型" title="Direct link to 著名的预训练模型">​</a></h4>
<p><strong>国际模型</strong>：</p>
<table><thead><tr><th>模型名称<th>发布机构<th>数据规模<th>参数量<th>主要用途<tbody><tr><td><strong><code>BERT</code></strong><td><code>Google</code><td><code>16GB</code>文本<td><code>110M-340M</code><td>文本理解、分类、问答<tr><td><strong><code>GPT-3</code></strong><td><code>OpenAI</code><td><code>45TB</code>文本<td><code>175B</code><td>文本生成、对话、推理<tr><td><strong><code>LLaMA</code></strong><td><code>Meta</code><td><code>1.4TB</code>文本<td><code>7B-65B</code><td>开源基座模型<tr><td><strong><code>CLIP</code></strong><td><code>OpenAI</code><td><code>4亿</code>图文对<td><code>400M</code><td>图像-文本理解<tr><td><strong><code>ResNet</code></strong><td><code>Microsoft</code><td><code>ImageNet 1.2M</code>图<td><code>25M-60M</code><td>图像识别</table>
<p><strong>国内模型</strong>：</p>
<table><thead><tr><th>模型名称<th>发布机构<th>数据规模<th>参数量<th>主要用途<tbody><tr><td><strong><code>Qwen</code>（通义千问）</strong><td>阿里云<td><code>3TB+</code>中英文文本<td><code>1.8B-72B</code><td>中文理解生成、多语言、编程<tr><td><strong><code>ChatGLM</code></strong><td>清华/智谱<code>AI</code><td>未公开<td><code>6B-130B</code><td>中文对话、文本生成<tr><td><strong><code>Baichuan</code></strong><td>百川智能<td><code>1.4TB</code>多语言<td><code>7B-13B</code><td>开源中文基座模型<tr><td><strong><code>ERNIE</code>（文心）</strong><td>百度<td>海量中文数据<td><code>10B-260B</code><td>中文理解、知识增强</table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=预训练的流程图>预训练的流程图<a href=#预训练的流程图 class=hash-link aria-label="Direct link to 预训练的流程图" title="Direct link to 预训练的流程图">​</a></h4>
<!-- -->
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=增量预训练-continual-pre-training-cpt>增量预训练 (Continual Pre-Training, CPT)<a href=#增量预训练-continual-pre-training-cpt class=hash-link aria-label="Direct link to 增量预训练 (Continual Pre-Training, CPT)" title="Direct link to 增量预训练 (Continual Pre-Training, CPT)">​</a></h3>
<p><strong>增量预训练</strong>是指在已有的预训练模型基础上，使用新的数据继续进行预训练，让模型学习新的知识或增强特定领域的能力。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=核心特点-1>核心特点<a href=#核心特点-1 class=hash-link aria-label="Direct link to 核心特点" title="Direct link to 核心特点">​</a></h4>
<p><strong>通俗理解</strong>：就像一个大学毕业生已经有了基础知识，现在去读研究生深造，学习更专业、更前沿的知识。</p>
<p><strong>为什么需要增量预训练？</strong></p>
<table><thead><tr><th>场景<th>问题<th>增量预训练的作用<tbody><tr><td><strong>知识过时</strong><td>预训练模型的数据可能是几年前的，不了解最新事件<td>用最新数据继续训练，更新知识<tr><td><strong>领域专业性不足</strong><td>通用模型在医疗、法律等专业领域表现不佳<td>用领域数据训练，增强专业能力<tr><td><strong>语言覆盖不足</strong><td>英文模型不擅长中文<td>用中文数据训练，提升中文能力<tr><td><strong>特定能力欠缺</strong><td>需要增强代码理解能力<td>用代码数据训练，提升编程能力</table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=增量预训练-vs-从零预训练>增量预训练 vs 从零预训练<a href=#增量预训练-vs-从零预训练 class=hash-link aria-label="Direct link to 增量预训练 vs 从零预训练" title="Direct link to 增量预训练 vs 从零预训练">​</a></h4>
<table><thead><tr><th>维度<th>从零预训练<th>增量预训练<tbody><tr><td><strong>起点</strong><td>随机初始化参数<td>已有预训练模型<tr><td><strong>数据量</strong><td>需要海量数据（<code>TB</code>级）<td>可以用较少数据（<code>GB-TB</code>级）<tr><td><strong>训练时间</strong><td>数周到数月<td>数天到数周<tr><td><strong>计算成本</strong><td>极高（数百万美元）<td>中等（数万到数十万美元）<tr><td><strong>适用场景</strong><td>构建通用基座模型<td>领域适配、知识更新</table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=典型应用场景>典型应用场景<a href=#典型应用场景 class=hash-link aria-label="Direct link to 典型应用场景" title="Direct link to 典型应用场景">​</a></h4>
<p><strong>1. 领域适配</strong></p>
<p><strong>案例</strong>：基于通用的<code>LLaMA</code>模型，使用医学文献进行增量预训练，得到医学领域的<code>Med-LLaMA</code>。</p>
<p><strong>效果</strong>：</p>
<ul>
<li>医学术语理解更准确</li>
<li>医学知识问答能力显著提升</li>
<li>临床推理能力增强</li>
</ul>
<p><strong>2. 多语言适配</strong></p>
<p><strong>案例</strong>：基于英文的<code>GPT</code>模型，使用中文语料进行增量预训练，得到中文能力更强的<code>GPT</code>模型。</p>
<p><strong>效果</strong>：</p>
<ul>
<li>中文理解和生成能力提升</li>
<li>中文文化相关知识增强</li>
<li>保留原有的英文能力（不会完全遗忘）</li>
</ul>
<p><strong>3. 知识更新</strong></p>
<p><strong>案例</strong>：<code>2025</code>年发布的模型不知道<code>2026</code>年的新闻，使用<code>2026</code>年的新闻数据进行增量预训练。</p>
<p><strong>效果</strong>：</p>
<ul>
<li>了解最新事件和知识</li>
<li>时效性信息更准确</li>
<li>保持原有的基础能力</li>
</ul>
<p><strong>4. 能力增强</strong></p>
<p><strong>案例</strong>：在通用语言模型基础上，使用大量代码数据进行增量预训练，得到<code>Code-LLaMA</code>这样的代码专用模型。</p>
<p><strong>效果</strong>：</p>
<ul>
<li>代码理解能力大幅提升</li>
<li>代码生成质量更高</li>
<li>支持更多编程语言</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=增量预训练的技术要点>增量预训练的技术要点<a href=#增量预训练的技术要点 class=hash-link aria-label="Direct link to 增量预训练的技术要点" title="Direct link to 增量预训练的技术要点">​</a></h4>
<p><strong>1. 学习率设置</strong></p>
<p>增量预训练通常使用<strong>比从零训练更小的学习率（参数更新步长的超参数）</strong>，避免破坏已有知识。</p>
<p><strong>通俗理解</strong>：就像已经学会的东西，复习时要温和一点，不要用力过猛把以前学的都忘了。</p>
<p><strong>2. 数据配比</strong></p>
<p>通常会<strong>混合新数据和原始数据</strong>，而不是只用新数据。</p>
<p><strong>原因</strong>：防止"灾难性遗忘"（<code>Catastrophic Forgetting</code>），即学新知识时把旧知识全忘了。</p>
<p><strong>配比示例</strong>：</p>
<ul>
<li>新领域数据：<code>70%</code></li>
<li>原始通用数据：<code>30%</code></li>
</ul>
<p><strong>3. 训练轮次</strong></p>
<p>增量预训练的轮次通常<strong>比从零训练少得多</strong>。</p>
<p><strong>原因</strong>：模型已经有了好的初始化，不需要太多轮次就能学会新知识。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=增量预训练流程图>增量预训练流程图<a href=#增量预训练流程图 class=hash-link aria-label="Direct link to 增量预训练流程图" title="Direct link to 增量预训练流程图">​</a></h4>
<!-- -->
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=预训练与增量预训练的关系>预训练与增量预训练的关系<a href=#预训练与增量预训练的关系 class=hash-link aria-label="Direct link to 预训练与增量预训练的关系" title="Direct link to 预训练与增量预训练的关系">​</a></h3>
<!-- -->
<p><strong>完整训练流程</strong>：</p>
<ol>
<li><strong>预训练</strong>：在海量通用数据上训练，得到通用基座模型</li>
<li><strong>增量预训练</strong>（可选）：在特定领域数据上继续训练，得到领域模型</li>
<li><strong>微调</strong>：在具体任务数据上训练，得到任务专用模型</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=预训练的成本与价值>预训练的成本与价值<a href=#预训练的成本与价值 class=hash-link aria-label="Direct link to 预训练的成本与价值" title="Direct link to 预训练的成本与价值">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=成本分析>成本分析<a href=#成本分析 class=hash-link aria-label="Direct link to 成本分析" title="Direct link to 成本分析">​</a></h4>
<table><thead><tr><th>模型<th>参数量<th>训练硬件<th>训练时间<th>估计成本<tbody><tr><td><strong><code>BERT-Base</code></strong><td><code>110M</code><td><code>16</code>块<code>TPU</code><td><code>4</code>天<td><code>~$7,000</code><tr><td><strong><code>GPT-2</code></strong><td><code>1.5B</code><td><code>32</code>块<code>V100</code><td><code>1</code>周<td><code>~$43,000</code><tr><td><strong><code>GPT-3</code></strong><td><code>175B</code><td><code>10,000</code>块<code>V100</code><td><code>数月</code><td><code>~$4,600,000</code><tr><td><strong><code>LLaMA-65B</code></strong><td><code>65B</code><td><code>2,048</code>块<code>A100</code><td><code>21</code>天<td><code>~$2,000,000</code></table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=价值体现>价值体现<a href=#价值体现 class=hash-link aria-label="Direct link to 价值体现" title="Direct link to 价值体现">​</a></h4>
<p>尽管预训练成本高昂，但其价值在于：</p>
<p>✅ <strong>一次训练，多次复用</strong>：一个预训练模型可以用于成千上万种任务<br>
<!-- -->✅ <strong>社区共享</strong>：开源后全世界的开发者都能受益<br>
<!-- -->✅ <strong>降低门槛</strong>：让小团队也能开发<code>AI</code>应用<br>
<!-- -->✅ <strong>加速创新</strong>：不需要每个人都从零开始</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=增量预训练的成本与价值>增量预训练的成本与价值<a href=#增量预训练的成本与价值 class=hash-link aria-label="Direct link to 增量预训练的成本与价值" title="Direct link to 增量预训练的成本与价值">​</a></h3>
<p>相比完整的从零预训练，增量预训练的成本要低得多，但仍需要可观的投入。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=成本分析-1>成本分析<a href=#成本分析-1 class=hash-link aria-label="Direct link to 成本分析" title="Direct link to 成本分析">​</a></h4>
<table><thead><tr><th>场景<th>基座模型<th>数据规模<th>训练硬件<th>训练时间<th>估计成本<tbody><tr><td><strong>中文适配</strong><td><code>LLaMA-7B</code><td><code>100GB</code>中文文本<td><code>64</code>块<code>A100</code><td><code>5-7</code>天<td><code>~$50,000</code><tr><td><strong>医学领域</strong><td><code>LLaMA-13B</code><td><code>50GB</code>医学文献<td><code>32</code>块<code>A100</code><td><code>3-5</code>天<td><code>~$30,000</code><tr><td><strong>代码能力</strong><td><code>GPT-3</code><td><code>200GB</code>代码数据<td><code>128</code>块<code>A100</code><td><code>7-10</code>天<td><code>~$100,000</code><tr><td><strong>金融领域</strong><td><code>BERT-Base</code><td><code>20GB</code>金融文档<td><code>8</code>块<code>V100</code><td><code>2-3</code>天<td><code>~$5,000</code></table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=与从零预训练的成本对比>与从零预训练的成本对比<a href=#与从零预训练的成本对比 class=hash-link aria-label="Direct link to 与从零预训练的成本对比" title="Direct link to 与从零预训练的成本对比">​</a></h4>
<p>让我们看一个具体例子：<strong>打造一个7B参数的中文大模型</strong></p>
<table><thead><tr><th>维度<th>从零预训练<th>增量预训练<th>节省比例<tbody><tr><td><strong>数据需求</strong><td><code>1-2TB</code>多语言数据<td><code>100GB</code>中文数据<td>节省<code>90%+</code><tr><td><strong>训练硬件</strong><td><code>256</code>块<code>A100</code><td><code>64</code>块<code>A100</code><td>节省<code>75%</code><tr><td><strong>训练时间</strong><td><code>30-40</code>天<td><code>5-7</code>天<td>节省<code>80%+</code><tr><td><strong>总成本</strong><td><code>$400,000-$600,000</code><td><code>$50,000-$80,000</code><td>节省<code>85%+</code><tr><td><strong>风险</strong><td>高（可能失败）<td>低（基于成熟模型）<td>-</table>
<p><strong>关键优势</strong>：</p>
<p>✅ <strong>成本降低</strong>：通常只需要从零训练成本的<code>10-20%</code>
✅ <strong>时间缩短</strong>：训练时间减少<code>70-85%</code><br>
<!-- -->✅ <strong>数据需求少</strong>：只需要领域数据，不需要海量通用数据<br>
<!-- -->✅ <strong>风险更低</strong>：基于已验证的模型，成功率更高<br>
<!-- -->✅ <strong>效果有保证</strong>：继承基座模型的通用能力，只需增强特定领域</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=价值体现-1>价值体现<a href=#价值体现-1 class=hash-link aria-label="Direct link to 价值体现" title="Direct link to 价值体现">​</a></h4>
<p>增量预训练的价值在于<strong>平衡了成本和专业性</strong>：</p>
<table><thead><tr><th>价值点<th>说明<th>示例<tbody><tr><td><strong>领域专业化</strong><td>在特定领域达到专家水平<td>医学模型理解专业术语准确率提升<code>40%</code><tr><td><strong>语言本地化</strong><td>显著提升特定语言能力<td>中文模型在中文任务上超越原版<code>30%</code><tr><td><strong>知识更新</strong><td>学习最新知识和趋势<td><code>2024</code>年数据让模型了解最新事件<tr><td><strong>企业可负担</strong><td>中型企业也能承受的成本<td><code>5-10</code>万美元的预算即可实现<tr><td><strong>快速迭代</strong><td>几天就能看到效果<td>一周内完成模型升级</table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=实际案例对比>实际案例对比<a href=#实际案例对比 class=hash-link aria-label="Direct link to 实际案例对比" title="Direct link to 实际案例对比">​</a></h4>
<p><strong>案例：打造医学AI助手</strong></p>
<table><thead><tr><th>方案<th>从零训练医学模型<th>基于<code>LLaMA</code>增量预训练<tbody><tr><td><strong>需要数据</strong><td>需要<code>TB</code>级通用数据+医学数据<td>只需<code>50-100GB</code>医学数据<tr><td><strong>训练成本</strong><td><code>$500,000+</code><td><code>$30,000-$50,000</code><tr><td><strong>训练时间</strong><td><code>2-3</code>个月<td><code>5-7</code>天<tr><td><strong>团队规模</strong><td><code>10+</code>人的大团队<td><code>2-3</code>人的小团队<tr><td><strong>成功率</strong><td><code>60-70%</code>（可能失败）<td><code>90%+</code>（基于成熟模型）<tr><td><strong>最终效果</strong><td>通用能力弱，医学能力强<td>通用能力强，医学能力也强</table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=何时选择增量预训练>何时选择增量预训练？<a href=#何时选择增量预训练 class=hash-link aria-label="Direct link to 何时选择增量预训练？" title="Direct link to 何时选择增量预训练？">​</a></h4>
<p><strong>适合增量预训练的场景</strong>：</p>
<p>✅ 已有开源基座模型可用（如<code>LLaMA</code>、<code>Qwen</code>）<br>
<!-- -->✅ 需要增强特定领域或语言的能力<br>
<!-- -->✅ 预算在<code>5-20</code>万美元范围<br>
<!-- -->✅ 时间紧迫，需要快速上线<br>
<!-- -->✅ 团队规模有限（<code>2-5</code>人）</p>
<p><strong>必须从零训练的场景</strong>：</p>
<p>❌ 需要完全不同的架构创新<br>
<!-- -->❌ 现有模型都不满足基本要求<br>
<!-- -->❌ 有充足的预算（百万美元级）和时间（数月）<br>
<!-- -->❌ 需要完全掌控模型的所有细节<br>
<!-- -->❌ 商业许可限制（某些模型不允许商用）</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=预训练方法总结>预训练方法总结<a href=#预训练方法总结 class=hash-link aria-label="Direct link to 预训练方法总结" title="Direct link to 预训练方法总结">​</a></h3>
<table><thead><tr><th>维度<th>从零预训练<th>增量预训练<tbody><tr><td><strong>起点</strong><td>随机初始化<td>已有预训练模型<tr><td><strong>数据规模</strong><td><code>TB</code>级<td><code>GB-TB</code>级<tr><td><strong>训练目标</strong><td>学习通用知识<td>增强特定领域<tr><td><strong>成本</strong><td><code>$100万-$500万</code><td><code>$5万-$20万</code><tr><td><strong>时间</strong><td><code>1-3</code>个月<td><code>5-15</code>天<tr><td><strong>适用场景</strong><td>构建基座模型<td>领域适配、语言适配<tr><td><strong>主要玩家</strong><td>大公司、研究机构<td>中型企业、创业公司</table>
<p>预训练和增量预训练构成了现代<code>AI</code>模型的基础，前者建立通用能力，后者实现专业适配。理解这两种方法的成本和价值，是掌握<code>AI</code>模型训练的关键第一步。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id=ai模型训练的完整流程>AI模型训练的完整流程<a href=#ai模型训练的完整流程 class=hash-link aria-label="Direct link to AI模型训练的完整流程" title="Direct link to AI模型训练的完整流程">​</a></h2>
<!-- -->
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=步骤1需求分析>步骤1：需求分析<a href=#步骤1需求分析 class=hash-link aria-label="Direct link to 步骤1：需求分析" title="Direct link to 步骤1：需求分析">​</a></h3>
<p>明确要解决的业务问题：</p>
<ul>
<li>具体任务是什么？（分类、生成、问答等）</li>
<li>输入和输出是什么？</li>
<li>性能要求是什么？（准确率、延迟等）</li>
<li>可用资源是什么？（数据、算力、预算）</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=步骤2数据收集>步骤2：数据收集<a href=#步骤2数据收集 class=hash-link aria-label="Direct link to 步骤2：数据收集" title="Direct link to 步骤2：数据收集">​</a></h3>
<table><thead><tr><th>数据来源<th>优点<th>缺点<th>适用场景<tbody><tr><td><strong>企业内部数据</strong><td>领域相关性强<td>可能量不足<td>垂直领域应用<tr><td><strong>公开数据集</strong><td>免费、量大<td>可能不匹配任务<td>通用任务、学习<tr><td><strong>数据采购</strong><td>质量可控<td>成本高<td>商业项目<tr><td><strong>数据标注</strong><td>可定制<td>耗时长<td>监督学习任务<tr><td><strong>数据生成</strong><td>成本低、可扩展<td>可能有偏差<td>数据增强</table>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=步骤3数据预处理>步骤3：数据预处理<a href=#步骤3数据预处理 class=hash-link aria-label="Direct link to 步骤3：数据预处理" title="Direct link to 步骤3：数据预处理">​</a></h3>
<p><strong>数据清洗</strong>：</p>
<ul>
<li>去除重复数据</li>
<li>过滤低质量或错误数据</li>
<li>统一格式和编码</li>
</ul>
<p><strong>数据标注</strong>：</p>
<ul>
<li>定义标注规范</li>
<li>培训标注员</li>
<li>质量抽检和一致性检查</li>
</ul>
<p><strong>数据增强</strong>：</p>
<ul>
<li>同义词替换</li>
<li>回译（翻译成其他语言再翻译回来）</li>
<li>使用模型生成相似样本</li>
</ul>
<p><strong>数据划分</strong>：</p>
<ul>
<li>训练集：70-80%</li>
<li>验证集：10-15%</li>
<li>测试集：10-15%</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=步骤4选择基座模型>步骤4：选择基座模型<a href=#步骤4选择基座模型 class=hash-link aria-label="Direct link to 步骤4：选择基座模型" title="Direct link to 步骤4：选择基座模型">​</a></h3>
<p><strong>考虑因素</strong>：</p>
<table><thead><tr><th>因素<th>考虑点<tbody><tr><td><strong>任务类型</strong><td>文本、图像、多模态等<tr><td><strong>模型规模</strong><td>参数量与算力是否匹配<tr><td><strong>语言支持</strong><td>中文、英文或多语言<tr><td><strong>开源协议</strong><td>商业使用是否受限<tr><td><strong>社区支持</strong><td>文档、工具、案例是否丰富</table>
<p><strong>常用开源模型</strong>：</p>
<table><thead><tr><th>模型系列<th>参数量<th>特点<th>适用场景<tbody><tr><td><strong><code>LLaMA-2</code></strong><td><code>7B-70B</code><td><code>Meta</code>开源，性能强<td>通用文本任务<tr><td><strong><code>Qwen</code></strong><td><code>1.8B-72B</code><td>阿里云，中文优秀<td>中文应用<tr><td><strong><code>ChatGLM</code></strong><td><code>6B-32B</code><td>清华开源，对话好<td>中文对话<tr><td><strong><code>Mistral</code></strong><td><code>7B</code><td>欧洲团队，高效<td>资源受限场景<tr><td><strong><code>BERT</code></strong><td><code>110M-340M</code><td>经典文本理解<td>分类、<code>NER</code>等</table>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=步骤5增量预训练可选>步骤5：增量预训练（可选）<a href=#步骤5增量预训练可选 class=hash-link aria-label="Direct link to 步骤5：增量预训练（可选）" title="Direct link to 步骤5：增量预训练（可选）">​</a></h3>
<p><strong>何时需要</strong>：</p>
<ul>
<li>领域数据与通用数据差异大（如医学、法律）</li>
<li>需要学习特定领域知识</li>
<li>有大量领域无标注数据</li>
</ul>
<p><strong>训练要点</strong>：</p>
<ul>
<li>使用较小学习率（如<code>2e-5</code>）</li>
<li>混合通用数据和领域数据</li>
<li>监控困惑度（<code>Perplexity</code>）下降</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=步骤6微调训练>步骤6：微调训练<a href=#步骤6微调训练 class=hash-link aria-label="Direct link to 步骤6：微调训练" title="Direct link to 步骤6：微调训练">​</a></h3>
<p><strong>选择微调方法</strong>：</p>
<ul>
<li>任务简单、数据充足：全量微调（<code>FT</code>）</li>
<li>需要指令遵循：有监督微调（<code>SFT</code>）</li>
<li>需要优化主观质量：强化学习（<code>RLHF</code>）</li>
</ul>
<p><strong>训练技巧</strong>：</p>
<ul>
<li>使用梯度累积应对显存不足</li>
<li>使用混合精度训练加速</li>
<li>定期在验证集上评估</li>
<li>使用早停防止过拟合</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=步骤7模型评估>步骤7：模型评估<a href=#步骤7模型评估 class=hash-link aria-label="Direct link to 步骤7：模型评估" title="Direct link to 步骤7：模型评估">​</a></h3>
<p><strong>自动评估指标</strong>：</p>
<table><thead><tr><th>任务类型<th>常用指标<tbody><tr><td><strong>分类</strong><td>准确率、<code>F1</code>分数、<code>AUC</code><tr><td><strong>生成</strong><td><code>BLEU</code>、<code>ROUGE</code>、<code>Perplexity</code><tr><td><strong>问答</strong><td><code>EM</code>（精确匹配）、<code>F1</code><tr><td><strong>摘要</strong><td><code>ROUGE</code>、<code>BERTScore</code><tr><td><strong>对话</strong><td>困惑度、响应多样性</table>
<p><strong>人工评估</strong>：</p>
<ul>
<li>相关性：回答是否切题</li>
<li>流畅性：语言是否自然</li>
<li>准确性：信息是否正确</li>
<li>安全性：是否包含有害内容</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=步骤8模型优化>步骤8：模型优化<a href=#步骤8模型优化 class=hash-link aria-label="Direct link to 步骤8：模型优化" title="Direct link to 步骤8：模型优化">​</a></h3>
<p>针对部署需求优化模型：</p>
<p><strong>模型压缩</strong>：</p>
<ul>
<li><strong>量化</strong>：将<code>32</code>位浮点数降为<code>8</code>位或<code>4</code>位整数</li>
<li><strong>剪枝</strong>：移除不重要的参数</li>
<li><strong>知识蒸馏</strong>：用小模型学习大模型</li>
</ul>
<p><strong>效果对比</strong>：</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#f8f8f2;--prism-background-color:#272822><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-text codeBlock_bY9V thin-scrollbar" style=color:#f8f8f2;background-color:#272822><code class=codeBlockLines_e6Vv><span class=token-line style=color:#f8f8f2><span class="token plain">原始模型：7B 参数，14GB 显存，100ms 延迟，准确率 92%</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">量化后（INT4）：7B 参数，3.5GB 显存，110ms 延迟，准确率 90.5%（下降 1.5% &lt; 2%）</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">蒸馏后（学生模型）：1.5B 参数，3GB 显存，20ms 延迟，准确率 87%（下降 5%）</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label="Copy code to clipboard" title=Copy class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=步骤9部署上线>步骤9：部署上线<a href=#步骤9部署上线 class=hash-link aria-label="Direct link to 步骤9：部署上线" title="Direct link to 步骤9：部署上线">​</a></h3>
<p><strong>部署方式</strong>：</p>
<table><thead><tr><th>方式<th>特点<th>适用场景<tbody><tr><td><strong>云端API</strong><td>高性能、易扩展、成本按需<td>并发不高的应用<tr><td><strong>边缘部署</strong><td>低延迟、数据隐私保护<td>实时性要求高<tr><td><strong>本地部署</strong><td>数据安全、无网络依赖<td>企业内网系统<tr><td><strong>混合部署</strong><td>平衡性能和成本<td>复杂业务场景</table>
<p><strong>常用部署框架</strong>：</p>
<ul>
<li><strong><code>vLLM</code></strong>：高性能推理引擎</li>
<li><strong><code>FastAPI</code></strong>：快速构建<code>API</code>服务</li>
<li><strong><code>TensorRT</code></strong>：<code>NVIDIA</code>推理加速</li>
<li><strong><code>ONNX Runtime</code></strong>：跨平台推理</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=步骤10监控运营>步骤10：监控运营<a href=#步骤10监控运营 class=hash-link aria-label="Direct link to 步骤10：监控运营" title="Direct link to 步骤10：监控运营">​</a></h3>
<p><strong>监控指标</strong>：</p>
<ul>
<li><strong>性能指标</strong>：响应延迟、吞吐量、可用性</li>
<li><strong>业务指标</strong>：用户满意度、任务完成率、错误率</li>
<li><strong>成本指标</strong>：<code>GPU</code>利用率、推理成本</li>
</ul>
<p><strong>持续优化</strong>：</p>
<ul>
<li>收集用户反馈和<code>badcase</code></li>
<li>定期评估模型效果</li>
<li>积累新数据进行增量训练</li>
<li>跟踪新技术和新模型</li>
</ul></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href=/ai/machine-learning-fundamentals><div class=pagination-nav__sublabel>Previous</div><div class=pagination-nav__label>AI模型与机器学习</div></a><a class="pagination-nav__link pagination-nav__link--next" href=/ai/fine-tuning><div class=pagination-nav__sublabel>Next</div><div class=pagination-nav__label>AI模型微调技术详解</div></a></nav><div class=docusaurus-mt-lg></div></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href=#ai模型训练的基本概念 class="table-of-contents__link toc-highlight">AI模型训练的基本概念</a><li><a href=#ai模型训练的常见方法 class="table-of-contents__link toc-highlight">AI模型训练的常见方法</a><ul><li><a href=#预训练-pre-training-pt class="table-of-contents__link toc-highlight">预训练 (Pre-Training, PT)</a><li><a href=#增量预训练-continual-pre-training-cpt class="table-of-contents__link toc-highlight">增量预训练 (Continual Pre-Training, CPT)</a><li><a href=#预训练与增量预训练的关系 class="table-of-contents__link toc-highlight">预训练与增量预训练的关系</a><li><a href=#预训练的成本与价值 class="table-of-contents__link toc-highlight">预训练的成本与价值</a><li><a href=#增量预训练的成本与价值 class="table-of-contents__link toc-highlight">增量预训练的成本与价值</a><li><a href=#预训练方法总结 class="table-of-contents__link toc-highlight">预训练方法总结</a></ul><li><a href=#ai模型训练的完整流程 class="table-of-contents__link toc-highlight">AI模型训练的完整流程</a><ul><li><a href=#步骤1需求分析 class="table-of-contents__link toc-highlight">步骤1：需求分析</a><li><a href=#步骤2数据收集 class="table-of-contents__link toc-highlight">步骤2：数据收集</a><li><a href=#步骤3数据预处理 class="table-of-contents__link toc-highlight">步骤3：数据预处理</a><li><a href=#步骤4选择基座模型 class="table-of-contents__link toc-highlight">步骤4：选择基座模型</a><li><a href=#步骤5增量预训练可选 class="table-of-contents__link toc-highlight">步骤5：增量预训练（可选）</a><li><a href=#步骤6微调训练 class="table-of-contents__link toc-highlight">步骤6：微调训练</a><li><a href=#步骤7模型评估 class="table-of-contents__link toc-highlight">步骤7：模型评估</a><li><a href=#步骤8模型优化 class="table-of-contents__link toc-highlight">步骤8：模型优化</a><li><a href=#步骤9部署上��线 class="table-of-contents__link toc-highlight">步骤9：部署上线</a><li><a href=#步骤10监控运营 class="table-of-contents__link toc-highlight">步骤10：监控运营</a></ul></ul></div></div></div></div></main></div></div></div><footer class=footer><div class="container container-fluid"><div class="footer__bottom text--center"><div class=footer__copyright>Copyright 2026 johng.cn</div></div></div></footer></div>