<!doctype html><html lang=en dir=ltr class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-docs/AI技术/vGPU/HAMi vGPU介绍" data-has-hydrated=false><meta charset=UTF-8><meta name=generator content="Docusaurus v3.6.3"><title data-rh=true>HAMi vGPU介绍 | John's Blog</title><meta data-rh=true name=viewport content="width=device-width,initial-scale=1.0"><meta data-rh=true name=twitter:card content=summary_large_image><meta data-rh=true property=og:url content=https://johng.cn/ai/vgpu-hami><meta data-rh=true property=og:locale content=en><meta data-rh=true name=docusaurus_locale content=en><meta data-rh=true name=docsearch:language content=en><meta data-rh=true name=docusaurus_version content=current><meta data-rh=true name=docusaurus_tag content=docs-default-current><meta data-rh=true name=docsearch:version content=current><meta data-rh=true name=docsearch:docusaurus_tag content=docs-default-current><meta data-rh=true property=og:title content="HAMi vGPU介绍 | John's Blog"><meta data-rh=true name=description content="HAMi是CNCF沙箱项目，提供Kubernetes环境下的GPU虚拟化解决方案。通过CUDA API劫持实现硬显存隔离和算力配额管理，支持多GPU厂商，零侵入应用，是目前最成熟的开源vGPU方案之一。"><meta data-rh=true property=og:description content="HAMi是CNCF沙箱项目，提供Kubernetes环境下的GPU虚拟化解决方案。通过CUDA API劫持实现硬显存隔离和算力配额管理，支持多GPU厂商，零侵入应用，是目前最成熟的开源vGPU方案之一。"><meta data-rh=true name=keywords content="HAMi,vGPU,GPU虚拟化,Kubernetes,CUDA API劫持,显存隔离,GPU共享,CNCF,云原生"><link data-rh=true rel=icon href=/img/favicon.ico><link data-rh=true rel=canonical href=https://johng.cn/ai/vgpu-hami><link data-rh=true rel=alternate href=https://johng.cn/ai/vgpu-hami hreflang=en><link data-rh=true rel=alternate href=https://johng.cn/ai/vgpu-hami hreflang=x-default><link data-rh=true rel=preconnect href=https://XGS1CPQERK-dsn.algolia.net crossorigin><link rel=alternate type=application/rss+xml href=/blog/rss.xml title="John's Blog RSS Feed"><link rel=alternate type=application/atom+xml href=/blog/atom.xml title="John's Blog Atom Feed"><link rel=search type=application/opensearchdescription+xml title="John's Blog" href=/opensearch.xml><script src=https://hm.baidu.com/hm.js?6b4ae23dc83ee5efe875b7172af6c7c1 async></script><link rel=stylesheet href=/assets/css/styles.b3f7724c.css><script src=/assets/js/runtime~main.a665ee42.js defer></script><script src=/assets/js/main.c72ff0a9.js defer></script><body class=navigation-with-keyboard><script>!function(){var t,e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t=null!==e?e:"light",document.documentElement.setAttribute("data-theme",t)}(),function(){try{for(var[t,e]of new URLSearchParams(window.location.search).entries())if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id=__docusaurus><div role=region aria-label="Skip to main content"><a class=skipToContent_fXgn href=#__docusaurus_skipToContent_fallback>Skip to main content</a></div><nav aria-label=Main class="navbar navbar--fixed-top"><div class=navbar__inner><div class=navbar__items><button aria-label="Toggle navigation bar" aria-expanded=false class="navbar__toggle clean-btn" type=button><svg width=30 height=30 viewBox="0 0 30 30" aria-hidden=true><path stroke=currentColor stroke-linecap=round stroke-miterlimit=10 stroke-width=2 d="M4 7h22M4 15h22M4 23h22"/></svg></button><a class=navbar__brand href=/><b class="navbar__title text--truncate">John's Blog</b></a><a aria-current=page class="navbar__item navbar__link navbar__link--active" sidebarid=mainSidebar href=/ai>AI技术</a><a class="navbar__item navbar__link" sidebarid=mainSidebar href=/cloud-native>云原生</a><a class="navbar__item navbar__link" sidebarid=mainSidebar href=/notes>日常笔记</a><a class="navbar__item navbar__link" sidebarid=mainSidebar href=/programming>开发语言</a><a class="navbar__item navbar__link" sidebarid=mainSidebar href=/architecture>技术架构</a><a class="navbar__item navbar__link" sidebarid=mainSidebar href=/observability>可观测性</a><a class="navbar__item navbar__link" sidebarid=mainSidebar href=/database-and-middleware>数据库与中间件</a><a class="navbar__item navbar__link" href=/aboutme>关于我</a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href=/blog>博客</a><a href=https://goframe.org/ target=_blank rel="noopener noreferrer" class="navbar__item navbar__link header-goframe-link"></a><a href=https://github.com/gqcn target=_blank rel="noopener noreferrer" class="navbar__item navbar__link header-github-link"></a><div class=navbarSearchContainer_Bca1><button type=button class="DocSearch DocSearch-Button" aria-label="Search (Command+K)"><span class=DocSearch-Button-Container><svg width=20 height=20 class=DocSearch-Search-Icon viewBox="0 0 20 20" aria-hidden=true><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke=currentColor fill=none fill-rule=evenodd stroke-linecap=round stroke-linejoin=round /></svg><span class=DocSearch-Button-Placeholder>Search</span></span><span class=DocSearch-Button-Keys></span></button></div></div></div><div role=presentation class=navbar-sidebar__backdrop></div></nav><div id=__docusaurus_skipToContent_fallback class="main-wrapper mainWrapper_z2l0"><div class=docsWrapper_hBAB><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type=button></button><div class=docRoot_UBD9><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class=sidebarViewport_aRkj><div class=sidebar_njMd><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--active" href=/ai>AI技术</a><button aria-label="Collapse sidebar category 'AI技术'" aria-expanded=true type=button class="clean-btn menu__caret"></button></div><ul style=display:block;overflow:visible;height:auto class=menu__list><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" tabindex=0 href=/ai/nvidia>NVIDIA</a><button aria-label="Expand sidebar category 'NVIDIA'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" tabindex=0 href=/ai/distributed-inference>分布式推理</a><button aria-label="Expand sidebar category '分布式推理'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" tabindex=0 href=/ai/scheduling>算力资源调度</a><button aria-label="Expand sidebar category '算力资源调度'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" tabindex=0 href=/ai/rdma>RDMA</a><button aria-label="Expand sidebar category 'RDMA'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--active" tabindex=0 href=/ai/vgpu>vGPU</a><button aria-label="Collapse sidebar category 'vGPU'" aria-expanded=true type=button class="clean-btn menu__caret"></button></div><ul style=display:block;overflow:visible;height:auto class=menu__list><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/ai/vgpu-survey>vGPU方案调研</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current=page tabindex=0 href=/ai/vgpu-hami>HAMi vGPU介绍</a></ul><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ai/common-acceleration-cards>常见智算加速卡汇总</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ai/general-ai-model-and-reasoning-ai-model-difference>通用大模型和推理大模型区别</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ai/common-ai-model-training-inference-framework>常见AI模型训练推理框架对比</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ai/ai-training-inference-scenarios>AI模型训练推理常见业务场景痛点</a></ul><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/cloud-native>云原生</a><button aria-label="Expand sidebar category '云原生'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/notes>日常笔记</a><button aria-label="Expand sidebar category '日常笔记'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/programming>开发语言</a><button aria-label="Expand sidebar category '开发语言'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/architecture>技术架构</a><button aria-label="Expand sidebar category '技术架构'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/management>技术管理</a><button aria-label="Expand sidebar category '技术管理'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/observability>可观测性</a><button aria-label="Expand sidebar category '可观测性'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/database-and-middleware>数据库与中间件</a><button aria-label="Expand sidebar category '数据库与中间件'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/operating-systems-and-networks>操作系统和网络</a><button aria-label="Expand sidebar category '操作系统和网络'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div></ul></nav></div></div></aside><main class=docMainContainer_TBSr><div class="container padding-top--md padding-bottom--lg"><div class=row><div class="col docItemCol_VOVn"><div class=docItemContainer_Djhp><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label=Breadcrumbs><ul class=breadcrumbs itemscope itemtype=https://schema.org/BreadcrumbList><li class=breadcrumbs__item><a aria-label="Home page" class=breadcrumbs__link href=/><svg viewBox="0 0 24 24" class=breadcrumbHomeIcon_YNFT><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill=currentColor /></svg></a><li itemscope itemprop=itemListElement itemtype=https://schema.org/ListItem class=breadcrumbs__item><a class=breadcrumbs__link itemprop=item href=/ai><span itemprop=name>AI技术</span></a><meta itemprop=position content=1><li itemscope itemprop=itemListElement itemtype=https://schema.org/ListItem class=breadcrumbs__item><a class=breadcrumbs__link itemprop=item href=/ai/vgpu><span itemprop=name>vGPU</span></a><meta itemprop=position content=2><li itemscope itemprop=itemListElement itemtype=https://schema.org/ListItem class="breadcrumbs__item breadcrumbs__item--active"><span class=breadcrumbs__link itemprop=name>HAMi vGPU介绍</span><meta itemprop=position content=3></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type=button class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h3 class="anchor anchorWithStickyNavbar_LWe7" id=1-hami项目概述>1. HAMi项目概述<a href=#1-hami项目概述 class=hash-link aria-label="Direct link to 1. HAMi项目概述" title="Direct link to 1. HAMi项目概述">​</a></h3>
<p><img decoding=async loading=lazy alt=HAMi整体架构 src=/assets/images/image-2-84381ed8be34a777eec27418714dd345.png width=1280 height=720 class=img_ev3q></p>
<p><strong>HAMi</strong> (<code>Heterogeneous AI Computing Virtualization Middleware</code>) 是开源的 <code>vGPU</code>与调度系统 <a href=https://project-hami.io/ target=_blank rel="noopener noreferrer">https://project-hami.io/</a> ，目标是为<code>Kubernetes</code>环境下的深度学习/推理任务提供细粒度、灵活的<code>GPU</code>资源管理能力。其思路是：在<code>Kubernetes</code>调度层与<code>GPU driver</code>层能力之间，建立一个智能的中间层，用统一的接口和策略提供给用户。这样，用户提交任务时不需要关心底层细节，只需要声明需要多少<code>GPU</code>算力/显存，<code>HAMi</code>就能动态分配、隔离并调度。</p>
<p><strong>项目信息</strong>：</p>
<ul>
<li><strong>GitHub</strong>: <a href=https://github.com/Project-HAMi/HAMi target=_blank rel="noopener noreferrer">https://github.com/Project-HAMi/HAMi</a></li>
<li><strong>开源协议</strong>: <code>Apache 2.0</code></li>
<li><strong>项目状态</strong>: <code>CNCF</code>沙箱项目，活跃，持续更新</li>
</ul>
<p><strong>核心特性</strong>：</p>
<ul>
<li>✅ 硬显存隔离</li>
<li>✅ 算力配额限制</li>
<li>✅ <code>Kubernetes</code>原生集成</li>
<li>✅ 多GPU厂商支持（<code>NVIDIA</code>、<code>AMD</code>、<code>昇腾</code>等）</li>
<li>✅ 完善的监控和可观测性</li>
<li>✅ 零侵入，应用无需修改</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id=2-hami的优势与局限>2. HAMi的优势与局限<a href=#2-hami的优势与局限 class=hash-link aria-label="Direct link to 2. HAMi的优势与局限" title="Direct link to 2. HAMi的优势与局限">​</a></h2>
<table><thead><tr><th>维度<th>优势 ✅<th>局限 ⚠️<tbody><tr><td><strong>隔离性</strong><td>• 硬显存隔离，防止<code>OOM</code>相互影响<br>• 进程崩溃不影响其他容器<br>• 资源配额强制执行<td>• 算力隔离较弱，仅能软限制<br>• 无法像<code>MIG</code>那样硬件级隔离<br>• 恶意进程可能超出配额<tr><td><strong>性能</strong><td>• 大规模计算场景影响较小<br>• 相比内核态方案开销更低<td>• <code>API</code>劫持带来<code>5-15%</code>性能损失<br>• 小<code>batch</code>推理场景影响较大<tr><td><strong>易用性</strong><td>• <code>Kubernetes</code>原生集成<br>• 无缝集成<code>K8S</code>调度器<br>• 支持标准资源请求语法<br>• 完善的监控和可观测性<td>• <code>API</code>劫持可能影响调试工具<br>• 错误信息可能不够直观<br>• 需要理解<code>vGPU</code>机制<tr><td><strong>兼容性</strong><td>• 多<code>GPU</code>厂商支持（<code>NVIDIA</code>、<code>AMD</code>、<code>昇腾</code>等）<br>• 易于扩展支持新硬件<br>• 零侵入，应用无需修改<td>• 某些使用<code>CUDA IPC</code>的应用不兼容<br>• 直接调用<code>Driver API</code>的应用可能绕过<br>• 需要针对<code>CUDA</code>版本适配<tr><td><strong>开源与社区</strong><td>• <code>Apache 2.0</code>协议<br>• 社区活跃，持续更新<br>• 无版权风险<br>• <code>CNCF</code>沙箱项目<td>• 相比商业方案技术支持有限<br>• 部分高级特性需要社区贡献</table>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id=3-hami整体架构>3 HAMi整体架构<a href=#3-hami整体架构 class=hash-link aria-label="Direct link to 3 HAMi整体架构" title="Direct link to 3 HAMi整体架构">​</a></h2>
<p><img decoding=async loading=lazy alt=HAMi关键组件详解 src=/assets/images/image-3-cabd4484c18781655b001906186b4fde.png width=1394 height=550 class=img_ev3q></p>
<p><code>HAMi</code>采用分层架构设计，由以下四个核心组件协同工作：</p>
<ul>
<li><strong>HAMi Mutating Webhook</strong>：<code>Pod</code>准入控制器，拦截并修改<code>Pod</code>定义</li>
<li><strong>HAMi Scheduler Extender</strong>：调度器扩展，实现智能<code>GPU</code>资源调度</li>
<li><strong>HAMi Device Plugin</strong>：设备插件，负责<code>GPU</code>资源注册与分配</li>
<li><strong>HAMi Core</strong>：容器内运行时库，实现资源隔离与配额控制</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=31-hami-mutatingwebhook>3.1 HAMi MutatingWebhook<a href=#31-hami-mutatingwebhook class=hash-link aria-label="Direct link to 3.1 HAMi MutatingWebhook" title="Direct link to 3.1 HAMi MutatingWebhook">​</a></h3>
<p><strong>功能职责</strong>：</p>
<ul>
<li>拦截<code>Pod</code>创建请求，检查是否包含<code>GPU</code>资源需求</li>
<li>自动为<code>GPU Pod</code>注入必要的配置和环境变量</li>
<li>设置<code>schedulerName</code>为<code>hami-scheduler</code>，确保由<code>HAMi</code>调度器处理</li>
<li>注入<code>runtimeClassName</code>和<code>LD_PRELOAD</code>等运行时参数</li>
</ul>
<p><strong>工作流程</strong>：</p>
<ol>
<li><strong>Pod提交拦截</strong>：当用户提交包含<code>GPU</code>资源请求的<code>Pod</code>时，<code>Webhook</code>首先拦截该请求</li>
<li><strong>资源字段扫描</strong>：检查<code>Pod</code>的资源需求字段，识别是否为<code>HAMi</code>管理的<code>GPU</code>资源</li>
<li><strong>自动配置注入</strong>：为符合条件的<code>Pod</code>自动设置调度器名称和运行时配置</li>
<li><strong>环境变量预埋</strong>：注入<code>LD_PRELOAD</code>等环境变量，为后续的<code>API</code>劫持做准备</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=32-hami-scheduler-extender>3.2 HAMi Scheduler Extender<a href=#32-hami-scheduler-extender class=hash-link aria-label="Direct link to 3.2 HAMi Scheduler Extender" title="Direct link to 3.2 HAMi Scheduler Extender">​</a></h3>
<p><strong>功能职责</strong>：</p>
<ul>
<li>扩展<code>Kubernetes</code>默认调度器，实现<code>GPU</code>资源的智能调度</li>
<li>维护集群级别的<code>GPU</code>资源全局视图</li>
<li>根据显存、算力等多维度资源进行节点筛选和打分</li>
<li>支持拓扑感知、资源碎片优化等高级调度策略</li>
</ul>
<p><strong>调度策略</strong>：</p>
<ol>
<li>
<p><strong>Filter阶段</strong>：</p>
<ul>
<li>过滤显存不足的节点</li>
<li>过滤算力不足的节点</li>
<li>检查<code>GPU</code>型号匹配性</li>
</ul>
</li>
<li>
<p><strong>Score阶段</strong>：</p>
<ul>
<li>优先选择资源碎片少的节点</li>
<li>考虑<code>GPU</code>拓扑结构，减少跨卡通信</li>
<li>平衡节点负载，避免资源热点</li>
</ul>
</li>
<li>
<p><strong>Bind阶段</strong>：</p>
<ul>
<li>确定最优节点并绑定<code>Pod</code></li>
<li>更新资源分配记录到<code>Pod</code>注解</li>
</ul>
</li>
</ol>
<p><strong>配置示例</strong>：</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#f8f8f2;--prism-background-color:#272822><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style=color:#f8f8f2;background-color:#272822><code class=codeBlockLines_e6Vv><span class=token-line style=color:#f8f8f2><span class="token key atrule">apiVersion</span><span class="token punctuation" style=color:#f8f8f2>:</span><span class="token plain"> v1</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token key atrule">kind</span><span class="token punctuation" style=color:#f8f8f2>:</span><span class="token plain"> ConfigMap</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token key atrule">metadata</span><span class="token punctuation" style=color:#f8f8f2>:</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">  </span><span class="token key atrule">name</span><span class="token punctuation" style=color:#f8f8f2>:</span><span class="token plain"> hami</span><span class="token punctuation" style=color:#f8f8f2>-</span><span class="token plain">scheduler</span><span class="token punctuation" style=color:#f8f8f2>-</span><span class="token plain">config</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token key atrule">data</span><span class="token punctuation" style=color:#f8f8f2>:</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">  </span><span class="token key atrule">config.yaml</span><span class="token punctuation" style=color:#f8f8f2>:</span><span class="token plain"> </span><span class="token punctuation" style=color:#f8f8f2>|</span><span class="token scalar string" style=color:#a6e22e></span><br></span><span class=token-line style=color:#f8f8f2><span class="token scalar string" style=color:#a6e22e>    schedulerName: hami-scheduler</span><br></span><span class=token-line style=color:#f8f8f2><span class="token scalar string" style=color:#a6e22e>    policy:</span><br></span><span class=token-line style=color:#f8f8f2><span class="token scalar string" style=color:#a6e22e>      # 调度策略</span><br></span><span class=token-line style=color:#f8f8f2><span class="token scalar string" style=color:#a6e22e>      binpack: true  # 启用紧凑打包</span><br></span><span class=token-line style=color:#f8f8f2><span class="token scalar string" style=color:#a6e22e>      spread: false  # 禁用分散策略</span><br></span><span class=token-line style=color:#f8f8f2><span class="token scalar string" style=color:#a6e22e>      </span><br></span><span class=token-line style=color:#f8f8f2><span class="token scalar string" style=color:#a6e22e>      # 资源分配</span><br></span><span class=token-line style=color:#f8f8f2><span class="token scalar string" style=color:#a6e22e>      overcommit:</span><br></span><span class=token-line style=color:#f8f8f2><span class="token scalar string" style=color:#a6e22e>        memory: 1.0  # 显存不超卖</span><br></span><span class=token-line style=color:#f8f8f2><span class="token scalar string" style=color:#a6e22e>        cores: 1.2   # 算力可超卖20%</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label="Copy code to clipboard" title=Copy class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=33-hami-device-plugin>3.3 HAMi Device Plugin<a href=#33-hami-device-plugin class=hash-link aria-label="Direct link to 3.3 HAMi Device Plugin" title="Direct link to 3.3 HAMi Device Plugin">​</a></h3>
<p><strong>功能职责</strong>：</p>
<ul>
<li>发现节点上的<code>GPU</code>资源并向<code>Kubernetes</code>注册虚拟<code>GPU</code>资源</li>
<li>处理<code>Pod</code>的<code>GPU</code>资源分配请求</li>
<li>从调度结果的注解字段获取分配信息</li>
<li>将相应的<code>GPU</code>设备映射到容器，并注入配额环境变量</li>
</ul>
<p><strong>工作流程</strong>：</p>
<ol>
<li>
<p><strong>启动阶段</strong>：</p>
<ul>
<li>扫描节点<code>GPU</code>资源（型号、显存、数量等）</li>
<li>计算可分配的虚拟<code>GPU</code>数量</li>
<li>向<code>kubelet</code>注册设备资源</li>
</ul>
</li>
<li>
<p><strong>资源分配阶段</strong>：</p>
<ul>
<li>接收<code>kubelet</code>的<code>Allocate</code>请求</li>
<li>从<code>Pod</code>注解中读取调度器分配的<code>GPU</code>信息</li>
<li>生成环境变量（显存限制、算力配额等）</li>
<li>挂载<code>HAMi Core</code>库到容器</li>
<li>返回设备列表和环境变量</li>
</ul>
</li>
<li>
<p><strong>监控阶段</strong>：</p>
<ul>
<li>定期更新资源状态</li>
<li>上报<code>GPU</code>使用情况</li>
<li>处理设备异常情况</li>
</ul>
</li>
</ol>
<p><strong>资源注册示例</strong>：</p>
<div class="language-go codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#f8f8f2;--prism-background-color:#272822><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-go codeBlock_bY9V thin-scrollbar" style=color:#f8f8f2;background-color:#272822><code class=codeBlockLines_e6Vv><span class=token-line style=color:#f8f8f2><span class="token comment" style=color:#8292a2;font-style:italic>// HAMi Device Plugin注册的资源类型</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">resources </span><span class="token operator" style=color:#66d9ef>:=</span><span class="token plain"> </span><span class="token keyword" style=color:#66d9ef>map</span><span class="token punctuation" style=color:#f8f8f2>[</span><span class="token builtin" style=color:#e6db74>string</span><span class="token punctuation" style=color:#f8f8f2>]</span><span class="token builtin" style=color:#e6db74>int64</span><span class="token punctuation" style=color:#f8f8f2>{</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    </span><span class="token string" style=color:#a6e22e>"nvidia.com/gpu"</span><span class="token punctuation" style=color:#f8f8f2>:</span><span class="token plain">      </span><span class="token number" style=color:#ae81ff>8</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain">      </span><span class="token comment" style=color:#8292a2;font-style:italic>// 物理GPU数量</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    </span><span class="token string" style=color:#a6e22e>"nvidia.com/gpumem"</span><span class="token punctuation" style=color:#f8f8f2>:</span><span class="token plain">   </span><span class="token number" style=color:#ae81ff>192000</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain"> </span><span class="token comment" style=color:#8292a2;font-style:italic>// 总显存(MB)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    </span><span class="token string" style=color:#a6e22e>"nvidia.com/gpucores"</span><span class="token punctuation" style=color:#f8f8f2>:</span><span class="token plain"> </span><span class="token number" style=color:#ae81ff>800</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain">    </span><span class="token comment" style=color:#8292a2;font-style:italic>// 总算力(百分比*GPU数)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token punctuation" style=color:#f8f8f2>}</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label="Copy code to clipboard" title=Copy class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=34-hami-core-libvgpuso>3.4 HAMi Core (libvgpu.so)<a href=#34-hami-core-libvgpuso class=hash-link aria-label="Direct link to 3.4 HAMi Core (libvgpu.so)" title="Direct link to 3.4 HAMi Core (libvgpu.so)">​</a></h3>
<p><strong>功能职责</strong>：</p>
<ul>
<li>通过<code>LD_PRELOAD</code>机制劫持<code>CUDA Runtime API</code>调用</li>
<li>实现显存配额的硬隔离管理</li>
<li>提供算力使用的软限制功能</li>
<li>收集容器级别的<code>GPU</code>使用统计信息</li>
</ul>
<p><strong>工作原理</strong>：</p>
<p><code>HAMi Core</code>是一个动态链接库（<code>libvgpu.so</code>），通过<code>LD_PRELOAD</code>机制在应用程序启动时被加载。它拦截关键的<code>CUDA API</code>调用，在调用真正的<code>CUDA</code>函数之前进行资源检查和配额控制。</p>
<p><strong>核心拦截API</strong>：</p>
<ul>
<li><code>cudaMalloc</code> / <code>cudaFree</code>：显存分配与释放</li>
<li><code>cudaMemcpy</code> / <code>cudaMemcpyAsync</code>：显存拷贝操作</li>
<li><code>cudaLaunchKernel</code>：内核函数启动</li>
<li><code>cudaStreamCreate</code>：流管理</li>
</ul>
<p><strong>算力限制机制</strong>：</p>
<p>通过监控<code>kernel</code>启动频率和执行时间，实现算力使用的软限制。当容器的算力使用超过配额时，会延迟后续<code>kernel</code>的启动，从而控制整体算力占用。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id=4-hami原理分析>4 HAMi原理分析<a href=#4-hami原理分析 class=hash-link aria-label="Direct link to 4 HAMi原理分析" title="Direct link to 4 HAMi原理分析">​</a></h2>
<p><img decoding=async loading=lazy alt=HAMi原理分析 src=/assets/images/image-6-109c44b1a4cb18a8e39094d3baa8f129.png width=2480 height=678 class=img_ev3q></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=41-pod调�度阶段>4.1 Pod调度阶段<a href=#41-pod调度阶段 class=hash-link aria-label="Direct link to 4.1 Pod调度阶段" title="Direct link to 4.1 Pod调度阶段">​</a></h3>
<p>在<code>Kubernetes</code>集群中，<code>HAMi</code>扩展了<code>Pod</code>的调度与运行流程。整个过程可以分为以下几个阶段：</p>
<ol>
<li>
<p><strong><code>Pod</code>提交与<code>Mutating Webhook</code>拦截</strong></p>
<p>当用户提交一个带有<code>GPU</code>资源请求的<code>Pod</code>时，请求首先进入<code>API Server</code>。此时<code>Mutating Webhook</code>会拦截<code>Pod</code>对象，对其中的<code>GPU</code>资源声明进行补全和修正，例如：</p>
<ul>
<li>自动设置<code>schedulerName=hami-scheduler</code></li>
<li>注入<code>runtimeClassName=nvidia</code></li>
<li>为容器补齐必要的<code>GPU</code>资源字段和环境变量</li>
</ul>
<p>同时，<code>HAMi</code>还会通过<code>Pod</code>的环境变量和容器启动参数注入 <code>LD_PRELOAD</code>，确保在容器启动后，应用程序会自动加载<code>HAMi Core</code>的动态库。这样，就为后续的<code>GPU</code>调度与运行阶段预埋了“劫持” <code>CUDA API</code>的钩子。</p>
<p>这样，<code>Pod</code>被标记为交由<code>HAMi Scheduler</code>来处理，而不是默认调度器。</p>
</li>
<li>
<p><strong><code>HAMi Scheduler</code>调度</strong></p>
<p><code>Pod</code>被送入<code>HAMi Scheduler</code>的调度逻辑：</p>
<ul>
<li><strong>Filter</strong> <strong>阶段</strong>：解析<code>Pod</code>的资源需求，筛选出满足显存、算力等要求的候选节点。</li>
<li><strong>Score</strong> <strong>阶段</strong>：对候选节点进行多维度打分，包括资源利用率、碎片化程度、拓扑结构等。</li>
<li><strong>Bind</strong> <strong>阶段</strong>：选择最优节点，并将<code>Pod</code>绑定到该节点。</li>
</ul>
<p>这一流程保证了<code>Pod</code>能够在合适的<code>GPU</code>上运行，并提高集群整体的利用效率。</p>
</li>
<li>
<p><strong><code>HAMi Device Plugin</code>与环境变量注入</strong></p>
<p>当<code>Pod</code>被分配到节点后，<code>HAMi Device Plugin</code>接管了容器与<code>GPU</code>的连接过程。与 <code>NVIDIA</code>官方插件相比，<code>HAMi Device Plugin</code>不仅保留了驱动与API的兼容性，还新增了以下能力：</p>
<ul>
<li>为容器注入显存、算力、任务优先级等控制参数</li>
<li>挂载<code>HAMi Core</code>库，实现对<code>GPU</code>的虚拟化控制</li>
<li>精细化配置<code>CUDA_MEM_LIMIT</code>、<code>CUDA_CORE_LIMIT</code>等环境变量，实现资源隔离与共享</li>
</ul>
<p>最终，<code>Pod</code>内部的应用感知到的<code>GPU</code>是一个受控的虚拟化<code>GPU</code>，既保证了隔离性，也支持资源共享。</p>
</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=42-pod持续运行阶段>4.2 Pod持续运行阶段<a href=#42-pod持续运行阶段 class=hash-link aria-label="Direct link to 4.2 Pod持续运行阶段" title="Direct link to 4.2 Pod持续运行阶段">​</a></h3>
<p>在<code>Pod</code>启动后，<code>HAMi Core</code>通过<code>Linux</code>的<code>LD_PRELOAD</code>机制直接“嵌入”到应用进程中。</p>
<p><code>LD_PRELOAD</code>是<code>Linux</code>动态链接器的一种功能，允许开发者在运行时指定一个自定义的动态链接库，让它在系统标准库之前被加载。这时程序里调用的函数（比如<code>malloc</code>、<code>open</code>，或者在<code>CUDA</code>应用里调用的<code>cudaMalloc</code>）就会先经过自定义库的实现，从而实现“函数劫持”（<code>interception</code>）。<code>HAMi Core</code>正是利用这一点：它通过 <code>LD_PRELOAD</code> 注入一个定制的库到容器应用中，这个库拦截了关键的<code>CUDA Runtime API</code>（如<code>cudaMalloc</code>）。</p>
<p>关键工作流程如下：</p>
<ol>
<li><strong>拦截调用</strong>：当应用尝试调用<code>cudaMalloc</code>申请显存时，请求首先会进入<code>HAMi Core</code>的拦截逻辑，而不是直接进入<code>CUDA runtime API</code>。</li>
<li><strong>资源校验</strong>：<code>HAMi Core</code>会读取<code>Pod</code>下发的<code>GPU</code>配置（例如显存上限），检查本次申请是否超限。</li>
<li><strong>严格控制</strong>：若超出限制，则直接拒绝分配并返回错误码；若合法，则放行并记录分配情况。</li>
<li><strong>持续监管</strong>：所有显存分配和释放都会经过这种拦截校验机制，形成一个完整的<code>Pod</code>级“资源沙盒”。</li>
</ol>
<p>对比<code>NVIDIA MPS</code>仅能在<code>GPU</code>核心算力（<code>SM</code>）维度做时间片调度不同，<code>HAMi Core</code>能进一步在显存维度上做细粒度隔离。这样即便某个应用因为显存泄漏或异常崩溃，也不会像<code>MPS</code>下那样拖垮同节点的其他应用。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id=5-参考资料>5. 参考资料<a href=#5-参考资料 class=hash-link aria-label="Direct link to 5. 参考资料" title="Direct link to 5. 参考资料">​</a></h2>
<ul>
<li><a href=https://github.com/Project-HAMi/HAMi target=_blank rel="noopener noreferrer">https://github.com/Project-HAMi/HAMi</a></li>
<li><a href=https://dynamia.ai/ target=_blank rel="noopener noreferrer">https://dynamia.ai/</a></li>
</ul></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href=/ai/vgpu-survey><div class=pagination-nav__sublabel>Previous</div><div class=pagination-nav__label>vGPU方案调研</div></a><a class="pagination-nav__link pagination-nav__link--next" href=/ai/common-acceleration-cards><div class=pagination-nav__sublabel>Next</div><div class=pagination-nav__label>常见智算加速卡汇总</div></a></nav><div class=docusaurus-mt-lg></div></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href=#1-hami项目概述 class="table-of-contents__link toc-highlight">1. HAMi项目概述</a><li><a href=#2-hami的优势与局限 class="table-of-contents__link toc-highlight">2. HAMi的优势与局限</a><li><a href=#3-hami整体架构 class="table-of-contents__link toc-highlight">3 HAMi整体架构</a><ul><li><a href=#31-hami-mutatingwebhook class="table-of-contents__link toc-highlight">3.1 HAMi MutatingWebhook</a><li><a href=#32-hami-scheduler-extender class="table-of-contents__link toc-highlight">3.2 HAMi Scheduler Extender</a><li><a href=#33-hami-device-plugin class="table-of-contents__link toc-highlight">3.3 HAMi Device Plugin</a><li><a href=#34-hami-core-libvgpuso class="table-of-contents__link toc-highlight">3.4 HAMi Core (libvgpu.so)</a></ul><li><a href=#4-hami原理分析 class="table-of-contents__link toc-highlight">4 HAMi原理分析</a><ul><li><a href=#41-pod调度阶段 class="table-of-contents__link toc-highlight">4.1 Pod调度阶段</a><li><a href=#42-pod持续运行阶段 class="table-of-contents__link toc-highlight">4.2 Pod持续运行阶段</a></ul><li><a href=#5-参考资料 class="table-of-contents__link toc-highlight">5. 参考资料</a></ul></div></div></div></div></main></div></div></div><footer class=footer><div class="container container-fluid"><div class="footer__bottom text--center"><div class=footer__copyright>Copyright 2025 johng.cn</div></div></div></footer></div>