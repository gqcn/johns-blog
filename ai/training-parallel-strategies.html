<!doctype html><html lang=en dir=ltr class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-docs/AI技术/训练微调/AI模型训练并行策略介绍" data-has-hydrated=false><meta charset=UTF-8><meta name=generator content="Docusaurus v3.6.3"><title data-rh=true>AI模型训练并行策略介绍 | John's Blog</title><meta data-rh=true name=viewport content="width=device-width,initial-scale=1.0"><meta data-rh=true name=twitter:card content=summary_large_image><meta data-rh=true property=og:url content=https://johng.cn/ai/training-parallel-strategies><meta data-rh=true property=og:locale content=en><meta data-rh=true name=docusaurus_locale content=en><meta data-rh=true name=docsearch:language content=en><meta data-rh=true name=author content="John Guo"><meta data-rh=true property=og:image content=https://johng.cn/img/favicon.png><meta data-rh=true name=docusaurus_version content=current><meta data-rh=true name=docusaurus_tag content=docs-default-current><meta data-rh=true name=docsearch:version content=current><meta data-rh=true name=docsearch:docusaurus_tag content=docs-default-current><meta data-rh=true property=og:title content="AI模型训练并行策略介绍 | John's Blog"><meta data-rh=true name=description content=深入讲解AI大模型训练中的各种并行策略，包括数据并行、模型并行、流水线并行和张量并行的原理、适用场景和实现方式，帮助技术小白理解分布式训练的核心概念><meta data-rh=true property=og:description content=深入讲解AI大模型训练中的各种并行策略，包括数据并行、模型并行、流水线并行和张量并行的原理、适用场景和实现方式，帮助技术小白理解分布式训练的核心概念><meta data-rh=true name=keywords content="AI训练,并行策略,数据并行,模型并行,流水线并行,张量并行,Data Parallelism,Model Parallelism,Pipeline Parallelism,Tensor Parallelism,分布式训练,梯度同步,AllReduce,GPU训练,深度学习,大模型训练"><link data-rh=true rel=icon href=/img/favicon.ico><link data-rh=true rel=canonical href=https://johng.cn/ai/training-parallel-strategies><link data-rh=true rel=alternate href=https://johng.cn/ai/training-parallel-strategies hreflang=en><link data-rh=true rel=alternate href=https://johng.cn/ai/training-parallel-strategies hreflang=x-default><link data-rh=true rel=preconnect href=https://XGS1CPQERK-dsn.algolia.net crossorigin><link rel=alternate type=application/rss+xml href=/blog/rss.xml title="John's Blog RSS Feed"><link rel=alternate type=application/atom+xml href=/blog/atom.xml title="John's Blog Atom Feed"><link rel=search type=application/opensearchdescription+xml title="John's Blog" href=/opensearch.xml><script src=https://hm.baidu.com/hm.js?6b4ae23dc83ee5efe875b7172af6c7c1 async></script><link rel=stylesheet href=/assets/css/styles.2f56d3c4.css><script src=/assets/js/runtime~main.ee10e55f.js defer></script><script src=/assets/js/main.139bc18f.js defer></script><body class=navigation-with-keyboard><script>!function(){var t,e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t=null!==e?e:"light",document.documentElement.setAttribute("data-theme",t)}(),function(){try{for(var[t,e]of new URLSearchParams(window.location.search).entries())if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id=__docusaurus><div role=region aria-label="Skip to main content"><a class=skipToContent_fXgn href=#__docusaurus_skipToContent_fallback>Skip to main content</a></div><nav aria-label=Main class="navbar navbar--fixed-top"><div class=navbar__inner><div class=navbar__items><button aria-label="Toggle navigation bar" aria-expanded=false class="navbar__toggle clean-btn" type=button><svg width=30 height=30 viewBox="0 0 30 30" aria-hidden=true><path stroke=currentColor stroke-linecap=round stroke-miterlimit=10 stroke-width=2 d="M4 7h22M4 15h22M4 23h22"/></svg></button><a class=navbar__brand href=/><b class="navbar__title text--truncate">John's Blog</b></a><a aria-current=page class="navbar__item navbar__link navbar__link--active" href=/ai>AI技术</a><a class="navbar__item navbar__link" href=/cloud-native>云原生</a><a class="navbar__item navbar__link" href=/notes>日常笔记</a><a class="navbar__item navbar__link" href=/programming>开发语言</a><a class="navbar__item navbar__link" href=/architecture>技术架构</a><a class="navbar__item navbar__link" href=/observability>可观测性</a><a class="navbar__item navbar__link" href=/life>生活笔记</a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href=/aboutme>关于我</a><a class="navbar__item navbar__link" href=/blog>博客</a><a href=https://goframe.org/ target=_blank rel="noopener noreferrer" class="navbar__item navbar__link header-goframe-link"></a><a href=https://github.com/gqcn target=_blank rel="noopener noreferrer" class="navbar__item navbar__link header-github-link"></a><div class=navbarSearchContainer_Bca1><button type=button class="DocSearch DocSearch-Button" aria-label="Search (Command+K)"><span class=DocSearch-Button-Container><svg width=20 height=20 class=DocSearch-Search-Icon viewBox="0 0 20 20" aria-hidden=true><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke=currentColor fill=none fill-rule=evenodd stroke-linecap=round stroke-linejoin=round /></svg><span class=DocSearch-Button-Placeholder>Search</span></span><span class=DocSearch-Button-Keys></span></button></div></div></div><div role=presentation class=navbar-sidebar__backdrop></div></nav><div id=__docusaurus_skipToContent_fallback class="main-wrapper mainWrapper_z2l0"><div class=docsWrapper_hBAB><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type=button></button><div class=docRoot_UBD9><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class=sidebarViewport_aRkj><div class=sidebar_njMd><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--active" href=/ai>AI技术</a><button aria-label="Collapse sidebar category 'AI技术'" aria-expanded=true type=button class="clean-btn menu__caret"></button></div><ul style=display:block;overflow:visible;height:auto class=menu__list><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" tabindex=0 href=/ai/agents>智能体</a><button aria-label="Expand sidebar category '智能体'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" tabindex=0 href=/ai/app>应用开发</a><button aria-label="Expand sidebar category '应用开发'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" tabindex=0 href=/ai/inference>推理服务</a><button aria-label="Expand sidebar category '推理服务'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--active" tabindex=0 href=/ai/training-fine-tuning>训练微调</a><button aria-label="Collapse sidebar category '训练微调'" aria-expanded=true type=button class="clean-btn menu__caret"></button></div><ul style=display:block;overflow:visible;height:auto class=menu__list><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" tabindex=0 href=/ai/training-platform>开发训练平台</a><button aria-label="Expand sidebar category '开发训练平台'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" tabindex=0 href=/ai/kubeflow-trainer>Kubeflow Trainer</a><button aria-label="Expand sidebar category 'Kubeflow Trainer'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/ai/machine-learning-fundamentals>AI模型与机器学习</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/ai/training>AI模型训练技术详解</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/ai/fine-tuning>AI模型微调技术详解</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current=page tabindex=0 href=/ai/training-parallel-strategies>AI模型训练并行策略介绍</a></ul><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" tabindex=0 href=/ai/model-development>模型开发</a><button aria-label="Expand sidebar category '模型开发'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" tabindex=0 href=/ai/infra>基础架构</a><button aria-label="Expand sidebar category '基础架构'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" tabindex=0 href=/ai/basic>入门知识</a><button aria-label="Expand sidebar category '入门知识'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div></ul><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/cloud-native>云原生</a><button aria-label="Expand sidebar category '云原生'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/notes>日常笔记</a><button aria-label="Expand sidebar category '日常笔记'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/programming>开发语言</a><button aria-label="Expand sidebar category '开发语言'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/architecture>技术架构</a><button aria-label="Expand sidebar category '技术架构'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/management>技术管理</a><button aria-label="Expand sidebar category '技术管理'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/observability>可观测性</a><button aria-label="Expand sidebar category '可观测性'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/database-and-middleware>数据库与中间件</a><button aria-label="Expand sidebar category '数据库与中间件'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/operating-systems-and-networks>操作系统和网络</a><button aria-label="Expand sidebar category '操作系统和网络'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/life>生活笔记</a><button aria-label="Expand sidebar category '生活笔记'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div></ul></nav></div></div></aside><main class=docMainContainer_TBSr><div class="container padding-top--md padding-bottom--lg"><div class=row><div class="col docItemCol_VOVn"><div class=docItemContainer_Djhp><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label=Breadcrumbs><ul class=breadcrumbs itemscope itemtype=https://schema.org/BreadcrumbList><li class=breadcrumbs__item><a aria-label="Home page" class=breadcrumbs__link href=/><svg viewBox="0 0 24 24" class=breadcrumbHomeIcon_YNFT><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill=currentColor /></svg></a><li itemscope itemprop=itemListElement itemtype=https://schema.org/ListItem class=breadcrumbs__item><a class=breadcrumbs__link itemprop=item href=/ai><span itemprop=name>AI技术</span></a><meta itemprop=position content=1><li itemscope itemprop=itemListElement itemtype=https://schema.org/ListItem class=breadcrumbs__item><a class=breadcrumbs__link itemprop=item href=/ai/training-fine-tuning><span itemprop=name>训练微调</span></a><meta itemprop=position content=2><li itemscope itemprop=itemListElement itemtype=https://schema.org/ListItem class="breadcrumbs__item breadcrumbs__item--active"><span class=breadcrumbs__link itemprop=name>AI模型训练并行策略介绍</span><meta itemprop=position content=3></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type=button class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><p>在<code>AI</code>大模型训练中，单个<code>GPU</code>的计算能力和显存往往无法满足需求，需要使用多个<code>GPU</code>协同工作。并行策略就是如何合理地将训练任务分配到多个<code>GPU</code>上的方法。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id=并行策略分类对比>并行策略分类对比<a href=#并行策略分类对比 class=hash-link aria-label="Direct link to 并行策略分类对比" title="Direct link to 并行策略分类对比">​</a></h2>
<table><thead><tr><th>并行策略<th>核心原理<th>简单理解<th>适用场景<tbody><tr><td><strong>数据并行</strong> <code>Data Parallelism (DP)</code><td>每个<code>GPU</code>持有完整模型，处理不同的数据分片<td>就像4个厨师，每人拿着相同的菜谱（模型），同时做不同的菜（数据），最后交流心得（同步梯度）<td>模型较小，数据量大<tr><td><strong>模型并行</strong> <code>Model Parallelism (MP)</code><td>将模型的不同层分配到不同<code>GPU</code><td>就像流水线，第1个工人加工零件A（第1层），传给第2个工人加工零件B（第2层）<td>模型超大，单<code>GPU</code>装不下<tr><td><strong>流水线并行</strong> <code>Pipeline Parallelism (PP)</code><td>模型并行+微批次流水线优化<td>改进版流水线：第1批数据在第1个工人处理时，第2批数据同时进入第2个工人<td>大模型+想提高效率<tr><td><strong>张量并行</strong> <code>Tensor Parallelism (TP)</code><td>将单个神经网络层的计算拆分到多个<code>GPU</code><td>就像搬一个大箱子，几个人同时抬不同部位<td>单层计算量特别大</table>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id=数据并行详解>数据并行详解<a href=#数据并行详解 class=hash-link aria-label="Direct link to 数据并行详解" title="Direct link to 数据并行详解">​</a></h2>
<p>数据并行是最常用的并行策略，下面通过图示和术语表来深入理解：</p>
<!-- -->
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=核心术语>核心术语<a href=#核心术语 class=hash-link aria-label="Direct link to 核心术语" title="Direct link to 核心术语">​</a></h3>
<table><thead><tr><th>术语<th>英文<th>定义<th>通俗理解<th>在数据并行中的作用<tbody><tr><td><strong>数据分片</strong><td><code>Data Sharding</code><td>将完整训练数据集切分成多份，每份分配给一个<code>GPU</code><td>把一本书的页码平均分给4个人同时阅读<td>图中<code>GPU 0/1/2/3</code>各自处理不同"数据分片"，避免重复计算相同数据<tr><td><strong>模型副本</strong><td><code>Model Replica</code><td>每个<code>GPU</code>上存储的完整模型拷贝<td>每个人手里都有一本相同的菜谱（模型）<td>确保每个<code>GPU</code>都能独立完成前向和反向传播计算<tr><td><strong>前向传播</strong><td><code>Forward Pass</code><td>数据从输入层经过各层计算到输出层的过程<td>按照菜谱一步步做菜的过程<td>每个<code>GPU</code>独立用自己的数据分片计算输出，互不干扰<tr><td><strong>反向传播</strong><td><code>Backward Pass</code><td>从输出层计算损失，逐层计算梯度传回输入层<td>做完菜后总结每一步的改进空间<td>每个<code>GPU</code>独立计算自己数据分片产生的梯度<tr><td><strong>梯度</strong><td><code>Gradient</code><td>损失函数对模型参数的导数（记为<code>grad_W</code>），指示参数更新方向<td>告诉你模型参数应该往哪个方向调整、调多少<td>每个<code>GPU</code>计算出"本地梯度"，需要同步后才能更新模型<tr><td><strong>梯度同步</strong><td><code>Gradient Synchronization</code><td>将所有<code>GPU</code>的梯度汇总求平均（或求和），让所有<code>GPU</code>得到相同的梯度<td>4个厨师分别做菜后，交流心得并达成一致意见<td><strong>数据并行的关键步骤</strong>：确保所有<code>GPU</code>用相同的梯度更新模型，保持模型一致性<tr><td><strong>AllReduce</strong><td><code>AllReduce</code><td>一种集合通信算法，高效地完成"所有进程的数据求和并广播给所有进程"<td>就像开会时统计大家的意见，算出平均值，再告诉每个人<td>实现梯度同步的高效通信方式，比逐个传递快得多<tr><td><strong>参数更新</strong><td><code>Parameter Update</code><td>使用梯度更新模型参数：<code>W_new = W_old - 学习率 × grad_W</code><td>根据改进建议（梯度）修改菜谱（模型）<td>同步后所有<code>GPU</code>用相同梯度更新参数，确保模型一致<tr><td><strong>DistributedSampler</strong><td><code>Distributed Sampler</code><td><code>PyTorch</code>提供的数据采样器，确保各<code>GPU</code>取到不重复的数据分片<td>自动分配工作的调度员，保证4个人不会重复读同一页书<td>训练时必须使用，否则所有<code>GPU</code>会处理相同数据导致浪费</table>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=完整训练流程以4个gpu为例>完整训练流程（以4个GPU为例）<a href=#完整训练流程以4个gpu为例 class=hash-link aria-label="Direct link to 完整训练流程（以4个GPU为例）" title="Direct link to 完整训练流程（以4个GPU为例）">​</a></h3>
<ol>
<li>
<p><strong>初始化阶段</strong>：</p>
<ul>
<li><code>4</code>个<code>GPU</code>各自加载相同的模型副本（模型参数完全一致）</li>
<li>准备好完整的训练数据集</li>
</ul>
</li>
<li>
<p><strong>数据分片</strong>：</p>
<ul>
<li>使用<code>DistributedSampler</code>将一个批次（例如<code>256</code>张图片）均匀分成<code>4</code>份</li>
<li><code>GPU 0</code>处理图片<code>1-64</code>，<code>GPU 1</code>处理图片<code>65-128</code>，以此类推</li>
</ul>
</li>
<li>
<p><strong>前向传播</strong>（各GPU独立计算）：</p>
<ul>
<li>每个<code>GPU</code>用自己的<code>64</code>张图片，通过模型计算得到预测结果</li>
<li>这一步<strong>不需要通信</strong>，各<code>GPU</code>并行执行</li>
</ul>
</li>
<li>
<p><strong>反向传播</strong>（各GPU独立计算梯度）：</p>
<ul>
<li>每个<code>GPU</code>计算损失，并反向传播得到本地梯度</li>
<li><code>GPU 0</code>得到梯度<code>grad_W0</code>，<code>GPU 1</code>得到<code>grad_W1</code>，<code>GPU 2</code>得到<code>grad_W2</code>，<code>GPU 3</code>得到<code>grad_W3</code></li>
</ul>
</li>
<li>
<p><strong>梯度同步</strong>（关键通信步骤）：</p>
<ul>
<li>通过<code>AllReduce</code>操作，所有<code>GPU</code>交换梯度并求平均</li>
<li>最终所有<code>GPU</code>得到相同的平均梯度：<code>grad_W = (grad_W0 + grad_W1 + grad_W2 + grad_W3) / 4</code></li>
</ul>
</li>
<li>
<p><strong>参数更新</strong>（各GPU独立执行）：</p>
<ul>
<li>每个<code>GPU</code>用相同的平均梯度更新自己的模型参数</li>
<li>由于起点相同（上一步参数一致）、更新量相同（同步后的梯度一致），所以更新后参数仍然一致</li>
</ul>
</li>
<li>
<p><strong>重复步骤2-6</strong>，直到训练完成</p>
</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=为什么需要梯度同步>为什么需要梯度同步？<a href=#为什么需要梯度同步 class=hash-link aria-label="Direct link to 为什么需要梯度同步？" title="Direct link to 为什么需要梯度同步？">​</a></h3>
<p>假设没有梯度同步，会发生什么：</p>
<ul>
<li><code>GPU 0</code>看到猫的图片，学到"有毛→是猫"</li>
<li><code>GPU 1</code>看到狗的图片，学到"有毛→是狗"</li>
<li>两个<code>GPU</code>的模型会朝不同方向更新，导致模型"分裂"</li>
</ul>
<p>梯度同步让所有<code>GPU</code>看到全局信息：</p>
<ul>
<li>同步后梯度 = "有毛→50%是猫 + 50%是狗"</li>
<li>所有<code>GPU</code>用这个全局视角更新模型，保持一致性</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id=其他并行策略>其他并行策略<a href=#其他并行策略 class=hash-link aria-label="Direct link to 其他并行策略" title="Direct link to 其他并行策略">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=模型并行model-parallelism>模型并行（Model Parallelism）<a href=#模型并行model-parallelism class=hash-link aria-label="Direct link to 模型并行（Model Parallelism）" title="Direct link to 模型并行（Model Parallelism）">​</a></h3>
<ul>
<li><strong>原理</strong>：将模型的不同层分配到不同<code>GPU</code>，数据依次流过各层</li>
<li><strong>示例</strong>：4层神经网络，第1层在<code>GPU 0</code>，第2层在<code>GPU 1</code>...</li>
<li><strong>适用场景</strong>：模型太大（如<code>GPT-3</code>有1750亿参数），单个<code>GPU</code>显存装不下</li>
<li><strong>优势</strong>：突破单卡显存限制，可以训练超大模型</li>
<li><strong>缺点</strong>：同一时刻只有一个<code>GPU</code>在工作，其他<code>GPU</code>在等待，利用率低</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=流水线并行pipeline-parallelism>流水线并行（Pipeline Parallelism）<a href=#流水线并行pipeline-parallelism class=hash-link aria-label="Direct link to 流水线并行（Pipeline Parallelism）" title="Direct link to 流水线并行（Pipeline Parallelism）">​</a></h3>
<ul>
<li><strong>原理</strong>：模型并行的优化版，将数据切分成多个小批次（微批次），流水线式处理</li>
<li><strong>示例</strong>：当微批次1在<code>GPU 1</code>处理时，微批次2可以进入<code>GPU 0</code>，减少空闲</li>
<li><strong>适用场景</strong>：大模型+需要提高<code>GPU</code>利用率</li>
<li><strong>优势</strong>：减少<code>GPU</code>空闲时间，提高资源利用率</li>
<li><strong>实现</strong>：如<code>DeepSpeed</code>、<code>Megatron-LM</code>等框架</li>
</ul>
<p><strong>流水线示意</strong>：</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#f8f8f2;--prism-background-color:#272822><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-text codeBlock_bY9V thin-scrollbar" style=color:#f8f8f2;background-color:#272822><code class=codeBlockLines_e6Vv><span class=token-line style=color:#f8f8f2><span class="token plain">时间 t1: [GPU0处理batch1-layer1] [GPU1空闲]         [GPU2空闲]         [GPU3空闲]</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">时间 t2: [GPU0处理batch2-layer1] [GPU1处理batch1-layer2] [GPU2空闲]         [GPU3空闲]</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">时间 t3: [GPU0处理batch3-layer1] [GPU1处理batch2-layer2] [GPU2处理batch1-layer3] [GPU3空闲]</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">时间 t4: [GPU0处理batch4-layer1] [GPU1处理batch3-layer2] [GPU2处理batch2-layer3] [GPU3处理batch1-layer4]</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label="Copy code to clipboard" title=Copy class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=张量并行tensor-parallelism>张量并行（Tensor Parallelism）<a href=#张量并行tensor-parallelism class=hash-link aria-label="Direct link to 张量并行（Tensor Parallelism）" title="Direct link to 张量并行（Tensor Parallelism）">​</a></h3>
<ul>
<li><strong>原理</strong>：将单个网络层的矩阵运算拆分到多个<code>GPU</code>并行计算</li>
<li><strong>示例</strong>：一个<code>[1024, 1024]</code>的矩阵乘法，拆成<code>4</code>个<code>[1024, 256]</code>的小矩阵在<code>4</code>个<code>GPU</code>上同时计算</li>
<li><strong>适用场景</strong>：超大的<code>Transformer</code>模型，单个注意力层计算量巨大</li>
<li><strong>优势</strong>：层内并行，减少等待时间</li>
<li><strong>实现</strong>：如<code>Megatron-LM</code>对<code>GPT</code>模型的张量并行实现</li>
</ul>
<p><strong>矩阵分割示例</strong>：</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#f8f8f2;--prism-background-color:#272822><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-text codeBlock_bY9V thin-scrollbar" style=color:#f8f8f2;background-color:#272822><code class=codeBlockLines_e6Vv><span class=token-line style=color:#f8f8f2><span class="token plain">原始矩阵乘法: [M × K] × [K × N] = [M × N]</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain" style=display:inline-block></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">张量并行（按列切分）:</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">GPU 0: [M × K] × [K × N/4] = [M × N/4]</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">GPU 1: [M × K] × [K × N/4] = [M × N/4]</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">GPU 2: [M × K] × [K × N/4] = [M × N/4]</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">GPU 3: [M × K] × [K × N/4] = [M × N/4]</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain" style=display:inline-block></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">最后拼接: [M × N/4] + [M × N/4] + [M × N/4] + [M × N/4] = [M × N]</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label="Copy code to clipboard" title=Copy class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id=混合并行策略>混合并行策略<a href=#混合并行策略 class=hash-link aria-label="Direct link to 混合并行策略" title="Direct link to 混合并行策略">​</a></h2>
<p>在实际的大模型训练中，通常会<strong>组合使用</strong>多种并行策略以获得最佳性能：</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=2维并行数据并行--模型并行>2维并行：数据并行 + 模型并行<a href=#2维并行数据并行--模型并行 class=hash-link aria-label="Direct link to 2维并行：数据并行 + 模型并行" title="Direct link to 2维并行：数据并行 + 模型并行">​</a></h3>
<p>适用于中大型模型训练：</p>
<ul>
<li><strong>场景</strong>：8节点，每节点8卡，共64卡</li>
<li><strong>策略</strong>：节点间数据并行（8路），节点内模型并行（8层）</li>
<li><strong>优势</strong>：既能利用数据并行的高效性，又能突破单卡显存限制</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=3维并行数据并行--张量并行--流水线并行>3维并行：数据并行 + 张量并行 + 流水线并行<a href=#3维并行数据并行--张量并行--流水线并行 class=hash-link aria-label="Direct link to 3维并行：数据并行 + 张量并行 + 流水线并行" title="Direct link to 3维并行：数据并行 + 张量并行 + 流水线并行">​</a></h3>
<p>适用于超大模型训练（如GPT-3）：</p>
<ul>
<li><strong>数据并行</strong>：跨多个节点复制模型</li>
<li><strong>流水线并行</strong>：将模型垂直切分为多个stage</li>
<li><strong>张量并行</strong>：在每个stage内，将层水平切分</li>
</ul>
<p><strong>示例配置（GPT-3训练）</strong>：</p>
<ul>
<li>数据并行度：8</li>
<li>流水线并行度：16</li>
<li>张量并行度：8</li>
<li>总GPU数：8 × 16 × 8 = 1024</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id=通信开销对比>通信开销对比<a href=#通信开销对比 class=hash-link aria-label="Direct link to 通信开销对比" title="Direct link to 通信开销对比">​</a></h2>
<table><thead><tr><th>并行策略<th>通信频率<th>通信数据量<th>带宽需求<th>延迟敏感度<tbody><tr><td>数据并行<td>每个<code>batch</code><td>梯度大小 ≈ 模型大小<td>高<td>中<tr><td>模型并行<td>每层前向/反向<td>激活值大小<td>中<td>高<tr><td>流水线并行<td>每个微批次<td>激活值大小<td>低<td>中<tr><td>张量并行<td>每层内部<td>中间结果<td>极高<td>极高</table>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id=参考资料>参考资料<a href=#参考资料 class=hash-link aria-label="Direct link to 参考资料" title="Direct link to 参考资料">​</a></h2>
<ul>
<li><a href=https://arxiv.org/abs/1909.08053 target=_blank rel="noopener noreferrer">Megatron-LM: Training Multi-Billion Parameter Language Models</a></li>
<li><a href=https://arxiv.org/abs/1811.06965 target=_blank rel="noopener noreferrer">GPipe: Efficient Training of Giant Neural Networks</a></li>
<li><a href=https://arxiv.org/abs/1910.02054 target=_blank rel="noopener noreferrer">ZeRO: Memory Optimizations Toward Training Trillion Parameter Models</a></li>
<li><a href=https://pytorch.org/tutorials/beginner/dist_overview.html target=_blank rel="noopener noreferrer">PyTorch Distributed Overview</a></li>
<li><a href=https://www.deepspeed.ai/ target=_blank rel="noopener noreferrer">DeepSpeed Documentation</a></li>
</ul></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href=/ai/fine-tuning><div class=pagination-nav__sublabel>Previous</div><div class=pagination-nav__label>AI模型微调技术详解</div></a><a class="pagination-nav__link pagination-nav__link--next" href=/ai/model-development><div class=pagination-nav__sublabel>Next</div><div class=pagination-nav__label>模型开发</div></a></nav><div class=docusaurus-mt-lg></div></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href=#并行策略分类对比 class="table-of-contents__link toc-highlight">并行策略分类对比</a><li><a href=#数据并行详解 class="table-of-contents__link toc-highlight">数据并行详解</a><ul><li><a href=#核心术语 class="table-of-contents__link toc-highlight">核心术语</a><li><a href=#完整训练流程以4个gpu为例 class="table-of-contents__link toc-highlight">完整训练流程（以4个GPU为例）</a><li><a href=#为什么需要梯度同步 class="table-of-contents__link toc-highlight">为什么需要梯度同步？</a></ul><li><a href=#其他并行策略 class="table-of-contents__link toc-highlight">其他并行策略</a><ul><li><a href=#模型并行model-parallelism class="table-of-contents__link toc-highlight">模型并行（Model Parallelism）</a><li><a href=#流水线并行pipeline-parallelism class="table-of-contents__link toc-highlight">流水线并行（Pipeline Parallelism）</a><li><a href=#张量并行tensor-parallelism class="table-of-contents__link toc-highlight">张量并行（Tensor Parallelism）</a></ul><li><a href=#混合并行策略 class="table-of-contents__link toc-highlight">混合并行策略</a><ul><li><a href=#2维并行数据并行--模型并行 class="table-of-contents__link toc-highlight">2维并行：数据并行 + 模型并行</a><li><a href=#3维并行数据并行--张量并行--流水线并行 class="table-of-contents__link toc-highlight">3维并行：数据并行 + 张量并行 + 流水线并行</a></ul><li><a href=#通信开销对比 class="table-of-contents__link toc-highlight">通信开销对比</a><li><a href=#参考资料 class="table-of-contents__link toc-highlight">参考资料</a></ul></div></div></div></div></main></div></div></div><footer class=footer><div class="container container-fluid"><div class="footer__bottom text--center"><div class=footer__copyright>Copyright 2026 johng.cn</div></div></div></footer></div>