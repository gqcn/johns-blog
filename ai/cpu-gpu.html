<!doctype html><html lang=en dir=ltr class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-docs/AI技术/基础架构/CPU&GPU架构差异及AI场景中的应用" data-has-hydrated=false><meta charset=UTF-8><meta name=generator content="Docusaurus v3.6.3"><title data-rh=true>CPU&GPU架构差异及AI场景中的应用 | John's Blog</title><meta data-rh=true name=viewport content="width=device-width,initial-scale=1.0"><meta data-rh=true name=twitter:card content=summary_large_image><meta data-rh=true property=og:url content=https://johng.cn/ai/cpu-gpu><meta data-rh=true property=og:locale content=en><meta data-rh=true name=docusaurus_locale content=en><meta data-rh=true name=docsearch:language content=en><meta data-rh=true name=author content="John Guo"><meta data-rh=true property=og:image content=https://johng.cn/img/favicon.png><meta data-rh=true name=docusaurus_version content=current><meta data-rh=true name=docusaurus_tag content=docs-default-current><meta data-rh=true name=docsearch:version content=current><meta data-rh=true name=docsearch:docusaurus_tag content=docs-default-current><meta data-rh=true property=og:title content="CPU&GPU架构差异及AI场景中的应用 | John's Blog"><meta data-rh=true name=description content=深入解析CPU和GPU在架构设计上的本质区别，阐述为什么AI模型训练和推理需要大量使用GPU而非CPU。从缓存结构、控制单元、运算核心三个维度对比两者设计理念：CPU追求低延迟和复杂逻辑处理，GPU追求高吞吐量和大规模数据并行。详解异构计算模式下CPU与GPU的协同工作机制，为理解AI基础设施提供硬件架构基础。><meta data-rh=true property=og:description content=深入解析CPU和GPU在架构设计上的本质区别，阐述为什么AI模型训练和推理需要大量使用GPU而非CPU。从缓存结构、控制单元、运算核心三个维度对比两者设计理念：CPU追求低延迟和复杂逻辑处理，GPU追求高吞吐量和大规模数据并行。详解异构计算模式下CPU与GPU的协同工作机制，为理解AI基础设施提供硬件架构基础。><meta data-rh=true name=keywords content=CPU,GPU,CPU架构,GPU架构,并行计算,AI训练,深度学习,神经网络训练,矩阵运算,异构计算,CUDA,高吞吐量,低延迟,缓存架构,分支预测,流水线,算力,AI推理,模型训练,GPU加速><link data-rh=true rel=icon href=/img/favicon.ico><link data-rh=true rel=canonical href=https://johng.cn/ai/cpu-gpu><link data-rh=true rel=alternate href=https://johng.cn/ai/cpu-gpu hreflang=en><link data-rh=true rel=alternate href=https://johng.cn/ai/cpu-gpu hreflang=x-default><link data-rh=true rel=preconnect href=https://XGS1CPQERK-dsn.algolia.net crossorigin><link rel=alternate type=application/rss+xml href=/blog/rss.xml title="John's Blog RSS Feed"><link rel=alternate type=application/atom+xml href=/blog/atom.xml title="John's Blog Atom Feed"><link rel=search type=application/opensearchdescription+xml title="John's Blog" href=/opensearch.xml><script src=https://hm.baidu.com/hm.js?6b4ae23dc83ee5efe875b7172af6c7c1 async></script><link rel=stylesheet href=/assets/css/styles.baba4b83.css><script src=/assets/js/runtime~main.3215f30b.js defer></script><script src=/assets/js/main.c540a909.js defer></script><body class=navigation-with-keyboard><script>!function(){var t,e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t=null!==e?e:"light",document.documentElement.setAttribute("data-theme",t)}(),function(){try{for(var[t,e]of new URLSearchParams(window.location.search).entries())if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id=__docusaurus><div role=region aria-label="Skip to main content"><a class=skipToContent_fXgn href=#__docusaurus_skipToContent_fallback>Skip to main content</a></div><nav aria-label=Main class="navbar navbar--fixed-top"><div class=navbar__inner><div class=navbar__items><button aria-label="Toggle navigation bar" aria-expanded=false class="navbar__toggle clean-btn" type=button><svg width=30 height=30 viewBox="0 0 30 30" aria-hidden=true><path stroke=currentColor stroke-linecap=round stroke-miterlimit=10 stroke-width=2 d="M4 7h22M4 15h22M4 23h22"/></svg></button><a class=navbar__brand href=/><b class="navbar__title text--truncate">John's Blog</b></a><a aria-current=page class="navbar__item navbar__link navbar__link--active" href=/ai>AI技术</a><a class="navbar__item navbar__link" href=/cloud-native>云原生</a><a class="navbar__item navbar__link" href=/notes>日常笔记</a><a class="navbar__item navbar__link" href=/programming>开发语言</a><a class="navbar__item navbar__link" href=/architecture>技术架构</a><a class="navbar__item navbar__link" href=/observability>可观测性</a><a class="navbar__item navbar__link" href=/life>生活笔记</a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href=/aboutme>关于我</a><a class="navbar__item navbar__link" href=/blog>博客</a><a href=https://goframe.org/ target=_blank rel="noopener noreferrer" class="navbar__item navbar__link header-goframe-link"></a><a href=https://github.com/gqcn target=_blank rel="noopener noreferrer" class="navbar__item navbar__link header-github-link"></a><div class=navbarSearchContainer_Bca1><button type=button class="DocSearch DocSearch-Button" aria-label="Search (Command+K)"><span class=DocSearch-Button-Container><svg width=20 height=20 class=DocSearch-Search-Icon viewBox="0 0 20 20" aria-hidden=true><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke=currentColor fill=none fill-rule=evenodd stroke-linecap=round stroke-linejoin=round /></svg><span class=DocSearch-Button-Placeholder>Search</span></span><span class=DocSearch-Button-Keys></span></button></div></div></div><div role=presentation class=navbar-sidebar__backdrop></div></nav><div id=__docusaurus_skipToContent_fallback class="main-wrapper mainWrapper_z2l0"><div class=docsWrapper_hBAB><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type=button></button><div class=docRoot_UBD9><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class=sidebarViewport_aRkj><div class=sidebar_njMd><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--active" href=/ai>AI技术</a><button aria-label="Collapse sidebar category 'AI技术'" aria-expanded=true type=button class="clean-btn menu__caret"></button></div><ul style=display:block;overflow:visible;height:auto class=menu__list><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--sublist-caret" role=button aria-expanded=false tabindex=0 href=/ai/agents-deep-dive-from-llm-to-autonomous-agents>智能体</a></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--sublist-caret" role=button aria-expanded=false tabindex=0 href=/ai/copilot-skills-guide>应用开发</a></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--sublist-caret" role=button aria-expanded=false tabindex=0 href=/ai/online-offline-batch-inference>推理服务</a></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--sublist-caret" role=button aria-expanded=false tabindex=0 href=/ai/hpc-development-training-platform>训练微调</a></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" tabindex=0 href=/ai/model-development>模型开发</a><button aria-label="Expand sidebar category '模型开发'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role=button aria-expanded=true tabindex=0 href=/ai/rdma-brief>基础架构</a></div><ul style=display:block;overflow:visible;height:auto class=menu__list><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--sublist-caret" role=button aria-expanded=false tabindex=0 href=/ai/rdma-brief>RDMA</a></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--sublist-caret" role=button aria-expanded=false tabindex=0 href=/ai/nfd-gfd>NVIDIA</a></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--sublist-caret" role=button aria-expanded=false tabindex=0 href=/ai/hybrid-scheduling-affinity-toleration>算力调度</a></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--sublist-caret" role=button aria-expanded=false tabindex=0 href=/ai/vgpu-introduction-and-comparison>GPU虚拟化</a></div><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/ai/what-is-llmops-mlops>LLMOps介绍</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/ai/common-acceleration-cards>常见智算加速卡汇总</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/ai/ai-training-inference-scenarios>AI基础架构中常见业务场景痛点</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current=page tabindex=0 href=/ai/cpu-gpu>CPU&GPU架构差异及AI场景中的应用</a></ul><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--sublist-caret" role=button aria-expanded=false tabindex=0 href=/ai/basic-terminology>入门知识</a></div></ul><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/cloud-native>云原生</a><button aria-label="Expand sidebar category '云原生'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/notes>日常笔记</a><button aria-label="Expand sidebar category '日常笔记'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/programming>开发语言</a><button aria-label="Expand sidebar category '开发语言'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/architecture>技术架构</a><button aria-label="Expand sidebar category '技术架构'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/management>技术管理</a><button aria-label="Expand sidebar category '技术管理'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/observability>可观测性</a><button aria-label="Expand sidebar category '可观测性'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/database-and-middleware>数据库与中间件</a><button aria-label="Expand sidebar category '数据库与中间件'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/operating-systems-and-networks>操作系统和网络</a><button aria-label="Expand sidebar category '操作系统和网络'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/life>生活笔记</a><button aria-label="Expand sidebar category '生活笔记'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div></ul></nav></div></div></aside><main class=docMainContainer_TBSr><div class="container padding-top--md padding-bottom--lg"><div class=row><div class="col docItemCol_VOVn"><div class=docItemContainer_Djhp><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label=Breadcrumbs><ul class=breadcrumbs itemscope itemtype=https://schema.org/BreadcrumbList><li class=breadcrumbs__item><a aria-label="Home page" class=breadcrumbs__link href=/><svg viewBox="0 0 24 24" class=breadcrumbHomeIcon_YNFT><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill=currentColor /></svg></a><li itemscope itemprop=itemListElement itemtype=https://schema.org/ListItem class=breadcrumbs__item><a class=breadcrumbs__link itemprop=item href=/ai><span itemprop=name>AI技术</span></a><meta itemprop=position content=1><li class=breadcrumbs__item><span class=breadcrumbs__link>基础架构</span><meta itemprop=position content=2><li itemscope itemprop=itemListElement itemtype=https://schema.org/ListItem class="breadcrumbs__item breadcrumbs__item--active"><span class=breadcrumbs__link itemprop=name>CPU&GPU架构差异及AI场景中的应用</span><meta itemprop=position content=3></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type=button class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h2 class="anchor anchorWithStickyNavbar_LWe7" id=为什么ai更需要gpu而不是cpu>为什么AI更需要GPU而不是CPU？<a href=#为什么ai更需要gpu而不是cpu class=hash-link aria-label="Direct link to 为什么AI更需要GPU而不是CPU？" title="Direct link to 为什么AI更需要GPU而不是CPU？">​</a></h2>
<p>AI模型的训练和推理，本质上是<strong>大规模的矩阵运算</strong>。以一个简单的神经网络为例，前向传播和反向传播过程中充斥着矩阵乘法、卷积等运算，这些运算具有以下特点：</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=计算密集型且高度并行>计算密集型且高度并行<a href=#计算密集型且高度并行 class=hash-link aria-label="Direct link to 计算密集型且高度并行" title="Direct link to 计算密集型且高度并行">​</a></h3>
<p>神经网络的每一层通常包含数百万到数十亿个参数，训练时需要对海量数据进行重复计算。这些计算任务：</p>
<ul>
<li><strong>高度重复</strong>：相同的运算指令应用于不同的数据</li>
<li><strong>天然并行</strong>：矩阵中每个元素的计算相互独立，可以同时进行</li>
<li><strong>运算简单</strong>：主要是浮点数的加法和乘法，逻辑控制少</li>
</ul>
<p>例如，一个<code>1024×1024</code>的矩阵乘法需要约<strong>10亿次</strong>浮点运算，但每次运算都是简单的乘加操作，且互不依赖。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=gpu的天然优势>GPU的天然优势<a href=#gpu的天然优势 class=hash-link aria-label="Direct link to GPU的天然优势" title="Direct link to GPU的天然优势">​</a></h3>
<p><code>GPU</code>拥有<strong>数千个轻量级计算核心</strong>（如<code>NVIDIA A100</code>有<code>6912</code>个<code>CUDA</code>核心），专为这种"简单指令、海量数据"的场景设计：</p>
<ul>
<li><strong>大规模并行</strong>：成千上万个核心同时工作，将矩阵运算分配给不同核心并行执行</li>
<li><strong>高吞吐量</strong>：每秒可完成数万亿次浮点运算（<code>TFLOPS</code>级别）</li>
<li><strong>内存带宽高</strong>：HBM高带宽内存可快速传输海量数据</li>
</ul>
<p>相比之下，<code>CPU</code>通常只有<strong>几十个核心</strong>（如<code>Intel Xeon</code>最多几十核），更擅长处理复杂的串行逻辑，面对AI训练这种大规模并行任务时效率远低于<code>GPU</code>。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=实际性能对比>实际性能对比<a href=#实际性能对比 class=hash-link aria-label="Direct link to 实际性能对比" title="Direct link to 实际性能对比">​</a></h3>
<p>以训练一个<code>ResNet-50</code>模型（计算机视觉领域基准模型）为例：</p>
<ul>
<li><strong>CPU（Intel Xeon）</strong>：数小时到数天</li>
<li><strong>单块GPU（NVIDIA A100）</strong>：几分钟到几小时</li>
<li><strong>多GPU集群</strong>：进一步缩短至分钟级</li>
</ul>
<p><code>GPU</code>相比<code>CPU</code>在AI训练上可实现 <strong><code>10-100</code>倍</strong> 的加速，这就是为什么现代AI基础设施几乎全部依赖<code>GPU</code>的根本原因。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id=cpu与gpu的架构设计差异>CPU与GPU的架构设计差异<a href=#cpu与gpu的架构设计差异 class=hash-link aria-label="Direct link to CPU与GPU的架构设计差异" title="Direct link to CPU与GPU的架构设计差异">​</a></h2>
<p><code>CPU</code>和<code>GPU</code>虽然都是处理器，但它们的设计理念截然不同，分别针对不同类型的计算任务优化。</p>
<p><img decoding=async loading=lazy alt=CPU与GPU的架构设计差异 src=/assets/images/image-d000fb2152ae3bea06ac19aebe59366d.png width=925 height=443 class=img_ev3q></p>
<ul>
<li><code>CPU</code>：通用计算核心，擅长执行复杂、多样化的任务，尤其是需要精确逻辑和分支判断的计算。</li>
<li><code>GPU</code>：计算的加速引擎，专为大规模数据并行处理而设计，能够并行处理多个相似的计算任务。</li>
<li><code>GPU</code>相比于<code>CPU</code>拥有更多算术逻辑单元（<code>ALU</code>），<code>CPU</code>则拥有更多控制单元（复杂指令解码、分支预测、乱序执行、投机执行等），因此<code>CPU</code>擅长处理逻辑复杂、分支多变的任务，<code>GPU</code>更擅长并行计算。</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=缓存结构>缓存结构<a href=#缓存结构 class=hash-link aria-label="Direct link to 缓存结构" title="Direct link to 缓存结构">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=cpu大容量多级缓存>CPU：大容量多级缓存<a href=#cpu大容量多级缓存 class=hash-link aria-label="Direct link to CPU：大容量多级缓存" title="Direct link to CPU：大容量多级缓存">​</a></h4>
<ul>
<li><strong>设计目标</strong>：减少内存访问延迟</li>
<li><strong>特点</strong>：包含<code>L1</code>、<code>L2</code>、<code>L3</code>多级高速缓存（几<code>MB</code>到几十<code>MB</code>）</li>
<li><strong>策略</strong>：将经常访问的数据放在低级缓存，不经常访问的放在高级缓存</li>
<li><strong>原因</strong>：<code>CPU</code>处理的指令流复杂多变，需要频繁访问不同内存地址，大缓存可显著降低平均访问时间</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=gpu少量缓存>GPU：少量缓存<a href=#gpu少量缓存 class=hash-link aria-label="Direct link to GPU：少量缓存" title="Direct link to GPU：少量缓存">​</a></h4>
<ul>
<li><strong>设计目标</strong>：减少缓存占用，腾出空间给更多计算核心</li>
<li><strong>特点</strong>：缓存容量相对较小</li>
<li><strong>策略</strong>：依靠高带宽显存（<code>HBM</code>）和大量线程隐藏内存延迟</li>
<li><strong>原因</strong>：<code>GPU</code>处理的数据访问模式规整、可预测，且通过大量线程并发执行来掩盖访存延迟，不需要依赖大缓存</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=控制单元>控制单元<a href=#控制单元 class=hash-link aria-label="Direct link to 控制单元" title="Direct link to 控制单元">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=cpu复杂控制逻辑>CPU：复杂控制逻辑<a href=#cpu复杂控制逻辑 class=hash-link aria-label="Direct link to CPU：复杂控制逻辑" title="Direct link to CPU：复杂控制逻辑">​</a></h4>
<ul>
<li><strong>分支预测</strong>：预测程序执行路径，提前加载指令，减少分支跳转损失</li>
<li><strong>乱序执行</strong>：动态调整指令执行顺序，充分利用执行单元</li>
<li><strong>数据转发（前递）</strong>：指令间数据依赖时快速转发数据，避免等待</li>
<li><strong>目标</strong>：降低单条指令延迟，适应复杂的程序逻辑</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=gpu简化控制逻辑>GPU：简化控制逻辑<a href=#gpu简化控制逻辑 class=hash-link aria-label="Direct link to GPU：简化控制逻辑" title="Direct link to GPU：简化控制逻辑">​</a></h4>
<ul>
<li><strong>无分支预测</strong>：控制单元极简，不进行复杂的分支预测</li>
<li><strong>SIMD/SIMT模式</strong>：同一指令作用于多个数据（<code>Single Instruction</code>, <code>Multiple Threads</code>）</li>
<li><strong>一个控制器管理多个核心</strong>：一行运算单元共享一个控制器，所有核心执行相同指令</li>
<li><strong>目标</strong>：提高吞吐量，适应数据并行的整齐划一运算</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=运算核心>运算核心<a href=#运算核心 class=hash-link aria-label="Direct link to 运算核心" title="Direct link to 运算核心">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=cpu少而强的核心>CPU：少而强的核心<a href=#cpu少而强的核心 class=hash-link aria-label="Direct link to CPU：少而强的核心" title="Direct link to CPU：少而强的核心">​</a></h4>
<ul>
<li><strong>核心数</strong>：通常几十个（如<code>Intel Xeon Platinum</code>最多几十核）</li>
<li><strong>单核性能</strong>：每个核心功能强大，支持复杂的整型、浮点型、向量运算</li>
<li><strong>频率</strong>：主频高（<code>3-4GHz</code>甚至更高）</li>
<li><strong>适合</strong>：串行任务、复杂逻辑、低延迟场景</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=gpu多而简的核心>GPU：多而简的核心<a href=#gpu多而简的核心 class=hash-link aria-label="Direct link to GPU：多而简的核心" title="Direct link to GPU：多而简的核心">​</a></h4>
<ul>
<li><strong>核心数</strong>：数千到上万个（如<code>NVIDIA A100</code>有<code>6912</code>个<code>CUDA</code>核心）</li>
<li><strong>单核性能</strong>：每个核心功能简单，主要执行浮点运算</li>
<li><strong>频率</strong>：主频较低（<code>1-2GHz</code>）</li>
<li><strong>长延时流水线</strong>：采用深度流水线，通过高吞吐量补偿单指令延迟</li>
<li><strong>适合</strong>：大规模并行任务、数据密集型计算</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=并行计算模型>并行计算模型<a href=#并行计算模型 class=hash-link aria-label="Direct link to 并行计算模型" title="Direct link to 并行计算模型">​</a></h3>
<p><strong>单指令多数据（<code>Single Instruction, Multiple Data, SIMD</code>）</strong>：一条指令同时在多个数据元素上执行。一次执行一条指令，同时对多个数据元素进行相同操作。数据被组织成向量或者批次，由同一个指令控制单元下发到多个执行单元，同时进行处理。如<code>CPU</code>中的向量化指令集（<code>SSE</code>、<code>AVX</code>）。</p>
<p><strong>单指令多线程（<code>Single Instruction, Multiple Thread, SIMT</code>）</strong>：一次发出一条指令，但由多个独立线程执行，每个线程拥有自己的寄存器和程序计数器。每个线程可以操作不同的数据，线程间可以有分支，但是同一个<code>warp</code>分支不一致时会发生分支发散，影响程序性能。</p>
<p><code>SIMD</code>是硬件级别的向量化模型，强调“指令+数据通道同步”，缺点是编程不够灵活；<code>SIMT</code>是<code>GPU</code>提供的编程抽象，是多线程编程模型。
例子：<code>SIMD</code>好比是一个工人，把8块砖放到一个箱子里，然后一次把箱子搬到指定位置；<code>SIMT</code>则是被镣铐锁住的<code>8</code>个囚犯，每人搬一块，指挥一次，也能把8块砖搬到指定位置。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=计算架构>计算架构<a href=#计算架构 class=hash-link aria-label="Direct link to 计算架构" title="Direct link to 计算架构">​</a></h3>
<p><strong>流式处理器（<code>Stream Processor</code>）</strong>：最基本的处理单元，也称为<code>CUDA core</code>。最后具体的指令和任务都是在<code>SP</code>上处理的。<code>GPU</code>进行并行计算，也就是很多个<code>SP</code>同时做处理。</p>
<p><strong>流式多处理器（<code>Stream MultiProcessor</code>）</strong>：<code>SM</code>由多个流式处理器（<code>Stream Processor</code>）、线程、一定数量的寄存器、线程束（<code>thread warp</code>）调度器、缓存组成。每个流式多处理器可以视为具有较小结构的<code>CPU</code>，支持指令并行。流式多处理器是线程块的运行载体，但不支持乱序执行。采用SIMT单指令多线程执行，一个指令由同一个<code>warp</code>中的<code>32</code>个线程执行。</p>
<p><img decoding=async loading=lazy alt=流式多处理器示意图 src=/assets/images/image-c49670c191b6cb59a88494daa9abd53e.png width=960 height=704 class=img_ev3q></p>
<p><code>Warp</code>：<code>warp</code>是调度和运行的基本单元，<code>warp</code>中所有<code>threads</code>并行的执行相同的指令。<code>warp</code>由<code>SM</code>的硬件<code>warp scheduler</code>负责调度，一个<code>SM</code>同一个时刻可以执行多个<code>warp</code>。</p>
<p><img decoding=async loading=lazy alt=Warp示意图 src=/assets/images/image-1-1ac3cb40fa61028ed35a3b73bf40ffba.png width=438 height=282 class=img_ev3q></p>
<p><strong>编程模型</strong>：</p>
<ul>
<li><code>Grid</code>：由一个单独的<code>kernel</code>启动的所有线程组成一个<code>grid</code>，<code>grid</code>中所有线程共享<code>global memory</code>。<code>Grid</code>由很多<code>Block</code>组成，可以是一维二维或三维。</li>
<li><code>Block</code>：一个<code>grid</code>由许多<code>block</code>组成，<code>block</code>由许多线程组成，同样可以有一维、二维或者三维。<code>block</code>内部的多个线程可以同步（<code>synchronize</code>），可访问共享内存（<code>share memory</code>）。</li>
<li><code>Thread</code>：最小编程模型，具体执行计算。</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=存储架构>存储架构<a href=#存储架构 class=hash-link aria-label="Direct link to 存储架构" title="Direct link to 存储架构">​</a></h3>
<p><strong>全局内存（<code>Global Memory</code>）</strong>：即显存（<code>HBM</code>），全局存储器，通过动态随机访问存储器实现。延迟高（几百个时钟周期），吞吐量大，配有<code>L2 Cache</code>。访问全局内存需要进行合并访问（<code>coalesce access</code>），即一个<code>warp</code>的线程尽量访问连续地址。</p>
<p><strong>共享内存（<code>Shared Memory</code>）</strong>：共享存储器，也是片上存储器；把共享存储器分配给线程块，同一个块（<code>Block</code>）中的所有线程都可以访问共享存储器中的变量，共享存储器是一种用于线程协作的高效方式；延迟显著低于全局内存（十几个时钟周期），可将需要频繁访问的数据加载到共享内存中进行优化，但需要避免出现<code>bank conflict</code>，即多个地址请求落在同一个<code>bank</code>中。</p>
<p><strong>本地内存（<code>Local Memory</code>）</strong>：本地存储器，存储位置在显存上，也就是全局存储器，只是在逻辑上属于某个线程，当线程使用的寄存器都占满时，数据将被存储在全局存储器，因为不是片上的寄存器或者缓存，访问速度很慢。</p>
<p><strong>寄存器（<code>Register</code>）</strong>：是<code>GPU</code>片上（<code>on-chip</code>）高速缓存，执行单元可以以极低的延迟访问寄存器（单周期访问）；寄存器变量是每个线程私有的，一旦<code>thread</code>执行结束，寄存器变量就会失效。把寄存器分配给每个线程，而每个线程也只能访问分配给自己的寄存器。</p>
<p><img decoding=async loading=lazy alt=CPU*GPU存储架构差异 src=/assets/images/image-2-a3a1f7826c12f7c4ba03e4767d8e5667.png width=579 height=641 class=img_ev3q></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=设计理念总结>设计理念总结<a href=#设计理念总结 class=hash-link aria-label="Direct link to 设计理念总结" title="Direct link to 设计理念总结">​</a></h3>
<table><thead><tr><th>维度<th>CPU<th>GPU<tbody><tr><td><strong>设计导向</strong><td>减少指令延迟<td>增加计算吞吐量<tr><td><strong>核心数量</strong><td>少而强（几十个核心）<td>多而简（数千到上万个核心）<tr><td><strong>主频</strong><td>高频（<code>3-4GHz</code>或更高）<td>低频（<code>1-2GHz</code>）<tr><td><strong>缓存结构</strong><td>大容量多级缓存（<code>L1/L2/L3</code>，几MB到几十MB）<td>小缓存，依靠高带宽显存（<code>HBM</code>）<tr><td><strong>控制逻辑</strong><td>复杂（分支预测、乱序执行、数据转发）<td>简化（无分支预测，<code>SIMT</code>单指令多线程）<tr><td><strong>并行模型</strong><td><code>SIMD</code>（向量化指令集，如<code>SSE</code>、<code>AVX</code>）<td><code>SIMT</code>（单指令多线程，<code>Warp</code>调度）<tr><td><strong>内存带宽</strong><td>较低（<code>DDR</code>）<td>极高（<code>HBM</code>高带宽内存）<tr><td><strong>优势场景</strong><td>复杂逻辑、频繁分支、低延迟、串行任务<td>简单重复、高度并行、高吞吐、数据密集<tr><td><strong>典型应用</strong><td>操作系统、数据库、<code>Web</code>服务、通用计算<td><code>AI</code>训练推理、科学计算、图形渲染、矩阵运算<tr><td><strong>类比</strong><td>精密机床，适合加工复杂零件<td>大规模流水线，适合批量生产</table>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id=异构计算cpu与gpu的协同>异构计算：CPU与GPU的协同<a href=#异构计算cpu与gpu的协同 class=hash-link aria-label="Direct link to 异构计算：CPU与GPU的协同" title="Direct link to 异构计算：CPU与GPU的协同">​</a></h2>
<p>在现代AI计算系统中，单靠<code>GPU</code>无法完成全部任务，必须借助<code>CPU</code>协同工作，这就是<strong>异构计算</strong>模式。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=分工模式>分工模式<a href=#分工模式 class=hash-link aria-label="Direct link to 分工模式" title="Direct link to 分工模式">​</a></h3>
<ul>
<li>
<p><strong>CPU负责</strong>：</p>
<ul>
<li>程序流程控制（调度、分支决策）</li>
<li>数据预处理和后处理</li>
<li>与系统交互（I/O、网络通信）</li>
<li>启动<code>GPU</code>任务、管理显存</li>
</ul>
</li>
<li>
<p><strong>GPU负责</strong>：</p>
<ul>
<li>大规模并行计算（矩阵运算、卷积等）</li>
<li>模型前向和反向传播</li>
<li>梯度计算和参数更新</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=典型工作流程>典型工作流程<a href=#典型工作流程 class=hash-link aria-label="Direct link to 典型工作流程" title="Direct link to 典型工作流程">​</a></h3>
<ol>
<li><strong>CPU准备数据</strong>：从硬盘/内存读取训练数据，进行必要的预处理</li>
<li><strong>CPU→GPU传输</strong>：将数据从主机内存拷贝到<code>GPU</code>显存</li>
<li><strong>GPU执行计算</strong>：数千个核心并行执行训练任务</li>
<li><strong>GPU→CPU传输</strong>：将计算结果（如损失值、梯度）拷贝回<code>CPU</code></li>
<li><strong>CPU分析决策</strong>：根据结果决定是否继续训练、调整超参数等</li>
<li><strong>循环往复</strong>：重复上述过程直到训练完成</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=为什么需要这种模式>为什么需要这种模式？<a href=#为什么需要这种模式 class=hash-link aria-label="Direct link to 为什么需要这种模式？" title="Direct link to 为什么需要这种模式？">​</a></h3>
<ul>
<li><strong>发挥各自优势</strong>：<code>CPU</code>擅长控制流，<code>GPU</code>擅长计算密集任务</li>
<li><strong>系统兼容性</strong>：操作系统、文件系统等基础设施运行在<code>CPU</code>上</li>
<li><strong>成本效益</strong>：通过合理分工，达到性能和成本的最优平衡</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id=总结>总结<a href=#总结 class=hash-link aria-label="Direct link to 总结" title="Direct link to 总结">​</a></h2>
<p><code>CPU</code>和<code>GPU</code>的架构差异源于它们服务的不同计算场景：</p>
<ul>
<li><strong>CPU</strong>是计算机的"大脑"，擅长处理复杂逻辑和串行任务，通过大缓存、分支预测等技术追求<strong>低延迟</strong></li>
<li><strong>GPU</strong>是计算机的"肌肉"，擅长大规模重复计算和并行任务，通过海量核心和简化控制追求<strong>高吞吐量</strong></li>
</ul>
<p>AI模型训练恰好属于后者——大规模的矩阵运算，天然适合<code>GPU</code>的并行架构。这就是为什么现代AI基础设施几乎全部依赖<code>GPU</code>，并采用<code>CPU</code>-<code>GPU</code>异构计算模式来发挥各自优势。</p>
<p>理解这些底层架构差异，对于优化AI训练流程、选择合适的硬件配置、提升资源利用率都至关重要。</div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href=/ai/ai-training-inference-scenarios><div class=pagination-nav__sublabel>Previous</div><div class=pagination-nav__label>AI基础架构中常见业务场景痛点</div></a><a class="pagination-nav__link pagination-nav__link--next" href=/ai/basic-terminology><div class=pagination-nav__sublabel>Next</div><div class=pagination-nav__label>人工智能领域常见术语梳理</div></a></nav><div class=docusaurus-mt-lg></div></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href=#为什么ai更需要gpu而不是cpu class="table-of-contents__link toc-highlight">为什么AI更需要GPU而不是CPU？</a><ul><li><a href=#计算密集型且高度并行 class="table-of-contents__link toc-highlight">计算密集型且高度并行</a><li><a href=#gpu的天然优势 class="table-of-contents__link toc-highlight">GPU的天然优势</a><li><a href=#实际性能对比 class="table-of-contents__link toc-highlight">实际性能对比</a></ul><li><a href=#cpu与gpu的架构设计差异 class="table-of-contents__link toc-highlight">CPU与GPU的架构设计差异</a><ul><li><a href=#缓存结构 class="table-of-contents__link toc-highlight">缓存结构</a><li><a href=#控制单元 class="table-of-contents__link toc-highlight">控制单元</a><li><a href=#运算核心 class="table-of-contents__link toc-highlight">运算核心</a><li><a href=#并行计算模型 class="table-of-contents__link toc-highlight">并行计算模型</a><li><a href=#计算架构 class="table-of-contents__link toc-highlight">计算架构</a><li><a href=#存储架构 class="table-of-contents__link toc-highlight">存储架构</a><li><a href=#设计理念总结 class="table-of-contents__link toc-highlight">设计理念总结</a></ul><li><a href=#异构计算cpu与gpu的协同 class="table-of-contents__link toc-highlight">异构计算：CPU与GPU的协同</a><ul><li><a href=#分工模式 class="table-of-contents__link toc-highlight">分工模式</a><li><a href=#典型工作流程 class="table-of-contents__link toc-highlight">典型工作流程</a><li><a href=#为什么需要这种模式 class="table-of-contents__link toc-highlight">为什么需要这种模式？</a></ul><li><a href=#总结 class="table-of-contents__link toc-highlight">总结</a></ul></div></div></div></div></main></div></div></div><footer class=footer><div class="container container-fluid"><div class="footer__bottom text--center"><div class=footer__copyright>Copyright 2026 johng.cn</div></div></div></footer></div>