<!doctype html><html lang=en dir=ltr class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-docs/AI技术/入门知识/AI领域常见基础术语梳理" data-has-hydrated=false><meta charset=UTF-8><meta name=generator content="Docusaurus v3.6.3"><title data-rh=true>AI领域常见基础术语梳理 | John's Blog</title><meta data-rh=true name=viewport content="width=device-width,initial-scale=1.0"><meta data-rh=true name=twitter:card content=summary_large_image><meta data-rh=true property=og:url content=https://johng.cn/ai/basic-terminology><meta data-rh=true property=og:locale content=en><meta data-rh=true name=docusaurus_locale content=en><meta data-rh=true name=docsearch:language content=en><meta data-rh=true name=author content="John Guo"><meta data-rh=true property=og:image content=https://johng.cn/img/favicon.png><meta data-rh=true name=docusaurus_version content=current><meta data-rh=true name=docusaurus_tag content=docs-default-current><meta data-rh=true name=docsearch:version content=current><meta data-rh=true name=docsearch:docusaurus_tag content=docs-default-current><meta data-rh=true property=og:title content="AI领域常见基础术语梳理 | John's Blog"><meta data-rh=true name=description content=系统梳理AI核心术语，涵盖基础概念(大语言模型/多模态/RAG/思维链)、机器学习(监督/无监督/强化学习)、训练微调(梯度下降/反向传播/LoRA/RLHF/并行计算策略)、模型评估(准确率/精确率/召回率)、硬件工具(GPU/TPU/CUDA)五大模块。每个术语配有中英对照、原理解释和生动类比，通俗易懂，助力AI新人快速入门，建立完整知识体系。><meta data-rh=true property=og:description content=系统梳理AI核心术语，涵盖基础概念(大语言模型/多模态/RAG/思维链)、机器学习(监督/无监督/强化学习)、训练微调(梯度下降/反向传播/LoRA/RLHF/并行计算策略)、模型评估(准确率/精确率/召回率)、硬件工具(GPU/TPU/CUDA)五大模块。每个术语配有中英对照、原理解释和生动类比，通俗易懂，助力AI新人快速入门，建立完整知识体系。><meta data-rh=true name=keywords content=AI术语,机器学习术语,深度学习术语,大语言模型,LLM,神经网络,模型训练,模型微调,Fine-tuning,LoRA,RLHF,RAG检索增强生成,损失函数,梯度下降,反向传播,过拟合欠拟合,监督学习,强化学习,模型评估,数据并行,模型并行,张量并行,流水线并行,知识蒸馏,模型压缩,量化剪枝,GPU加速,PyTorch,TensorFlow,AI基础概念,人工智能词汇,AI入门教程><link data-rh=true rel=icon href=/img/favicon.ico><link data-rh=true rel=canonical href=https://johng.cn/ai/basic-terminology><link data-rh=true rel=alternate href=https://johng.cn/ai/basic-terminology hreflang=en><link data-rh=true rel=alternate href=https://johng.cn/ai/basic-terminology hreflang=x-default><link data-rh=true rel=preconnect href=https://XGS1CPQERK-dsn.algolia.net crossorigin><link rel=alternate type=application/rss+xml href=/blog/rss.xml title="John's Blog RSS Feed"><link rel=alternate type=application/atom+xml href=/blog/atom.xml title="John's Blog Atom Feed"><link rel=search type=application/opensearchdescription+xml title="John's Blog" href=/opensearch.xml><script src=https://hm.baidu.com/hm.js?6b4ae23dc83ee5efe875b7172af6c7c1 async></script><link rel=stylesheet href=/assets/css/styles.2f56d3c4.css><script src=/assets/js/runtime~main.4bec07ad.js defer></script><script src=/assets/js/main.df2d7182.js defer></script><body class=navigation-with-keyboard><script>!function(){var t,e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t=null!==e?e:"light",document.documentElement.setAttribute("data-theme",t)}(),function(){try{for(var[t,e]of new URLSearchParams(window.location.search).entries())if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id=__docusaurus><div role=region aria-label="Skip to main content"><a class=skipToContent_fXgn href=#__docusaurus_skipToContent_fallback>Skip to main content</a></div><nav aria-label=Main class="navbar navbar--fixed-top"><div class=navbar__inner><div class=navbar__items><button aria-label="Toggle navigation bar" aria-expanded=false class="navbar__toggle clean-btn" type=button><svg width=30 height=30 viewBox="0 0 30 30" aria-hidden=true><path stroke=currentColor stroke-linecap=round stroke-miterlimit=10 stroke-width=2 d="M4 7h22M4 15h22M4 23h22"/></svg></button><a class=navbar__brand href=/><b class="navbar__title text--truncate">John's Blog</b></a><a aria-current=page class="navbar__item navbar__link navbar__link--active" href=/ai>AI技术</a><a class="navbar__item navbar__link" href=/cloud-native>云原生</a><a class="navbar__item navbar__link" href=/notes>日常笔记</a><a class="navbar__item navbar__link" href=/programming>开发语言</a><a class="navbar__item navbar__link" href=/architecture>技术架构</a><a class="navbar__item navbar__link" href=/observability>可观测性</a><a class="navbar__item navbar__link" href=/life>生活笔记</a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href=/aboutme>关于我</a><a class="navbar__item navbar__link" href=/blog>博客</a><a href=https://goframe.org/ target=_blank rel="noopener noreferrer" class="navbar__item navbar__link header-goframe-link"></a><a href=https://github.com/gqcn target=_blank rel="noopener noreferrer" class="navbar__item navbar__link header-github-link"></a><div class=navbarSearchContainer_Bca1><button type=button class="DocSearch DocSearch-Button" aria-label="Search (Command+K)"><span class=DocSearch-Button-Container><svg width=20 height=20 class=DocSearch-Search-Icon viewBox="0 0 20 20" aria-hidden=true><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke=currentColor fill=none fill-rule=evenodd stroke-linecap=round stroke-linejoin=round /></svg><span class=DocSearch-Button-Placeholder>Search</span></span><span class=DocSearch-Button-Keys></span></button></div></div></div><div role=presentation class=navbar-sidebar__backdrop></div></nav><div id=__docusaurus_skipToContent_fallback class="main-wrapper mainWrapper_z2l0"><div class=docsWrapper_hBAB><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type=button></button><div class=docRoot_UBD9><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class=sidebarViewport_aRkj><div class=sidebar_njMd><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--active" href=/ai>AI技术</a><button aria-label="Collapse sidebar category 'AI技术'" aria-expanded=true type=button class="clean-btn menu__caret"></button></div><ul style=display:block;overflow:visible;height:auto class=menu__list><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" tabindex=0 href=/ai/agents>智能体</a><button aria-label="Expand sidebar category '智能体'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" tabindex=0 href=/ai/app>应用开发</a><button aria-label="Expand sidebar category '应用开发'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" tabindex=0 href=/ai/inference>推理服务</a><button aria-label="Expand sidebar category '推理服务'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" tabindex=0 href=/ai/training>训练微调</a><button aria-label="Expand sidebar category '训练微调'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" tabindex=0 href=/ai/infra>基础架构</a><button aria-label="Expand sidebar category '基础架构'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--active" tabindex=0 href=/ai/basic>入门知识</a><button aria-label="Collapse sidebar category '入门知识'" aria-expanded=true type=button class="clean-btn menu__caret"></button></div><ul style=display:block;overflow:visible;height:auto class=menu__list><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current=page tabindex=0 href=/ai/basic-terminology>AI领域常见基础术语梳理</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/ai/general-ai-model-and-thinking-ai-model-difference>通用大模型和思维大模型区别</a></ul></ul><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/cloud-native>云原生</a><button aria-label="Expand sidebar category '云原生'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/notes>日常笔记</a><button aria-label="Expand sidebar category '日常笔记'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/programming>开发语言</a><button aria-label="Expand sidebar category '开发语言'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/architecture>技术架构</a><button aria-label="Expand sidebar category '技术架构'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/management>技术管理</a><button aria-label="Expand sidebar category '技术管理'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/observability>可观测性</a><button aria-label="Expand sidebar category '可观测性'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/database-and-middleware>数据库与中间件</a><button aria-label="Expand sidebar category '数据库与中间件'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/operating-systems-and-networks>操作系统和网络</a><button aria-label="Expand sidebar category '操作系统和网络'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/life>生活笔记</a><button aria-label="Expand sidebar category '生活笔记'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div></ul></nav></div></div></aside><main class=docMainContainer_TBSr><div class="container padding-top--md padding-bottom--lg"><div class=row><div class="col docItemCol_VOVn"><div class=docItemContainer_Djhp><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label=Breadcrumbs><ul class=breadcrumbs itemscope itemtype=https://schema.org/BreadcrumbList><li class=breadcrumbs__item><a aria-label="Home page" class=breadcrumbs__link href=/><svg viewBox="0 0 24 24" class=breadcrumbHomeIcon_YNFT><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill=currentColor /></svg></a><li itemscope itemprop=itemListElement itemtype=https://schema.org/ListItem class=breadcrumbs__item><a class=breadcrumbs__link itemprop=item href=/ai><span itemprop=name>AI技术</span></a><meta itemprop=position content=1><li itemscope itemprop=itemListElement itemtype=https://schema.org/ListItem class=breadcrumbs__item><a class=breadcrumbs__link itemprop=item href=/ai/basic><span itemprop=name>入门知识</span></a><meta itemprop=position content=2><li itemscope itemprop=itemListElement itemtype=https://schema.org/ListItem class="breadcrumbs__item breadcrumbs__item--active"><span class=breadcrumbs__link itemprop=name>AI领域常见基础术语梳理</span><meta itemprop=position content=3></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type=button class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><blockquote>
<p>不定期更新完善。</p>
</blockquote>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id=基础概念>基础概念<a href=#基础概念 class=hash-link aria-label="Direct link to 基础概念" title="Direct link to 基础概念">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=大语言模型>大语言模型<a href=#大语言模型 class=hash-link aria-label="Direct link to 大语言��模型" title="Direct link to 大语言模型">​</a></h3>
<p>大语言模型(<code>Large Language Model, LLM</code>)：参数量巨大(数十亿到数万亿)的语言模型，通过在海量文本数据上训练，掌握语言的深层规律和广泛知识。能理解和生成自然语言，完成问答、写作、翻译、代码生成等多种任务。代表模型有<code>GPT</code>系列、<code>Claude</code>、<code>Llama</code>等。就像博览群书的学者，阅读了互联网上的大量文本后具备了广泛的知识和语言能力。参数越多模型越强大，但训练和运行成本也越高。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=基础模型>基础模型<a href=#基础模型 class=hash-link aria-label="Direct link to 基础模型" title="Direct link to 基础模型">​</a></h3>
<p>基础模型(<code>Foundation Model</code>)：在大规模、多样化数据上预训练的通用模型，可以作为基础适配到各种下游任务。不针对特定任务，而是学习通用的表示和能力，然后通过微调或提示工程应用到具体场景。大语言模型就是基础模型的典型代表。就像通识教育打好基础，然后可以选择不同专业方向深造。一个基础模型可以派生出无数应用。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=多模态模型>多模态模型<a href=#多模态模型 class=hash-link aria-label="Direct link to 多模态模型" title="Direct link to 多模态模型">​</a></h3>
<p>多模态模型(<code>Multimodal Model</code>)：能同时处理和理解多种类型数据(文本、图像、音频、视频等)的模型，打破单一模态的限制。可以根据图片回答问题、根据文本生成图片、理解视频内容等。代表模型有<code>GPT-4V</code>、<code>Claude 3</code>、<code>Gemini</code>等。就像人类用眼睛看、耳朵听、嘴巴说综合理解世界，多模态模型模拟这种综合感知能力，比单一处理文字更强大。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=思维链>思维链<a href=#思维链 class=hash-link aria-label="Direct link to 思维链" title="Direct link to 思维链">​</a></h3>
<p>思维链(<code>Chain of Thought, CoT</code>)：引导大模型逐步推理的提示技术，让模型"展示思考过程"。在提示中加入"让我们一步步思考"或提供推理示例，模型会先输出中间推理步骤，再给出最终答案。能显著提高数学、逻辑等复杂问题的准确率，因为分步骤降低了出错概率，也让推理过程可解释。就像考试要求写解题步骤，一步步推导比直接写答案更不容易错。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=检索增强生成>检索增强生成<a href=#检索增强生成 class=hash-link aria-label="Direct link to 检索增强生成" title="Direct link to 检索增强生成">​</a></h3>
<p>检索增强生成(<code>Retrieval-Augmented Generation, RAG</code>)：结合信息检索和文本生成的技术，先从知识库检索相关信息，再基于检索结果生成回答。弥补大模型知识更新滞后、容易产生幻觉的问题，用实时准确的外部信息增强生成质量。就像开卷考试，可以查资料再作答，答案更准确可靠。广泛应用于企业问答系统、文档助手等场景。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=提示调优>提示调优<a href=#提示调优 class=hash-link aria-label="Direct link to 提示调优" title="Direct link to 提示调优">​</a></h3>
<p>提示调优(<code>Prompt Tuning</code>)：不改变模型参数，只优化输入提示词的方法。通过精心设计提示内容、格式、示例来引导模型输出期望结果。相比微调，提示调优无需训练，成本极低，灵活性高，但效果可能不如微调稳定。就像问问题的方式不同得到的答案质量不同，找到最佳问法就是提示调优。提示工程(Prompt Engineering)是相关的实践技能。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=幻觉>幻觉<a href=#幻觉 class=hash-link aria-label="Direct link to 幻觉" title="Direct link to 幻觉">​</a></h3>
<p>幻觉(<code>Hallucination</code>)：大模型生成看似流畅合理但实际错误或编造的内容，是当前的主要局限。模型基于统计规律生成文本，可能"一本正经地胡说八道"，编造不存在的事实、引用、数据等。就像侃侃而谈但实际信口开河的人。应对方法包括检索增强(<code>RAG</code>)、增加引用、多模型验证、用户提醒等。使用大模型时需要批判性验证其输出。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=温度>温度<a href=#温度 class=hash-link aria-label="Direct link to 温度" title="Direct link to 温度">​</a></h3>
<p>温度(<code>Temperature</code>)：控制生成文本随机性的参数，影响输出的创造性和确定性。温度值通常在<code>0</code>到<code>2</code>之间，默认<code>1</code>。温度高(如<code>1.5-2</code>)输出更随机、多样、有创意，但可能不连贯；温度低(如<code>0.1-0.5</code>)输出更确定、保守、一致，但可能枯燥。温度0接近贪婪搜索，总选概率最高的词。就像做菜的火候，大火爆炒(高温度)有锅气但容易糊，小火慢炖(低温度)稳定但可能寡淡。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id=机器学习>机器学习<a href=#机器学习 class=hash-link aria-label="Direct link to 机器学习" title="Direct link to 机器学习">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=机器学习-1>机器学习<a href=#机器学习-1 class=hash-link aria-label="Direct link to 机器学习" title="Direct link to 机器学习">​</a></h3>
<p>机器学习(<code>Machine Learning, ML</code>)：让计算机从数据中自动学习规律和模式的技术，无需显式编程告诉它每一步该怎么做。传统编程是人写规则让计算机执行，而机器学习是让计算机自己从数据中总结规律。就像教小孩认水果，不用告诉他"红色圆形带梗的是苹果"，只要给他看够多的苹果样例，他自己就能总结出苹果的特征。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=监督学习>监督学习<a href=#监督学习 class=hash-link aria-label="Direct link to 监督学习" title="Direct link to 监督学习">​</a></h3>
<p>监督学习(<code>Supervised Learning</code>)：机器学习的方式之一，从已标注好的数据中学习的方法，每条数据都有明确的"答案"(标签)。模型通过学习大量"问题-答案"对，掌握从输入到输出的映射关系。就像学生做习题，每道题都有标准答案供对照学习。典型应用包括图片分类(给照片标注类别)、垃圾邮件识别(标注邮件是否垃圾)、房价预测(给出历史成交数据)。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=无监督学习>无监督学习<a href=#无监督学习 class=hash-link aria-label="Direct link to 无监督学习" title="Direct link to 无监督学习">​</a></h3>
<p>无监督学习(<code>Unsupervised Learning</code>)：机器学习的方式之一，从未标注的数据中自动发现隐藏的模式和结构，数据没有预定义的"正确答案"。模型要自己摸索数据的内在规律和分组方式。就像让你整理一堆照片，没人告诉你分类标准，你可能按人物、地点或时间自己归类。常见任务包括客户分群、异常检测、数据降维等。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=半监督学习>半监督学习<a href=#半监督学习 class=hash-link aria-label="Direct link to 半监督学习" title="Direct link to 半监督学习">​</a></h3>
<p>半监督学习(<code>Semi-supervised Learning</code>)：机器学习的方式之一，结合少量标注数据和大量未标注数据进行学习的方法，介于监督学习和无监督学习之间。现实中标注数据成本高昂(需要人工逐个标注)，而未标注数据容易获取。半监督学习用少量标注数据指明方向，再利用大量未标注数据提升模型性能。就像老师批改了几份作业示范，然后让学生参考着互相学习。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=强化学习>强化学习<a href=#强化学习 class=hash-link aria-label="Direct link to 强化学习" title="Direct link to 强化学习">​</a></h3>
<p>强化学习(<code>Reinforcement Learning, RL</code>)：机器学习的方式之一，通过与环境不断交互、试错来学习最优决策策略的方法。智能体(Agent)在环境中采取行动，根据获得的奖励或惩罚反馈来调整策略。就像训练宠物或玩游戏升级，做对了给奖励(加分)，做错了给惩罚(扣血)，反复尝试找到得分最高的玩法。<code>AlphaGo</code>下围棋、机器人学走路都用到强化学习。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id=训练微调>训练微调<a href=#训练微调 class=hash-link aria-label="Direct link to 训练微调" title="Direct link to 训练微调">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=预训练>预训练<a href=#预训练 class=hash-link aria-label="Direct link to 预训练" title="Direct link to 预训练">​</a></h3>
<p>预训练(<code>Pre-training, PT</code>)：在大规模无标注数据上训练模型的初始阶段，让模型学习语言的基础规律和广泛知识。通常采用自监督学习任务，如预测下一个词(语言模型)、掩码词预测(<code>BERT</code>)等。预训练是构建基础模型的核心步骤，耗费大量算力和数据，但只需做一次。就像打地基和建主体结构，是最耗时耗力但最关键的阶段。预训练后的模型具备通用语言理解能力，可以通过微调适配到各种下游任务。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=增量预训练>增量预训练<a href=#增量预训练 class=hash-link aria-label="Direct link to 增量预训练" title="Direct link to 增量预训练">​</a></h3>
<p>增量预训练(<code>Continual Pre-training, CPT</code>)：在已有预训练模型基础上，使用新的领域数据或更新的数据继续进行预训练，让模型获得特定领域知识或更新知识库。与从头预训练相比，增量预训练成本更低，能够在保持通用能力的同时增强专业能力。比如在通用大模型上用医学文献继续预训练，让它掌握医学专业知识。就像在已有知识基础上继续深造学习新领域，比从零开始效率高得多。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=微调>微调<a href=#微调 class=hash-link aria-label="Direct link to 微调" title="Direct link to 微调">​</a></h3>
<p>微调(<code>Fine-tuning</code>)：在预训练大模型基础上，用特定任务的数据继续训练，让模型适应具体场景。预训练提供通用能力，微调定制专业能力。比如用医疗对话数据微调通用模型，让它成为医疗助手。微调所需数据量远小于从头训练，成本更低效果更好。就像大学毕业生(预训练)到公司后针对性培训(微调)成为专业人才。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=张量>张量<a href=#张量 class=hash-link aria-label="Direct link to 张量" title="Direct link to 张量">​</a></h3>
<p>张量(<code>Tensor</code>)：多维数组，是深度学习框架中的基本数据结构，用于表示和存储数据。标量是<code>0</code>维张量(一个数)，向量是<code>1</code>维张量(一串数)，矩阵是<code>2</code>维张量，更高维的统称张量。神经网络的输入、输出、权重都用张量表示，计算本质是张量运算。<code>PyTorch</code>、<code>TensorFlow</code>等框架的核心就是张量及其运算。就像乐高积木是基本单元，张量是搭建AI模型的基础组件。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=tensorflow>TensorFlow<a href=#tensorflow class=hash-link aria-label="Direct link to TensorFlow" title="Direct link to TensorFlow">​</a></h3>
<p><code>Google</code>开发的开源深度学习框架，提供完整的端到端机器学习平台。功能强大，支持从研究到生产部署的全流程，有丰富的工具生态(<code>TensorBoard</code>可视化、<code>TF Serving</code>部署等)。但学习曲线较陡，API复杂度高。适合大规模工业应用和生产环境。就像工业级全套装备，功能齐全但上手需要时间。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=pytorch>PyTorch<a href=#pytorch class=hash-link aria-label="Direct link to PyTorch" title="Direct link to PyTorch">​</a></h3>
<p><code>Facebook(Meta)</code>开发的深度学习框架，以灵活易用著称，是当前学术研究界最流行的框架。采用动态计算图，调试方便，代码简洁直观，接近原生<code>Python</code>风格。社区活跃，论文复现多用<code>PyTorch</code>。适合快速原型开发和研究实验。就像轻便的瑞士军刀，灵活好用易上手。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=损失函数>损失函数<a href=#损失函数 class=hash-link aria-label="Direct link to 损失函数" title="Direct link to 损失函数">​</a></h3>
<p>损失函数(<code>Loss Function</code>)：衡量模型预测值与真实值差距的函数，训练目标是最小化损失。就像考试的扣分标准，告诉模型哪里做得不好、扣了多少分。不同任务用不同损失函数：分类常用交叉熵损失，回归常用均方误差。损失函数的选择直接影响模型学到什么。训练过程就是不断调整参数让损失函数的值越来越小。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=梯度>梯度<a href=#梯度 class=hash-link aria-label="Direct link to 梯度" title="Direct link to 梯度">​</a></h3>
<p>梯度(<code>Gradient</code>)：指示每个参数应该如何调整的信号，是损失函数相对于参数的变化率（导数）。梯度告诉模型两件事：调整方向（增大还是减小参数）和调整幅度（变化快慢）。就像猜数字游戏，我心中目标数字是<code>10</code>，猜<code>7</code>时告诉你"往大了猜"（方向），并且"差得还挺远"（幅度），下次就该往更大的方向猜。梯度大说明参数对损失影响大，需要大步调整；梯度小说明接近最优，小步微调即可。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=梯度下降>梯度下降<a href=#梯度下降 class=hash-link aria-label="Direct link to 梯度下降" title="Direct link to 梯度下降">​</a></h3>
<p>梯度下降(<code>Gradient Descent</code>)：一种优化算法，通过计算梯度(斜率)来调整参数，让损失函数逐步减小。梯度指向函数上升最快的方向，沿着负梯度方向走就能下降。就像蒙眼下山，摸索脚下的坡度，朝最陡的方向往下走，最终到达山谷最低点。有多种变体:批量梯度下降(用全部数据)、随机梯度下降(<code>SGD</code>，每次一个样本)、小批量梯度下降(<code>Mini-batch</code>，折中方案)。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=反向传播>反向传播<a href=#反向传播 class=hash-link aria-label="Direct link to 反向传播" title="Direct link to 反向传播">​</a></h3>
<p>反向传播(<code>Backpropagation</code>)：神经网络的核心训练算法，从输出层反向逐层计算每个参数的梯度，用于更新参数。前向传播计算输出和损失，反向传播利用链式法则将误差从后往前传，算出每个权重对损失的影响(梯度)，然后用梯度下降更新权重。就像考试后分析错题，从最终错误倒推，找出每个步骤的问题。这是让深度网络可训练的关键技术。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=过拟合>过拟合<a href=#过拟合 class=hash-link aria-label="Direct link to 过拟合" title="Direct link to 过拟合">​</a></h3>
<p>过拟合(<code>Overfitting</code>)：模型在训练数据上表现很好，但在新数据上表现差的现象。模型记住了训练数据的细节和噪声，而没有学到泛化的规律，导致泛化能力弱。就像学生死记硬背标准答案，考原题满分，题目稍有变化就不会做了。解决方法包括：增加数据、正则化、简化模型、<code>Dropout</code>、提前停止训练等。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=欠拟合>欠拟合<a href=#欠拟合 class=hash-link aria-label="Direct link to 欠拟合" title="Direct link to 欠拟合">​</a></h3>
<p>欠拟合(<code>Underfitting</code>)：模型太简单，连训练数据都学不好的现象。模型复杂度不足以捕捉数据中的模式，预测误差大。就像用小学知识应对高考题，压根没学懂知识点。训练集和测试集上表现都很差。解决方法:增加模型复杂度、增加训练轮次、减少正则化、添加更多特征等。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=超参数>超参数<a href=#超参数 class=hash-link aria-label="Direct link to 超参数" title="Direct link to 超参数">​</a></h3>
<p>超参数(<code>Hyperparameter</code>)：训练前需要人工设定的参数，控制模型结构和学习过程，如学习率、批量大小、网络层数、神经元数量等。与训练过程中自动学习的模型参数(权重、偏置)不同，超参数不通过梯度下降更新。超参数的设置显著影响模型性能，需要通过实验或自动化方法寻找最优值。就像做菜前定好火候和时间，不是边做边调的。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=超参数调优>超参数调优<a href=#超参数调优 class=hash-link aria-label="Direct link to 超参数调优" title="Direct link to 超参数调优">​</a></h3>
<p>超参数调优(<code>Hyperparameter Tuning</code>)：寻找最优超参数组合的过程，也叫超参数搜索。常用方法有:网格搜索(穷举组合，计算量大但全面)、随机搜索(随机采样，效率更高)、贝叶斯优化(根据历史结果智能选择下一组参数)、自动化工具(如Optuna、Ray Tune)等。就像调试配方找最佳比例，需要反复实验。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=参数高效微调>参数高效微调<a href=#参数高效微调 class=hash-link aria-label="Direct link to 参数高效微调" title="Direct link to 参数高效微调">​</a></h3>
<p>参数高效微调(<code>Parameter-Efficient Fine-Tuning, PEFT</code>)：只更新少量参数实现微调的方法，而非更新全部参数。大幅降低计算和存储成本，同时保持接近全量微调的效果。常见方法有<code>LoRA</code>、<code>Adapter</code>、<code>Prefix Tuning</code>等。比如在百亿参数模型上只训练几百万参数就能适配新任务。就像装修房子不全部重建，只改局部就达到新效果，省时省力。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=lora>LoRA<a href=#lora class=hash-link aria-label="Direct link to LoRA" title="Direct link to LoRA">​</a></h3>
<p><code>LoRA(Low-Rank Adaptation)</code>：一种参数高效微调技术，通过在模型权重旁边添加低秩矩阵来适配新任务。只训练这些小矩阵(占原参数1%左右)，冻结原模型权重。训练快、显存占用小，可以为不同任务训练多个LoRA切换使用。就像给西装配不同领带，不用买多套西装，换领带就能适配不同场合。是当前最流行的高效微调方法。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=指令微调>指令微调<a href=#指令微调 class=hash-link aria-label="Direct link to 指令微调" title="Direct link to 指令微调">​</a></h3>
<p>指令微调(<code>Instruction Tuning</code>)：用"指令-响应"格式的数据微调模型，让它更好地理解和遵循人类指令。训练数据包含各种任务指令和对应的理想输出。指令微调后的模型更易用，能准确理解用户意图，按要求完成任务。GPT系列、Claude等模型都经过大量指令微调。就像培训客服人员理解各种客户需求，按规范服务。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=有监督微调>有监督微调<a href=#有监督微调 class=hash-link aria-label="Direct link to 有监督微调" title="Direct link to 有监督微调">​</a></h3>
<p>有监督微调(<code>Supervised Fine-Tuning, SFT</code>)：使用标注好的"输入-输出"对数据进行监督学习微调的方法，是指令微调的核心实现方式。与预训练的无监督学习不同，<code>SFT</code>使用高质量的人工标注数据，让模型学习特定的输入输出模式和任务完成方式。是大语言模型训练流程中的关键步骤，通常在预训练或增量预训练之后、人类偏好对齐之前进行。就像学生在掌握基础知识后，通过做标准答案的练习题来提升应试能力，学会如何正确回答问题。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=强化微调>强化微调<a href=#强化微调 class=hash-link aria-label="Direct link to 强化微调" title="Direct link to 强化微调">​</a></h3>
<p>强化微调(<code>Reinforcement Fine-Tuning, RFT</code>)：使用强化学习方法对模型进行微调，通过奖励信号引导模型优化输出。与监督微调直接学习标准答案不同，强化微调通过探索和试错学习最优策略，更适合没有标准答案或需要多步推理的复杂任务。可以基于自动化评估指标(如代码执行结果、数学验证)或人类反馈(<code>RLHF</code>)进行训练。就像通过实战演练和反馈不断改进决策能力，比单纯背答案更能培养解决问题的能力。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=人类偏好对齐>人类偏好对齐<a href=#人类偏好对齐 class=hash-link aria-label="Direct link to 人类偏好对齐" title="Direct link to 人类偏好对齐">​</a></h3>
<p>人类偏好对齐(<code>Reinforcement Learning from Human Feedback, RLHF</code>)：基于人类反馈的强化学习方法，让模型输出更符合人类偏好、价值观和期望。具体流程包括：收集人工对模型不同输出的排序或评分，训练奖励模型来预测人类偏好，最后用强化学习(如<code>PPO</code>算法)优化模型生成策略以最大化奖励。能让模型输出更有帮助、更安全、更符合人类期望，显著提升用户体验。<code>ChatGPT</code>的成功很大程度归功于<code>RLHF</code>技术。就像通过用户评价和反馈持续改进产品，让AI真正懂得人类想要什么。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=top-k采样>Top-k采样<a href=#top-k采样 class=hash-link aria-label="Direct link to Top-k采样" title="Direct link to Top-k采样">​</a></h3>
<p><code>Top-k</code>采样(<code>Top-k Sampling</code>)：生成每个词时只从概率最高的k个候选词中采样，过滤掉低概率词。平衡输出质量和多样性，k值越大越多样但可能出现低质量词，<code>k</code>值越小越保守。常见<code>k</code>值为<code>40-100</code>。就像选秀节目只在前k名选手中投票，保证基本水准。相比贪婪搜索(只选最高概率)更灵活，相比完全随机采样更可控。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=top-p采样>Top-p采样<a href=#top-p采样 class=hash-link aria-label="Direct link to Top-p采样" title="Direct link to Top-p采样">​</a></h3>
<p><code>Top-p</code>采样(<code>Nucleus Sampling</code>)：也叫核采样，从累计概率达到p的最小候选词集合中采样。动态确定候选集大小，概率分布陡峭时集合小(确定性高)，平缓时集合大(多样性高)。比<code>Top-k</code>更灵活自适应。p通常设为0.9-0.95。就像按实力动态划分候选人范围，而不是固定名额。Top-p和温度常配合使用，是现代文本生成的标准配置。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=模型压缩>模型压缩<a href=#模型压缩 class=hash-link aria-label="Direct link to 模型压缩" title="Direct link to 模型压缩">​</a></h3>
<p>模型压缩(<code>Model Compression</code>)：减小模型大小和计算量的技术集合，让大模型能在资源受限设备上运行。主要方法包括剪枝(删除冗余参数)、量化(降低精度)、知识蒸馏(训练小模型模仿大模型)、低秩分解等。压缩后模型体积更小、推理更快、耗电更少，但可能略微损失性能。就像压缩文件或精简装备，在保持核心功能的同时减轻负担。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=剪枝>剪枝<a href=#剪枝 class=hash-link aria-label="Direct link to 剪枝" title="Direct link to 剪枝">​</a></h3>
<p>剪枝(<code>Pruning</code>)：删除神经网络中不重要的参数、连接或神经元，减小模型规模。通过分析参数重要性(如权重大小、梯度等)，移除贡献小的部分，再重新训练恢复性能。可以减少50%-90%参数，速度提升明显，精度略降。就像修剪树枝，去掉冗余枝叶，树木更健壮高效。结构化剪枝(整个通道或层)比非结构化剪枝(零散参数)更利于加速。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=量化>量化<a href=#量化 class=hash-link aria-label="Direct link to 量化" title="Direct link to 量化">​</a></h3>
<p>量化(<code>Quantization</code>)：降低模型参数的数值精度，从32位浮点数(FP32)降到16位(FP16)、8位整数(INT8)甚至更低。减少内存占用(可达4-8倍)和计算量，加快推理速度。量化感知训练(训练时模拟量化)效果更好，训练后量化(直接转换)更简单。就像照片从高清压缩成标清，文件小很多，视觉效果差别不大。是部署大模型到移动设备的关键技术。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=知识蒸馏>知识蒸馏<a href=#知识蒸馏 class=hash-link aria-label="Direct link to 知识蒸馏" title="Direct link to 知识蒸馏">​</a></h3>
<p>知识蒸馏(<code>Knowledge Distillation</code>)：用大模型(教师)的知识训练小模型(学生)，让小模型获得接近大模型的能力。学生模型学习教师的输出分布(软标签)而非原始标签(硬标签)，包含更丰富信息。蒸馏后的小模型运行更快、成本更低，适合部署。就像名师指导徒弟，传授经验技巧，徒弟虽然水平不及师傅但远超自学。是获得高效模型的重要途径。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=模型集成>模型集成<a href=#模型集成 class=hash-link aria-label="Direct link to 模型集成" title="Direct link to 模型集成">​</a></h3>
<p>模型集成(<code>Model Ensemble</code>)：组合多个模型的预测结果，综合它们的优势以获得更好的性能。可以投票(分类)、平均(回归)或加权组合。不同模型犯的错误往往不同，集成可以互补，通常比单个模型更准确稳定，但推理成本成倍增加。就像专家会诊或评委打分，集体决策比个人更可靠。竞赛中常用，生产中权衡成本和收益。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=数据并行>数据并行<a href=#数据并行 class=hash-link aria-label="Direct link to 数据并行" title="Direct link to 数据并行">​</a></h3>
<p>数据并行(<code>Data Parallelism</code>)：将训练数据分成多份，在多个<code>GPU</code>上同时训练相同模型的副本，每个<code>GPU</code>处理不同批次数据。训练完一个批次后，各<code>GPU</code>计算的梯度汇总求平均，然后同步更新所有副本的参数。最常用的并行策略，实现简单效果好。就像工厂多条流水线同时生产相同产品，最后统一质检改进工艺。适合模型能放进单个GPU、但数据量大训练慢的场景。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=模型并行>模型并行<a href=#模型并行 class=hash-link aria-label="Direct link to 模型并行" title="Direct link to 模型并行">​</a></h3>
<p>模型并行(<code>Model Parallelism</code>)：将单个大模型拆分到多个<code>GPU</code>上，每个<code>GPU</code>只存储和计算模型的一部分。当模型太大单个<code>GPU</code>放不下时必须使用。分为层间并行(不同层放不同<code>GPU</code>)和层内并行(单层切分到多<code>GPU</code>)。就像建大楼，一层楼太大一个工地放不下，要分多个区域分别施工，但各区域要协调配合。实现复杂，通信开销大，但能训练超大模型。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=流水线并行>流水线并行<a href=#流水线并行 class=hash-link aria-label="Direct link to 流水线并行" title="Direct link to 流水线并行">​</a></h3>
<p>流水线并行(<code>Pipeline Parallelism</code>)：模型并行的优化版，将模型按层切分成多个阶段(<code>stage</code>)放到不同<code>GPU</code>，像流水线一样依次处理不同批次数据。当第一个<code>GPU</code>处理完第一批数据传给第二个<code>GPU</code>后，不是等待而是立即处理第二批数据，让所有<code>GPU</code>尽可能同时工作。就像工厂流水线，切菜、炒菜、装盘同时进行，提高效率。减少了<code>GPU</code>空闲时间，提升了模型并行的资源利用率。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=张量并行>张量并行<a href=#张量并行 class=hash-link aria-label="Direct link to 张量并行" title="Direct link to 张量并行">​</a></h3>
<p>张量并行(<code>Tensor Parallelism</code>)：在单个算子(层)内部进行并行，将矩阵运算切分到多个<code>GPU</code>协同计算。比如一个大矩阵乘法，把矩阵按行或按列切分，多个<code>GPU</code>各算一部分再合并结果。粒度更细，通信更频繁但能充分利用多<code>GPU</code>算力。就像搬大柜子，一个人搬不动，多人一起抬，每人出一份力。常与流水线并行组合使用，是训练超大模型(如<code>GPT-3</code>、<code>GPT-4</code>)的关键技术。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id=模型评估>模型评估<a href=#模型评估 class=hash-link aria-label="Direct link to 模型评估" title="Direct link to 模型评估">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=训练集>训练集<a href=#训练集 class=hash-link aria-label="Direct link to 训练集" title="Direct link to 训练集">​</a></h3>
<p>训练集(<code>Training Set</code>)：用于训练模型、调整模型参数的数据集，模型通过学习这部分数据掌握规律。占数据集的主要部分(通常<code>60%-80%</code>)。模型会反复"看"训练集数据，不断优化参数以减小预测误差。就像学生的练习题集，用来学习知识和方法。训练集的质量和数量直接影响模型学习效果。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=验证集>验证集<a href=#验证集 class=hash-link aria-label="Direct link to 验证集" title="Direct link to 验证集">​</a></h3>
<p>验证集(<code>Validation Set</code>)：用于调整超参数和模型选择的数据集，不参与模型训练但指导训练过程。训练时定期在验证集上评估性能，用于决定何时停止训练(防止过拟合)、对比不同模型、调整超参数。占数据集<code>10%-20%</code>。就像学生的模拟考试，用来检验学习效果和调整复习策略，但不是最终考核。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=测试集>测试集<a href=#测试集 class=hash-link aria-label="Direct link to 测试集" title="Direct link to 测试集">​</a></h3>
<p>测试集(<code>Test Set</code>)：用于最终评估模型性能的数据集，模型从未见过，也不用于任何训练决策。只在模型完全训练好后使用一次，模拟真实应用场景。占数据集<code>10%-20%</code>。就像正式考试，是对学习成果的最终评判。测试集性能代表模型在未知数据上的真实表现，是向外界报告的指标。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=准确率>准确率<a href=#准确率 class=hash-link aria-label="Direct link to 准确率" title="Direct link to 准确率">​</a></h3>
<p>准确率(<code>Accuracy</code>)：预测正确的样本数占总样本数的比例，最直观的评估指标。公式：<code>准确率 = 正确预测数 / 总样本数</code>。适用于类别平衡的数据。但在类别不平衡时会误导，比如<code>100</code>个样本中<code>99</code>个负例<code>1</code>个正例，模型全预测为负也有<code>99%</code>准确率，实际没学到任何东西。此时需要看精确率、召回率等指标。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=精确率>精确率<a href=#精确率 class=hash-link aria-label="Direct link to 精确率" title="Direct link to 精确率">​</a></h3>
<p>精确率(<code>Precision</code>)：在所有预测为正例的样本中，真正是正例的比例。公式：<code>精确率 = 真正例(TP) / (真正例(TP) + 假正例(FP))</code>。衡量"查准率"或"准确性"，关注预测的可靠性。高精确率意味着误报少。比如垃圾邮件过滤，精确率高说明标记为垃圾的邮件确实是垃圾，正常邮件不会被误杀。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=召回率>召回率<a href=#召回率 class=hash-link aria-label="Direct link to 召回率" title="Direct link to 召回率">​</a></h3>
<p>召回率(<code>Recall</code>)：在所有真实正例中，被正确预测为正例的比例。公式：<code>召回率 = 真正例(TP) / (真正例(TP) + 假负例(FN))</code>。衡量"查全率"或"覆盖率"，关注是否把正例都找出来。高召回率意味着漏报少。比如疾病诊断，召回率高说明患病的人都被检测出来了，不会漏诊。精确率和召回率通常此消彼长，需要权衡。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id=硬件工具>硬件工具<a href=#硬件��工具 class=hash-link aria-label="Direct link to 硬件工具" title="Direct link to 硬件工具">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=gpu>GPU<a href=#gpu class=hash-link aria-label="Direct link to GPU" title="Direct link to GPU">​</a></h3>
<p><code>GPU(Graphics Processing Unit)</code>：图形处理器，原本为图形渲染设计，但其强大的并行计算能力使其成为训练深度学习模型的主力硬件。包含数千个计算核心，擅长同时处理大量简单计算，非常适合神经网络的矩阵运算。<code>NVIDIA</code>的<code>GPU</code>(如<code>RTX</code>、<code>A100</code>、<code>H100</code>系列)占据AI训练市场主导地位。就像工厂流水线，虽然每个工人(核心)能力有限，但数千人同时工作效率惊人。没有<code>GPU</code>，深度学习不可能有今天的发展。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=tpu>TPU<a href=#tpu class=hash-link aria-label="Direct link to TPU" title="Direct link to TPU">​</a></h3>
<p><code>TPU(Tensor Processing Unit)</code>：<code>Google</code>专门为深度学习设计开发的AI专用芯片，针对张量运算深度优化。比通用<code>GPU</code>更高效，功耗更低，专为<code>TensorFlow</code>等框架优化。<code>Google</code>内部大量使用，也通过云服务对外提供。就像专业工具比瑞士军刀在特定任务上更高效，<code>TPU</code>在AI训练和推理上比<code>GPU</code>更专精。代表了AI硬件专用化的趋势。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=cuda>CUDA<a href=#cuda class=hash-link aria-label="Direct link to CUDA" title="Direct link to CUDA">​</a></h3>
<p><code>CUDA(Compute Unified Device Architecture)</code>：<code>NVIDIA</code>开发的并行计算平台和编程模型，让开发者能用<code>GPU</code>加速通用计算任务。提供<code>C/C++</code>扩展和丰富的库(<code>cuDNN</code>、<code>cuBLAS</code>等)，深度学习框架底层大多依赖<code>CUDA</code>。掌握了<code>GPU</code>市场的事实标准，但只支持<code>NVIDIA GPU</code>。就像<code>iOS</code>和<code>iPhone</code>的关系，<code>CUDA</code>把<code>NVIDIA GPU</code>的硬件能力开放给软件开发者，是深度学习生态的关键基础设施。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=gpu-direct>GPU Direct<a href=#gpu-direct class=hash-link aria-label="Direct link to GPU Direct" title="Direct link to GPU Direct">​</a></h3>
<p><code>GPU Direct</code>：<code>NVIDIA</code>的技术，允许<code>GPU</code>之间、<code>GPU</code>与其他设备(如网卡、存储)之间直接传输数据，无需经过<code>CPU</code>和系统内存。包括<code>GPUDirect P2P</code>(<code>GPU</code>间直接通信)、<code>GPUDirect RDMA</code>(<code>GPU</code>与网卡直接通信)等。大幅降低数据传输延迟和<code>CPU</code>开销，提升多<code>GPU</code>训练效率。就像城市间修建直达高速公路，不必绕道中转站，大幅缩短运输时间。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=pcie>PCIe<a href=#pcie class=hash-link aria-label="Direct link to PCIe" title="Direct link to PCIe">​</a></h3>
<p><code>PCIe(Peripheral Component Interconnect Express)</code>：高速串行计算机扩展总线标准，用于连接主板和各种扩展卡(如<code>GPU</code>、网卡、存储卡)。<code>PCIe 3.0 x16</code>提供约<code>16GB/s</code>带宽，<code>PCIe 4.0</code>翻倍，<code>PCIe 5.0</code>再翻倍。<code>GPU</code>通过<code>PCIe</code>与<code>CPU</code>和内存通信，带宽直接影响数据传输效率。在多<code>GPU</code>训练中，<code>PCIe</code>带宽可能成为瓶颈。就像高速公路的车道数，决定了数据流量的上限。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=nvlink>NVLink<a href=#nvlink class=hash-link aria-label="Direct link to NVLink" title="Direct link to NVLink">​</a></h3>
<p><code>NVLink</code>：<code>NVIDIA</code>开发的高速<code>GPU</code>互连技术，提供比<code>PCIe</code>高得多的带宽(单条<code>NVLink 3.0</code>达<code>100GB/s</code>，一个<code>GPU</code>可有多条<code>NVLink</code>)。多个<code>GPU</code>通过<code>NVLink</code>直接互连形成高速网络，大幅提升多<code>GPU</code>间的数据传输速度。训练大模型时，梯度同步、张量并行等需要频繁<code>GPU</code>间通信，<code>NVLink</code>能显著降低通信开销。就像给城市间修建专用高铁，比普通公路</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=nvswitch>NVSwitch<a href=#nvswitch class=hash-link aria-label="Direct link to NVSwitch" title="Direct link to NVSwitch">​</a></h3>
<p><code>NVSwitch</code>：<code>NVIDIA</code>的<code>GPU</code>交换芯片，像网络交换机一样连接多个<code>GPU</code>，让任意两个<code>GPU</code>之间都能通过<code>NVLink</code>高速通信。一个<code>NVSwitch</code>可连接多个<code>GPU</code>，多个<code>NVSwitch</code>可级联构建更大规模的<code>GPU</code>集群。<code>NVIDIA DGX</code>系统使用<code>NVSwitch</code>实现全连接<code>GPU</code>拓扑，最大化通信带宽。就像立交桥，让多条高速公路实现全互联，任意两点都能高速直达。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=rdma>RDMA<a href=#rdma class=hash-link aria-label="Direct link to RDMA" title="Direct link to RDMA">​</a></h3>
<p><code>RDMA(Remote Direct Memory Access)</code>：远程直接内存访问技术，允许一台计算机直接访问另一台计算机的内存，无需操作系统和<code>CPU</code>介入。绕过内核协议栈，实现零拷贝、低延迟、低<code>CPU</code>占用的数据传输。在分布式训练中，节点间需要频繁同步梯度和参数，<code>RDMA</code>能显著降低通信延迟(微秒级)和<code>CPU</code>开销，提升训练效率。就像两个仓库之间开通直达传送带，货物直接传输，不需要人工搬运和中转。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=infiniband>InfiniBand<a href=#infiniband class=hash-link aria-label="Direct link to InfiniBand" title="Direct link to InfiniBand">​</a></h3>
<p><code>InfiniBand(IB)</code>：高性能计算网络标准，原生支持<code>RDMA</code>，提供极高带宽(单链路<code>400Gbps</code>起)和极低延迟(亚微秒级)。是<code>HPC</code>(高性能计算)和AI训练集群的首选网络方案，广泛用于超算中心和大型AI训练集群。支持多种拓扑结构(胖树、<code>Dragonfly</code>等)，具有强大的<code>QoS</code>保障和拥塞控制能力。就像专为高速运输设计的磁悬浮列车系统，速度快、延迟低、可靠性高。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=roce>RoCE<a href=#roce class=hash-link aria-label="Direct link to RoCE" title="Direct link to RoCE">​</a></h3>
<p><code>RoCE(RDMA over Converged Ethernet)</code>：在以太网上实现<code>RDMA</code>的技术，让普通以太网也能享受<code>RDMA</code>的高性能。有两个版本：<code>RoCE v1</code>基于以太网二层，<code>RoCE v2</code>基于三层可路由，更灵活实用。相比<code>InfiniBand</code>成本更低，可以利用现有以太网基础设施。<code>RoCE v2</code>已成为云数据中心和企业AI集群的主流选择，平衡了性能和成本。就像在普通公路上开高速专线，比修建专用高速路便宜，性能也不错。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=iwarp>iWARP<a href=#iwarp class=hash-link aria-label="Direct link to iWARP" title="Direct link to iWARP">​</a></h3>
<p><code>iWARP(Internet Wide Area RDMA Protocol)</code>：另一种在以太网上实现<code>RDMA</code>的技术，基于<code>TCP/IP</code>协议栈。相比<code>RoCE</code>，<code>iWARP</code>对网络设备要求更低，兼容性更好，可以跨越路由器和防火墙。但性能略逊于<code>RoCE</code>和<code>InfiniBand</code>，<code>CPU</code>开销稍高。适合需要跨广域网或复杂网络环境的场景。就像在传统交通系统上增加快速通道，兼容性强但速度稍逊于专用系统。快几倍。</div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href=/ai/basic><div class=pagination-nav__sublabel>Previous</div><div class=pagination-nav__label>入门知识</div></a><a class="pagination-nav__link pagination-nav__link--next" href=/ai/general-ai-model-and-thinking-ai-model-difference><div class=pagination-nav__sublabel>Next</div><div class=pagination-nav__label>通用大模型和思维大模型区别</div></a></nav><div class=docusaurus-mt-lg></div></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href=#基础概念 class="table-of-contents__link toc-highlight">基础概念</a><ul><li><a href=#大语言模型 class="table-of-contents__link toc-highlight">大语言模型</a><li><a href=#基础模型 class="table-of-contents__link toc-highlight">基础模型</a><li><a href=#多模态模型 class="table-of-contents__link toc-highlight">多模态模型</a><li><a href=#思维链 class="table-of-contents__link toc-highlight">思维链</a><li><a href=#检索增强生成 class="table-of-contents__link toc-highlight">检索增强生成</a><li><a href=#提示调优 class="table-of-contents__link toc-highlight">提示调优</a><li><a href=#幻觉 class="table-of-contents__link toc-highlight">幻觉</a><li><a href=#温度 class="table-of-contents__link toc-highlight">温度</a></ul><li><a href=#机器学习 class="table-of-contents__link toc-highlight">机器学习</a><ul><li><a href=#机器学习-1 class="table-of-contents__link toc-highlight">机器学习</a><li><a href=#监督学习 class="table-of-contents__link toc-highlight">监督学习</a><li><a href=#无监督学习 class="table-of-contents__link toc-highlight">无监督学习</a><li><a href=#半监督学习 class="table-of-contents__link toc-highlight">半监督学习</a><li><a href=#强化学习 class="table-of-contents__link toc-highlight">强化学习</a></ul><li><a href=#训练微调 class="table-of-contents__link toc-highlight">训练微调</a><ul><li><a href=#预训练 class="table-of-contents__link toc-highlight">预训练</a><li><a href=#增量预训练 class="table-of-contents__link toc-highlight">增量预训练</a><li><a href=#微调 class="table-of-contents__link toc-highlight">微调</a><li><a href=#张量 class="table-of-contents__link toc-highlight">张量</a><li><a href=#tensorflow class="table-of-contents__link toc-highlight">TensorFlow</a><li><a href=#pytorch class="table-of-contents__link toc-highlight">PyTorch</a><li><a href=#损失函数 class="table-of-contents__link toc-highlight">损失函数</a><li><a href=#梯度 class="table-of-contents__link toc-highlight">梯度</a><li><a href=#梯度下降 class="table-of-contents__link toc-highlight">梯度下降</a><li><a href=#反向传播 class="table-of-contents__link toc-highlight">反向传播</a><li><a href=#过拟合 class="table-of-contents__link toc-highlight">过拟合</a><li><a href=#欠拟合 class="table-of-contents__link toc-highlight">欠拟合</a><li><a href=#超参数 class="table-of-contents__link toc-highlight">超参数</a><li><a href=#超参数调优 class="table-of-contents__link toc-highlight">超参数调优</a><li><a href=#参数高效微调 class="table-of-contents__link toc-highlight">参数高效微调</a><li><a href=#lora class="table-of-contents__link toc-highlight">LoRA</a><li><a href=#指令微调 class="table-of-contents__link toc-highlight">指令微调</a><li><a href=#有监督微调 class="table-of-contents__link toc-highlight">有监督微调</a><li><a href=#强化微调 class="table-of-contents__link toc-highlight">强化微调</a><li><a href=#人类偏好对齐 class="table-of-contents__link toc-highlight">人类偏好对齐</a><li><a href=#top-k采样 class="table-of-contents__link toc-highlight">Top-k采样</a><li><a href=#top-p采样 class="table-of-contents__link toc-highlight">Top-p采样</a><li><a href=#模型压缩 class="table-of-contents__link toc-highlight">模型压缩</a><li><a href=#剪枝 class="table-of-contents__link toc-highlight">剪枝</a><li><a href=#量化 class="table-of-contents__link toc-highlight">量化</a><li><a href=#知识蒸馏 class="table-of-contents__link toc-highlight">知识蒸馏</a><li><a href=#模型集成 class="table-of-contents__link toc-highlight">模型集成</a><li><a href=#数据并行 class="table-of-contents__link toc-highlight">数据并行</a><li><a href=#模型并行 class="table-of-contents__link toc-highlight">模型并行</a><li><a href=#流水线并行 class="table-of-contents__link toc-highlight">流水线并行</a><li><a href=#张量并行 class="table-of-contents__link toc-highlight">张量并行</a></ul><li><a href=#模型评估 class="table-of-contents__link toc-highlight">模型评估</a><ul><li><a href=#训练集 class="table-of-contents__link toc-highlight">训练集</a><li><a href=#验证集 class="table-of-contents__link toc-highlight">验证集</a><li><a href=#测试集 class="table-of-contents__link toc-highlight">测试集</a><li><a href=#准确率 class="table-of-contents__link toc-highlight">准确率</a><li><a href=#精确率 class="table-of-contents__link toc-highlight">精确率</a><li><a href=#召回率 class="table-of-contents__link toc-highlight">召回率</a></ul><li><a href=#硬件工具 class="table-of-contents__link toc-highlight">硬件工具</a><ul><li><a href=#gpu class="table-of-contents__link toc-highlight">GPU</a><li><a href=#tpu class="table-of-contents__link toc-highlight">TPU</a><li><a href=#cuda class="table-of-contents__link toc-highlight">CUDA</a><li><a href=#gpu-direct class="table-of-contents__link toc-highlight">GPU Direct</a><li><a href=#pcie class="table-of-contents__link toc-highlight">PCIe</a><li><a href=#nvlink class="table-of-contents__link toc-highlight">NVLink</a><li><a href=#nvswitch class="table-of-contents__link toc-highlight">NVSwitch</a><li><a href=#rdma class="table-of-contents__link toc-highlight">RDMA</a><li><a href=#infiniband class="table-of-contents__link toc-highlight">InfiniBand</a><li><a href=#roce class="table-of-contents__link toc-highlight">RoCE</a><li><a href=#iwarp class="table-of-contents__link toc-highlight">iWARP</a></ul></ul></div></div></div></div></main></div></div></div><footer class=footer><div class="container container-fluid"><div class="footer__bottom text--center"><div class=footer__copyright>Copyright 2026 johng.cn</div></div></div></footer></div>