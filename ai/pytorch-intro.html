<!doctype html><html lang=en dir=ltr class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-docs/AI技术/训练微调/开发训练框架/Pytorch/Pytorch框架介绍" data-has-hydrated=false><meta charset=UTF-8><meta name=generator content="Docusaurus v3.6.3"><title data-rh=true>PyTorch框架介绍 | John's Blog</title><meta data-rh=true name=viewport content="width=device-width,initial-scale=1.0"><meta data-rh=true name=twitter:card content=summary_large_image><meta data-rh=true property=og:url content=https://johng.cn/ai/pytorch-intro><meta data-rh=true property=og:locale content=en><meta data-rh=true name=docusaurus_locale content=en><meta data-rh=true name=docsearch:language content=en><meta data-rh=true name=author content="John Guo"><meta data-rh=true property=og:image content=https://johng.cn/img/favicon.png><meta data-rh=true name=docusaurus_version content=current><meta data-rh=true name=docusaurus_tag content=docs-default-current><meta data-rh=true name=docsearch:version content=current><meta data-rh=true name=docsearch:docusaurus_tag content=docs-default-current><meta data-rh=true property=og:title content="PyTorch框架介绍 | John's Blog"><meta data-rh=true name=description content=深入介绍PyTorch深度学习框架的核心概念和使用方法。详细讲解PyTorch是什么、解决什么问题，以及它的核心特性如张量计算、自动求导、动态计算图等。重点介绍PyTorch的分布式训练能力，包括关键环境变量的配置和使用。全面阐述PyTorch支持的多种并行计算策略，包括数据并行、模型并行、流水线并行和混合并行等技术方案。通过精简的代码示例帮助读者快速掌握PyTorch的使用方法，为AI模型开发和训练提供完整的技术指导。><meta data-rh=true property=og:description content=深入介绍PyTorch深度学习框架的核心概念和使用方法。详细讲解PyTorch是什么、解决什么问题，以及它的核心特性如张量计算、自动求导、动态计算图等。重点介绍PyTorch的分布式训练能力，包括关键环境变量的配置和使用。全面阐述PyTorch支持的多种并行计算策略，包括数据并行、模型并行、流水线并行和混合并行等技术方案。通过精简的代码示例帮助读者快速掌握PyTorch的使用方法，为AI模型开发和训练提供完整的技术指导。><meta data-rh=true name=keywords content="PyTorch,深度学习框架,神经网络,张量计算,自动求导,梯度计算,动态计算图,GPU加速,分布式训练,模型训练,机器学习,AI框架,深度学习,Python深度学习,开源框架,Facebook AI,模型开发,训练框架"><link data-rh=true rel=icon href=/img/favicon.ico><link data-rh=true rel=canonical href=https://johng.cn/ai/pytorch-intro><link data-rh=true rel=alternate href=https://johng.cn/ai/pytorch-intro hreflang=en><link data-rh=true rel=alternate href=https://johng.cn/ai/pytorch-intro hreflang=x-default><link data-rh=true rel=preconnect href=https://XGS1CPQERK-dsn.algolia.net crossorigin><link rel=alternate type=application/rss+xml href=/blog/rss.xml title="John's Blog RSS Feed"><link rel=alternate type=application/atom+xml href=/blog/atom.xml title="John's Blog Atom Feed"><link rel=search type=application/opensearchdescription+xml title="John's Blog" href=/opensearch.xml><script src=https://hm.baidu.com/hm.js?6b4ae23dc83ee5efe875b7172af6c7c1 async></script><link rel=stylesheet href=/assets/css/styles.2ece4f8a.css><script src=/assets/js/runtime~main.ba8776ac.js defer></script><script src=/assets/js/main.d69f8fc0.js defer></script><body class=navigation-with-keyboard><script>!function(){var t,e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t=null!==e?e:"light",document.documentElement.setAttribute("data-theme",t)}(),function(){try{for(var[t,e]of new URLSearchParams(window.location.search).entries())if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id=__docusaurus><div role=region aria-label="Skip to main content"><a class=skipToContent_fXgn href=#__docusaurus_skipToContent_fallback>Skip to main content</a></div><nav aria-label=Main class="navbar navbar--fixed-top"><div class=navbar__inner><div class=navbar__items><button aria-label="Toggle navigation bar" aria-expanded=false class="navbar__toggle clean-btn" type=button><svg width=30 height=30 viewBox="0 0 30 30" aria-hidden=true><path stroke=currentColor stroke-linecap=round stroke-miterlimit=10 stroke-width=2 d="M4 7h22M4 15h22M4 23h22"/></svg></button><a class=navbar__brand href=/><b class="navbar__title text--truncate">John's Blog</b></a><a aria-current=page class="navbar__item navbar__link navbar__link--active" href=/ai>AI技术</a><a class="navbar__item navbar__link" href=/cloud-native>云原生</a><a class="navbar__item navbar__link" href=/notes>日常笔记</a><a class="navbar__item navbar__link" href=/programming>开发语言</a><a class="navbar__item navbar__link" href=/architecture>技术架构</a><a class="navbar__item navbar__link" href=/observability>可观测性</a><a class="navbar__item navbar__link" href=/life>生活笔记</a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href=/aboutme>关于我</a><a class="navbar__item navbar__link" href=/blog>博客</a><a href=https://goframe.org/ target=_blank rel="noopener noreferrer" class="navbar__item navbar__link header-goframe-link"></a><a href=https://github.com/gqcn target=_blank rel="noopener noreferrer" class="navbar__item navbar__link header-github-link"></a><div class=navbarSearchContainer_Bca1><button type=button class="DocSearch DocSearch-Button" aria-label="Search (Command+K)"><span class=DocSearch-Button-Container><svg width=20 height=20 class=DocSearch-Search-Icon viewBox="0 0 20 20" aria-hidden=true><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke=currentColor fill=none fill-rule=evenodd stroke-linecap=round stroke-linejoin=round /></svg><span class=DocSearch-Button-Placeholder>Search</span></span><span class=DocSearch-Button-Keys></span></button></div></div></div><div role=presentation class=navbar-sidebar__backdrop></div></nav><div id=__docusaurus_skipToContent_fallback class="main-wrapper mainWrapper_z2l0"><div class=docsWrapper_hBAB><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type=button></button><div class=docRoot_UBD9><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class=sidebarViewport_aRkj><div class=sidebar_njMd><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--active" href=/ai>AI技术</a><button aria-label="Collapse sidebar category 'AI技术'" aria-expanded=true type=button class="clean-btn menu__caret"></button></div><ul style=display:block;overflow:visible;height:auto class=menu__list><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--sublist-caret" role=button aria-expanded=false tabindex=0 href=/ai/agents-deep-dive-from-llm-to-autonomous-agents>智能体</a></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--sublist-caret" role=button aria-expanded=false tabindex=0 href=/ai/copilot-skills-guide>应用开发</a></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--sublist-caret" role=button aria-expanded=false tabindex=0 href=/ai/online-offline-batch-inference>推理服务</a></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role=button aria-expanded=true tabindex=0 href=/ai/hpc-development-training-platform>训练微调</a></div><ul style=display:block;overflow:visible;height:auto class=menu__list><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--sublist-caret" role=button aria-expanded=false tabindex=0 href=/ai/hpc-development-training-platform>开发训练平台</a></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role=button aria-expanded=true tabindex=0 href=/ai/pytorch-intro>开发训练框架</a></div><ul style=display:block;overflow:visible;height:auto class=menu__list><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role=button aria-expanded=true tabindex=0 href=/ai/pytorch-intro>Pytorch</a></div><ul style=display:block;overflow:visible;height:auto class=menu__list><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link menu__link--active" aria-current=page tabindex=0 href=/ai/pytorch-intro>PyTorch框架介绍</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class=menu__link tabindex=0 href=/ai/volcano-pytorch-plugin>Volcano Job PyTorch Plugin调研测试</a></ul></ul><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--sublist-caret" role=button aria-expanded=false tabindex=0 href=/ai/kubeflow-trainer-in-hpc>Kubeflow Trainer</a></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--sublist-caret" role=button aria-expanded=false tabindex=0 href=/ai/ray-distributed-computing>Ray分布式计算引擎</a></div><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/ai/machine-learning-fundamentals>AI模型与机器学习</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/ai/training>AI模型训练技术详解</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/ai/fine-tuning>AI模型微调技术详解</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/ai/training-parallel-strategies>AI模型训练并行策略介绍</a></ul><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" tabindex=0 href=/ai/model-development>模型开发</a><button aria-label="Expand sidebar category '模型开发'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--sublist-caret" role=button aria-expanded=false tabindex=0 href=/ai/rdma-brief>基础架构</a></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--sublist-caret" role=button aria-expanded=false tabindex=0 href=/ai/basic-terminology>入门知识</a></div></ul><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/cloud-native>云原生</a><button aria-label="Expand sidebar category '云原生'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/notes>日常笔记</a><button aria-label="Expand sidebar category '日常笔记'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/programming>开发语言</a><button aria-label="Expand sidebar category '开发语言'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/architecture>技术架构</a><button aria-label="Expand sidebar category '技术架构'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/management>技术管理</a><button aria-label="Expand sidebar category '技术管理'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/observability>可观测性</a><button aria-label="Expand sidebar category '可观测性'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/database-and-middleware>数据库与中间件</a><button aria-label="Expand sidebar category '数据库与中间件'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/operating-systems-and-networks>操作系统和网络</a><button aria-label="Expand sidebar category '操作系统和网络'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/life>生活笔记</a><button aria-label="Expand sidebar category '生活笔记'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div></ul></nav></div></div></aside><main class=docMainContainer_TBSr><div class="container padding-top--md padding-bottom--lg"><div class=row><div class="col docItemCol_VOVn"><div class=docItemContainer_Djhp><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label=Breadcrumbs><ul class=breadcrumbs itemscope itemtype=https://schema.org/BreadcrumbList><li class=breadcrumbs__item><a aria-label="Home page" class=breadcrumbs__link href=/><svg viewBox="0 0 24 24" class=breadcrumbHomeIcon_YNFT><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill=currentColor /></svg></a><li itemscope itemprop=itemListElement itemtype=https://schema.org/ListItem class=breadcrumbs__item><a class=breadcrumbs__link itemprop=item href=/ai><span itemprop=name>AI技术</span></a><meta itemprop=position content=1><li class=breadcrumbs__item><span class=breadcrumbs__link>训练微调</span><meta itemprop=position content=2><li class=breadcrumbs__item><span class=breadcrumbs__link>开发训练框架</span><meta itemprop=position content=3><li class=breadcrumbs__item><span class=breadcrumbs__link>Pytorch</span><meta itemprop=position content=4><li itemscope itemprop=itemListElement itemtype=https://schema.org/ListItem class="breadcrumbs__item breadcrumbs__item--active"><span class=breadcrumbs__link itemprop=name>PyTorch框架介绍</span><meta itemprop=position content=5></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type=button class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>前置知识</div><div class=admonitionContent_BuS1><p>本文重点讲解<code>PyTorch</code>框架技术。建议先了解<code>AI</code>模型训练的基本概念、神经网络基础知识，请参考 <a href=/ai/training>AI模型训练技术详解</a>。</div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id=pytorch是什么>PyTorch是什么<a href=#pytorch是什么 class=hash-link aria-label="Direct link to PyTorch是什么" title="Direct link to PyTorch是什么">​</a></h2>
<p><code>PyTorch</code>是由<code>Facebook AI Research (FAIR)</code>开发的开源深度学习框架，于<code>2016</code>年首次发布。它是目前最流行的深度学习框架之一，与<code>TensorFlow</code>并列为业界主流选择。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=核心定位>核心定位<a href=#核心定位 class=hash-link aria-label="Direct link to 核心定位" title="Direct link to 核心定位">​</a></h3>
<p><code>PyTorch</code>本质上是一个<strong>基于<code>Python</code>的科学计算库</strong>，专门针对深度学习和神经网络训练进行了优化。它提供了两个核心功能：</p>
<ol>
<li><strong>强大的<code>GPU</code>加速张量计算</strong>（类似<code>NumPy</code>但支持<code>GPU</code>）</li>
<li><strong>基于自动微分系统的深度神经网络</strong>（自动计算梯度）</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=通俗理解>通俗理解<a href=#通俗理解 class=hash-link aria-label="Direct link to 通俗理解" title="Direct link to 通俗理解">​</a></h3>
<p>如果把深度学习比作烹饪，那么：</p>
<ul>
<li><strong>神经网络</strong>就像菜谱（定义了做菜的步骤）</li>
<li><strong>训练数据</strong>就像食材（模型学习的原料）</li>
<li><strong>PyTorch</strong>就是厨房里的工具和设备（让你能高效地按照菜谱做菜）</li>
</ul>
<p><code>PyTorch</code>提供了从切菜板（张量操作）、炉灶（计算设备）到自动计时器（自动求导）的全套工具，让你能够专注于设计菜谱（模型架构）而不用担心底层的实现细节。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id=pytorch解决什么问题>PyTorch解决什么问题<a href=#pytorch解决什么问题 class=hash-link aria-label="Direct link to PyTorch解决什么问题" title="Direct link to PyTorch解决什么问题">​</a></h2>
<p>在<code>PyTorch</code>出现之前，深度学习开发者面临诸多挑战，<code>PyTorch</code>针对性地解决了这些痛点。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=主要解决的问题>主要解决的问题<a href=#主要解决的问题 class=hash-link aria-label="Direct link to 主要解决的问题" title="Direct link to 主要解决的问题">​</a></h3>
<table><thead><tr><th>问题领域<th>传统困境<th>PyTorch的解决方案<th>价值<tbody><tr><td><strong>计算效率</strong><td><code>NumPy</code>只能用<code>CPU</code>，大规模计算很慢<td>支持<code>GPU/TPU</code>加速的张量计算<td>训练速度提升<code>10-100</code>倍<tr><td><strong>梯度计算</strong><td>手动推导和编写反向传播代码，容易出错<td>自动求导系统<code>Autograd</code><td>自动计算梯度，减少<code>90%+</code>代码量<tr><td><strong>开发体验</strong><td>静态计算图需要先编译，调试困难<td>动态计算图，像写普通<code>Python</code>代码<td>开发效率提升<code>3-5</code>倍<tr><td><strong>分布式训练</strong><td>多机多卡训练配置复杂，代码难写<td>内置分布式训练支持<td>简化大规模训练实现<tr><td><strong>模型部署</strong><td>训练和部署用不同框架，转换麻烦<td>支持<code>TorchScript</code>导出和优化<td>统一开发和部署流程</table>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=核心特性详解>核心特性详解<a href=#核心特性详解 class=hash-link aria-label="Direct link to 核心特性详解" title="Direct link to 核心特性详解">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=张量计算tensor>张量计算（Tensor）<a href=#张量计算tensor class=hash-link aria-label="Direct link to 张量计算（Tensor）" title="Direct link to 张量计算（Tensor）">​</a></h4>
<p><strong>张量</strong>是<code>PyTorch</code>的基础数据结构，类似<code>NumPy</code>的数组，但可以在<code>GPU</code>上运行。</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#f8f8f2;--prism-background-color:#272822><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-python codeBlock_bY9V thin-scrollbar" style=color:#f8f8f2;background-color:#272822><code class=codeBlockLines_e6Vv><span class=token-line style=color:#f8f8f2><span class="token keyword" style=color:#66d9ef>import</span><span class="token plain"> torch</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain" style=display:inline-block></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token comment" style=color:#8292a2;font-style:italic># 创建张量</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">x </span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain"> torch</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">tensor</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token punctuation" style=color:#f8f8f2>[</span><span class="token punctuation" style=color:#f8f8f2>[</span><span class="token number" style=color:#ae81ff>1</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain"> </span><span class="token number" style=color:#ae81ff>2</span><span class="token punctuation" style=color:#f8f8f2>]</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain"> </span><span class="token punctuation" style=color:#f8f8f2>[</span><span class="token number" style=color:#ae81ff>3</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain"> </span><span class="token number" style=color:#ae81ff>4</span><span class="token punctuation" style=color:#f8f8f2>]</span><span class="token punctuation" style=color:#f8f8f2>]</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain" style=display:inline-block></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token comment" style=color:#8292a2;font-style:italic># GPU加速计算</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token keyword" style=color:#66d9ef>if</span><span class="token plain"> torch</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">cuda</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">is_available</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token punctuation" style=color:#f8f8f2>:</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    x </span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain"> x</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">cuda</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain">  </span><span class="token comment" style=color:#8292a2;font-style:italic># 移到GPU</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    y </span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain"> x </span><span class="token operator" style=color:#66d9ef>*</span><span class="token plain"> </span><span class="token number" style=color:#ae81ff>2</span><span class="token plain">     </span><span class="token comment" style=color:#8292a2;font-style:italic># GPU上进行计算</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label="Copy code to clipboard" title=Copy class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<p><strong>价值</strong>：</p>
<ul>
<li>支持<code>GPU/TPU</code>加速，比<code>NumPy</code>快<code>10-100</code>倍</li>
<li>与<code>NumPy</code>语法相似，学习成本低</li>
<li>无缝切换<code>CPU</code>和<code>GPU</code></li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=自动求导autograd>自动求导（Autograd）<a href=#自动求导autograd class=hash-link aria-label="Direct link to 自动求导（Autograd）" title="Direct link to 自动求导（Autograd）">​</a></h4>
<p><strong>自动求导</strong>是<code>PyTorch</code>的核心特性，能自动计算梯度，无需手动推导反向传播。</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#f8f8f2;--prism-background-color:#272822><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-python codeBlock_bY9V thin-scrollbar" style=color:#f8f8f2;background-color:#272822><code class=codeBlockLines_e6Vv><span class=token-line style=color:#f8f8f2><span class="token comment" style=color:#8292a2;font-style:italic># 定义需要梯度的张量</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">x </span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain"> torch</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">tensor</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token number" style=color:#ae81ff>2.0</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain"> requires_grad</span><span class="token operator" style=color:#66d9ef>=</span><span class="token boolean" style=color:#ae81ff>True</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">y </span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain"> torch</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">tensor</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token number" style=color:#ae81ff>3.0</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain"> requires_grad</span><span class="token operator" style=color:#66d9ef>=</span><span class="token boolean" style=color:#ae81ff>True</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain" style=display:inline-block></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token comment" style=color:#8292a2;font-style:italic># 前向计算</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">z </span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain"> x </span><span class="token operator" style=color:#66d9ef>**</span><span class="token plain"> </span><span class="token number" style=color:#ae81ff>2</span><span class="token plain"> </span><span class="token operator" style=color:#66d9ef>+</span><span class="token plain"> y </span><span class="token operator" style=color:#66d9ef>**</span><span class="token plain"> </span><span class="token number" style=color:#ae81ff>3</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain" style=display:inline-block></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token comment" style=color:#8292a2;font-style:italic># 自动计算梯度</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">z</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">backward</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain" style=display:inline-block></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token keyword" style=color:#66d9ef>print</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token string-interpolation string" style=color:#a6e22e>f"dz/dx = </span><span class="token string-interpolation interpolation punctuation" style=color:#f8f8f2>{</span><span class="token string-interpolation interpolation">x</span><span class="token string-interpolation interpolation punctuation" style=color:#f8f8f2>.</span><span class="token string-interpolation interpolation">grad</span><span class="token string-interpolation interpolation punctuation" style=color:#f8f8f2>}</span><span class="token string-interpolation string" style=color:#a6e22e>"</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain">  </span><span class="token comment" style=color:#8292a2;font-style:italic># 输出: 4.0 (即 2*x)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token keyword" style=color:#66d9ef>print</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token string-interpolation string" style=color:#a6e22e>f"dz/dy = </span><span class="token string-interpolation interpolation punctuation" style=color:#f8f8f2>{</span><span class="token string-interpolation interpolation">y</span><span class="token string-interpolation interpolation punctuation" style=color:#f8f8f2>.</span><span class="token string-interpolation interpolation">grad</span><span class="token string-interpolation interpolation punctuation" style=color:#f8f8f2>}</span><span class="token string-interpolation string" style=color:#a6e22e>"</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain">  </span><span class="token comment" style=color:#8292a2;font-style:italic># 输出: 27.0 (即 3*y^2)</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label="Copy code to clipboard" title=Copy class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<p><strong>价值</strong>：</p>
<ul>
<li>自动计算任意复杂函数的梯度</li>
<li>不需要手动推导数学公式</li>
<li>支持高阶导数</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=动态计算图>动态计算图<a href=#动态计算图 class=hash-link aria-label="Direct link to 动态计算图" title="Direct link to 动态计算图">​</a></h4>
<p><code>PyTorch</code>采用<strong>动态计算图</strong>（<code>Define-by-Run</code>），每次前向传播都会构建新的计算图。</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#f8f8f2;--prism-background-color:#272822><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-python codeBlock_bY9V thin-scrollbar" style=color:#f8f8f2;background-color:#272822><code class=codeBlockLines_e6Vv><span class=token-line style=color:#f8f8f2><span class="token keyword" style=color:#66d9ef>import</span><span class="token plain"> torch</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">nn </span><span class="token keyword" style=color:#66d9ef>as</span><span class="token plain"> nn</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain" style=display:inline-block></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token comment" style=color:#8292a2;font-style:italic># 动态控制流</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token keyword" style=color:#66d9ef>def</span><span class="token plain"> </span><span class="token function" style=color:#e6db74>forward</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token plain">x</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain"> use_relu</span><span class="token operator" style=color:#66d9ef>=</span><span class="token boolean" style=color:#ae81ff>True</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token punctuation" style=color:#f8f8f2>:</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    x </span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain"> nn</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">Linear</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token number" style=color:#ae81ff>10</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain"> </span><span class="token number" style=color:#ae81ff>10</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token plain">x</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    </span><span class="token keyword" style=color:#66d9ef>if</span><span class="token plain"> use_relu</span><span class="token punctuation" style=color:#f8f8f2>:</span><span class="token plain">  </span><span class="token comment" style=color:#8292a2;font-style:italic># 运行时决定是否使用ReLU</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">        x </span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain"> torch</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">relu</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token plain">x</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    </span><span class="token keyword" style=color:#66d9ef>return</span><span class="token plain"> x</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label="Copy code to clipboard" title=Copy class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<p><strong>对比静态计算图</strong>（如早期的<code>TensorFlow 1.x</code>）：</p>
<table><thead><tr><th>特性<th>动态计算图（PyTorch）<th>静态计算图（TensorFlow 1.x）<tbody><tr><td><strong>定义方式</strong><td>边运行边构建<td>先定义后运行<tr><td><strong>调试</strong><td>可用<code>Python</code>调试器<td>需要特殊工具<tr><td><strong>灵活性</strong><td>支持任意<code>Python</code>控制流<td>受限于框架API<tr><td><strong>性能优化</strong><td>较难优化<td>可提前优化整个图</table>
<p><strong>价值</strong>：</p>
<ul>
<li>像写普通<code>Python</code>代码一样自然</li>
<li>调试方便，可使用<code>print</code>、断点等</li>
<li>支持动态结构（如可变长序列）</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=与其他框架对比>与其他框架对比<a href=#与其他框架对比 class=hash-link aria-label="Direct link to 与其他框架对比" title="Direct link to 与其他框架对比">​</a></h3>
<table><thead><tr><th>框架<th>发布时间<th>特点<th>适用场景<tbody><tr><td><strong>PyTorch</strong><td><code>2016</code><td>动态图、<code>Python</code>风格、易用性强<td>研究、快速原型开发<tr><td><strong>TensorFlow</strong><td><code>2015</code><td>生态完善、部署能力强<td>工业生产、大规模部署<tr><td><strong>JAX</strong><td><code>2018</code><td>函数式编程、可自动向量化<td>研究、性能极致优化<tr><td><strong>MXNet</strong><td><code>2015</code><td>多语言支持、云原生<td>云端训练推理</table>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id=pytorch核心组件>PyTorch核心组件<a href=#pytorch核心组件 class=hash-link aria-label="Direct link to PyTorch核心组件" title="Direct link to PyTorch核心组件">​</a></h2>
<p><code>PyTorch</code>采用模块化设计，主要包含以下核心组件：</p>
<!-- -->
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=核心模块说明>核心模块说明<a href=#核心模块说明 class=hash-link aria-label="Direct link to 核心模块说明" title="Direct link to 核心模块说明">​</a></h3>
<table><thead><tr><th>模块<th>功能<th>典型用法<tbody><tr><td><strong>torch</strong><td>张量操作和数学运算<td><code>torch.tensor()</code>, <code>torch.matmul()</code><tr><td><strong>torch.nn</strong><td>神经网络层和模型<td><code>nn.Linear()</code>, <code>nn.Conv2d()</code><tr><td><strong>torch.optim</strong><td>优化器<td><code>optim.Adam()</code>, <code>optim.SGD()</code><tr><td><strong>torch.autograd</strong><td>自动求导<td><code>tensor.backward()</code>, <code>torch.autograd.grad()</code><tr><td><strong>torch.utils.data</strong><td>数据加载<td><code>Dataset</code>, <code>DataLoader</code><tr><td><strong>torch.distributed</strong><td>分布式训练<td><code>DistributedDataParallel</code>, <code>init_process_group()</code></table>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=简单训练示例>简单训练示例<a href=#简单训练示例 class=hash-link aria-label="Direct link to 简单训练示例" title="Direct link to 简单训练示例">​</a></h3>
<p>下面是一个完整的模型训练示例，展示了<code>PyTorch</code>的基本使用流程：</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#f8f8f2;--prism-background-color:#272822><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-python codeBlock_bY9V thin-scrollbar" style=color:#f8f8f2;background-color:#272822><code class=codeBlockLines_e6Vv><span class=token-line style=color:#f8f8f2><span class="token keyword" style=color:#66d9ef>import</span><span class="token plain"> torch</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token keyword" style=color:#66d9ef>import</span><span class="token plain"> torch</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">nn </span><span class="token keyword" style=color:#66d9ef>as</span><span class="token plain"> nn</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token keyword" style=color:#66d9ef>import</span><span class="token plain"> torch</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">optim </span><span class="token keyword" style=color:#66d9ef>as</span><span class="token plain"> optim</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain" style=display:inline-block></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token comment" style=color:#8292a2;font-style:italic># 1. 定义模型</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token keyword" style=color:#66d9ef>class</span><span class="token plain"> </span><span class="token class-name" style=color:#e6db74>SimpleModel</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token plain">nn</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">Module</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token punctuation" style=color:#f8f8f2>:</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    </span><span class="token keyword" style=color:#66d9ef>def</span><span class="token plain"> </span><span class="token function" style=color:#e6db74>__init__</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token plain">self</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token punctuation" style=color:#f8f8f2>:</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">        </span><span class="token builtin" style=color:#e6db74>super</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">__init__</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">        self</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">fc1 </span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain"> nn</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">Linear</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token number" style=color:#ae81ff>10</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain"> </span><span class="token number" style=color:#ae81ff>5</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">        self</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">fc2 </span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain"> nn</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">Linear</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token number" style=color:#ae81ff>5</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain"> </span><span class="token number" style=color:#ae81ff>1</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    </span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    </span><span class="token keyword" style=color:#66d9ef>def</span><span class="token plain"> </span><span class="token function" style=color:#e6db74>forward</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token plain">self</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain"> x</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token punctuation" style=color:#f8f8f2>:</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">        x </span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain"> torch</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">relu</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token plain">self</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">fc1</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token plain">x</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">        </span><span class="token keyword" style=color:#66d9ef>return</span><span class="token plain"> self</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">fc2</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token plain">x</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain" style=display:inline-block></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token comment" style=color:#8292a2;font-style:italic># 2. 创建模型、损失函数和优化器</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">model </span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain"> SimpleModel</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">criterion </span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain"> nn</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">MSELoss</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">optimizer </span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain"> optim</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">Adam</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token plain">model</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">parameters</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain"> lr</span><span class="token operator" style=color:#66d9ef>=</span><span class="token number" style=color:#ae81ff>0.001</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain" style=display:inline-block></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token comment" style=color:#8292a2;font-style:italic># 3. 训练循环</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token keyword" style=color:#66d9ef>for</span><span class="token plain"> epoch </span><span class="token keyword" style=color:#66d9ef>in</span><span class="token plain"> </span><span class="token builtin" style=color:#e6db74>range</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token number" style=color:#ae81ff>100</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token punctuation" style=color:#f8f8f2>:</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    </span><span class="token comment" style=color:#8292a2;font-style:italic># 前向传播</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    x </span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain"> torch</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">randn</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token number" style=color:#ae81ff>32</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain"> </span><span class="token number" style=color:#ae81ff>10</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain">  </span><span class="token comment" style=color:#8292a2;font-style:italic># 批次数据</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    y </span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain"> torch</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">randn</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token number" style=color:#ae81ff>32</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain"> </span><span class="token number" style=color:#ae81ff>1</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain">   </span><span class="token comment" style=color:#8292a2;font-style:italic># 标签</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    pred </span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain"> model</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token plain">x</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    </span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    </span><span class="token comment" style=color:#8292a2;font-style:italic># 计算损失</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    loss </span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain"> criterion</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token plain">pred</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain"> y</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    </span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    </span><span class="token comment" style=color:#8292a2;font-style:italic># 反向传播和优化</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    optimizer</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">zero_grad</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain">  </span><span class="token comment" style=color:#8292a2;font-style:italic># 清零梯度</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    loss</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">backward</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain">        </span><span class="token comment" style=color:#8292a2;font-style:italic># 计算梯度</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    optimizer</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">step</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain">       </span><span class="token comment" style=color:#8292a2;font-style:italic># 更新参数</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label="Copy code to clipboard" title=Copy class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<p>这个示例展示了<code>PyTorch</code>训练的标准流程：定义模型 → 前向传播 → 计算损失 → 反向传播 → 更新参数。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id=pytorch分布式训练>PyTorch分布式训练<a href=#pytorch分布式训练 class=hash-link aria-label="Direct link to PyTorch分布式训练" title="Direct link to PyTorch分布式训练">​</a></h2>
<p>当模型规模增大或数据量激增时，单机单卡训练变得不现实。<code>PyTorch</code>提供了强大的分布式训练能力，支持多机多卡并行训练。</p>
<p><strong>分布式训练</strong>是指使用多个<code>GPU</code>（单机或多机）同时训练一个模型，以加速训练过程或支持更大的模型和批次大小。</p>
<p><strong>主要优势</strong>：</p>
<table><thead><tr><th>优势<th>说明<th>效果<tbody><tr><td><strong>训练加速</strong><td>多卡并行计算<td>近似线性加速（<code>8</code>卡约<code>6-7</code>倍）<tr><td><strong>更大批次</strong><td>聚合多卡的批次<td>提升训练稳定性和收敛速度<tr><td><strong>大模型支持</strong><td>模型切分到多卡<td>支持单卡装不下的大模型<tr><td><strong>更大数据集</strong><td>数据分布式加载<td>处理<code>TB</code>级数据集</table>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=分布式训练架构>分布式训练架构<a href=#分布式训练架构 class=hash-link aria-label="Direct link to 分布式训练架构" title="Direct link to 分布式训练架构">​</a></h3>
<p><code>PyTorch</code>的分布式训练基于进程组（<code>Process Group</code>）概念，每个<code>GPU</code>对应一个进程。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=架构示意图>架构示意图<a href=#架构示意图 class=hash-link aria-label="Direct link to 架构示意图" title="Direct link to 架构示意图">​</a></h4>
<!-- -->
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=进程映射关系>进程映射关系<a href=#进程映射关系 class=hash-link aria-label="Direct link to 进程映射关系" title="Direct link to 进程映射关系">​</a></h4>
<table><thead><tr><th>节点<th>Local Rank<th>Global Rank<th>GPU编号<th>IP地址<tbody><tr><td>节点1<td><code>0</code><td><code>0</code><td><code>GPU 0</code><td><code>192.168.1.1</code><tr><td>节点1<td><code>1</code><td><code>1</code><td><code>GPU 1</code><td><code>192.168.1.1</code><tr><td>节点2<td><code>0</code><td><code>2</code><td><code>GPU 0</code><td><code>192.168.1.2</code><tr><td>节点2<td><code>1</code><td><code>3</code><td><code>GPU 1</code><td><code>192.168.1.2</code></table>
<p><strong>说明</strong>：</p>
<ul>
<li>每个进程独立运行，持有模型副本</li>
<li>进程间通过<code>Process Group</code>进行通信</li>
<li><code>Rank 0</code>通常作为主进程，负责日志和检查点保存</li>
<li>所有进程通过<code>all-reduce</code>操作同步梯度</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=相关核心概念>相关核心概念<a href=#相关核心概念 class=hash-link aria-label="Direct link to 相关核心概念" title="Direct link to 相关核心概念">​</a></h3>
<table><thead><tr><th>概念<th>说明<th>示例<tbody><tr><td><strong>World Size</strong><td>总进程数（总<code>GPU</code>数）<td><code>4</code>卡训练，<code>world size = 4</code><tr><td><strong>Rank</strong><td>进程的全局唯一编号<td><code>0, 1, 2, 3</code><tr><td><strong>Local Rank</strong><td>进程在当前节点的编号<td>每个节点都从<code>0</code>开始<tr><td><strong>Master</strong><td>主进程，通常是<code>rank 0</code><td>负责日志、保存模型等<tr><td><strong>Backend</strong><td>通信后端<td><code>nccl</code>（<code>GPU</code>）、<code>gloo</code>（<code>CPU</code>）</table>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=分布式训练关键环境变量>分布式训练关键环境变量<a href=#分布式训练关键环境变量 class=hash-link aria-label="Direct link to 分布式训练关键环境变量" title="Direct link to 分布式训练关键环境变量">​</a></h3>
<p><code>PyTorch</code>分布式训练依赖环境变量来配置进程间通信。理解这些环境变量对于正确配置分布式训练至关重要。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=必需环境变量>必需环境变量<a href=#必需环境变量 class=hash-link aria-label="Direct link to 必需环境变量" title="Direct link to 必需环境变量">​</a></h4>
<table><thead><tr><th>环境变量<th>说明<th>示例值<th>设置方式<tbody><tr><td><strong>MASTER_ADDR</strong><td>主节点的<code>IP</code>地址或主机名<td><code>192.168.1.1</code><td>手动设置<tr><td><strong>MASTER_PORT</strong><td>主节点的端口号<td><code>29500</code><td>手动设置<tr><td><strong>WORLD_SIZE</strong><td>总进程数（所有节点的<code>GPU</code>总数）<td><code>8</code><td>手动设置或启动器自动设置<tr><td><strong>RANK</strong><td>当前进程的全局编号<td><code>0-7</code><td>启动器（<code>torchrun</code>）自动设置<tr><td><strong>LOCAL_RANK</strong><td>当前进程在本节点的编号<td><code>0-3</code><td>启动器（<code>torchrun</code>）自动设置</table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=可选环境变量>可选环境变量<a href=#可选环境变量 class=hash-link aria-label="Direct link to 可选环境变量" title="Direct link to 可选环境变量">​</a></h4>
<table><thead><tr><th>环境变量<th>说明<th>默认值<th>使用场景<tbody><tr><td><strong>NCCL_DEBUG</strong><td><code>NCCL</code>日志级别<td><code>WARN</code><td>调试通信问题，可设为<code>INFO</code>或<code>TRACE</code><tr><td><strong>NCCL_SOCKET_IFNAME</strong><td>网络接口名称<td>自动检测<td>多网卡环境指定网卡，如<code>eth0</code><tr><td><strong>NCCL_IB_DISABLE</strong><td>禁用<code>InfiniBand</code><td><code>0</code><td>设为<code>1</code>可禁用<code>IB</code>，使用<code>Ethernet</code><tr><td><strong>NCCL_P2P_DISABLE</strong><td>禁用<code>GPU</code>点对点通信<td><code>0</code><td>某些硬件不支持<code>P2P</code>时设为<code>1</code><tr><td><strong>NCCL_TIMEOUT</strong><td>通信超时时间（秒）<td><code>1800</code><td>大模型训练可能需要增加<tr><td><strong>GLOO_SOCKET_IFNAME</strong><td><code>Gloo</code>后端网络接口<td>自动检测<td>使用<code>Gloo</code>后端时指定网卡<tr><td><strong>OMP_NUM_THREADS</strong><td><code>OpenMP</code>线程数<td>系统默认<td>控制<code>CPU</code>并行度，避免过度订阅<tr><td><strong>CUDA_VISIBLE_DEVICES</strong><td>可见的<code>GPU</code>设备<td>全部<td>限制使用特定<code>GPU</code>，如<code>0,1,2</code></table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=环境变量使用示例>环境变量使用示例<a href=#环境变量使用示例 class=hash-link aria-label="Direct link to 环�境变量使用示例" title="Direct link to 环境变量使用示例">​</a></h4>
<p><strong>场景1：单机多卡训练（4卡）</strong></p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#f8f8f2;--prism-background-color:#272822><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style=color:#f8f8f2;background-color:#272822><code class=codeBlockLines_e6Vv><span class=token-line style=color:#f8f8f2><span class="token comment" style=color:#8292a2;font-style:italic># 使用torchrun启动（推荐）</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">torchrun </span><span class="token punctuation" style=color:#f8f8f2>\</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    </span><span class="token parameter variable" style=color:#f8f8f2>--nproc_per_node</span><span class="token operator" style=color:#66d9ef>=</span><span class="token number" style=color:#ae81ff>4</span><span class="token plain"> </span><span class="token punctuation" style=color:#f8f8f2>\</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    </span><span class="token parameter variable" style=color:#f8f8f2>--master_addr</span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain">localhost </span><span class="token punctuation" style=color:#f8f8f2>\</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    </span><span class="token parameter variable" style=color:#f8f8f2>--master_port</span><span class="token operator" style=color:#66d9ef>=</span><span class="token number" style=color:#ae81ff>29500</span><span class="token plain"> </span><span class="token punctuation" style=color:#f8f8f2>\</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    train.py</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain" style=display:inline-block></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token comment" style=color:#8292a2;font-style:italic># torchrun会自动设置：</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token comment" style=color:#8292a2;font-style:italic># RANK=0,1,2,3</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token comment" style=color:#8292a2;font-style:italic># LOCAL_RANK=0,1,2,3</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token comment" style=color:#8292a2;font-style:italic># WORLD_SIZE=4</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label="Copy code to clipboard" title=Copy class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<p><strong>场景2：多机多卡训练（2机，每机4卡）</strong></p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#f8f8f2;--prism-background-color:#272822><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style=color:#f8f8f2;background-color:#272822><code class=codeBlockLines_e6Vv><span class=token-line style=color:#f8f8f2><span class="token comment" style=color:#8292a2;font-style:italic># 节点0 (192.168.1.1)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">torchrun </span><span class="token punctuation" style=color:#f8f8f2>\</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    </span><span class="token parameter variable" style=color:#f8f8f2>--nproc_per_node</span><span class="token operator" style=color:#66d9ef>=</span><span class="token number" style=color:#ae81ff>4</span><span class="token plain"> </span><span class="token punctuation" style=color:#f8f8f2>\</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    </span><span class="token parameter variable" style=color:#f8f8f2>--nnodes</span><span class="token operator" style=color:#66d9ef>=</span><span class="token number" style=color:#ae81ff>2</span><span class="token plain"> </span><span class="token punctuation" style=color:#f8f8f2>\</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    </span><span class="token parameter variable" style=color:#f8f8f2>--node_rank</span><span class="token operator" style=color:#66d9ef>=</span><span class="token number" style=color:#ae81ff>0</span><span class="token plain"> </span><span class="token punctuation" style=color:#f8f8f2>\</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    </span><span class="token parameter variable" style=color:#f8f8f2>--master_addr</span><span class="token operator" style=color:#66d9ef>=</span><span class="token number" style=color:#ae81ff>192.168</span><span class="token plain">.1.1 </span><span class="token punctuation" style=color:#f8f8f2>\</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    </span><span class="token parameter variable" style=color:#f8f8f2>--master_port</span><span class="token operator" style=color:#66d9ef>=</span><span class="token number" style=color:#ae81ff>29500</span><span class="token plain"> </span><span class="token punctuation" style=color:#f8f8f2>\</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    train.py</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain" style=display:inline-block></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token comment" style=color:#8292a2;font-style:italic># 节点1 (192.168.1.2)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">torchrun </span><span class="token punctuation" style=color:#f8f8f2>\</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    </span><span class="token parameter variable" style=color:#f8f8f2>--nproc_per_node</span><span class="token operator" style=color:#66d9ef>=</span><span class="token number" style=color:#ae81ff>4</span><span class="token plain"> </span><span class="token punctuation" style=color:#f8f8f2>\</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    </span><span class="token parameter variable" style=color:#f8f8f2>--nnodes</span><span class="token operator" style=color:#66d9ef>=</span><span class="token number" style=color:#ae81ff>2</span><span class="token plain"> </span><span class="token punctuation" style=color:#f8f8f2>\</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    </span><span class="token parameter variable" style=color:#f8f8f2>--node_rank</span><span class="token operator" style=color:#66d9ef>=</span><span class="token number" style=color:#ae81ff>1</span><span class="token plain"> </span><span class="token punctuation" style=color:#f8f8f2>\</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    </span><span class="token parameter variable" style=color:#f8f8f2>--master_addr</span><span class="token operator" style=color:#66d9ef>=</span><span class="token number" style=color:#ae81ff>192.168</span><span class="token plain">.1.1 </span><span class="token punctuation" style=color:#f8f8f2>\</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    </span><span class="token parameter variable" style=color:#f8f8f2>--master_port</span><span class="token operator" style=color:#66d9ef>=</span><span class="token number" style=color:#ae81ff>29500</span><span class="token plain"> </span><span class="token punctuation" style=color:#f8f8f2>\</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    train.py</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain" style=display:inline-block></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token comment" style=color:#8292a2;font-style:italic># torchrun会自动设置：</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token comment" style=color:#8292a2;font-style:italic># 节点0: RANK=0,1,2,3, LOCAL_RANK=0,1,2,3</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token comment" style=color:#8292a2;font-style:italic># 节点1: RANK=4,5,6,7, LOCAL_RANK=0,1,2,3</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token comment" style=color:#8292a2;font-style:italic># WORLD_SIZE=8</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label="Copy code to clipboard" title=Copy class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<p><strong>场景3：手动设置环境变量</strong></p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#f8f8f2;--prism-background-color:#272822><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style=color:#f8f8f2;background-color:#272822><code class=codeBlockLines_e6Vv><span class=token-line style=color:#f8f8f2><span class="token comment" style=color:#8292a2;font-style:italic># 当不使用torchrun时，需手动设置</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token builtin class-name" style=color:#e6db74>export</span><span class="token plain"> </span><span class="token assign-left variable" style=color:#f8f8f2>MASTER_ADDR</span><span class="token operator" style=color:#66d9ef>=</span><span class="token number" style=color:#ae81ff>192.168</span><span class="token plain">.1.1</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token builtin class-name" style=color:#e6db74>export</span><span class="token plain"> </span><span class="token assign-left variable" style=color:#f8f8f2>MASTER_PORT</span><span class="token operator" style=color:#66d9ef>=</span><span class="token number" style=color:#ae81ff>29500</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token builtin class-name" style=color:#e6db74>export</span><span class="token plain"> </span><span class="token assign-left variable" style=color:#f8f8f2>WORLD_SIZE</span><span class="token operator" style=color:#66d9ef>=</span><span class="token number" style=color:#ae81ff>8</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token builtin class-name" style=color:#e6db74>export</span><span class="token plain"> </span><span class="token assign-left variable" style=color:#f8f8f2>RANK</span><span class="token operator" style=color:#66d9ef>=</span><span class="token number" style=color:#ae81ff>0</span><span class="token plain">  </span><span class="token comment" style=color:#8292a2;font-style:italic># 每个进程不同</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token builtin class-name" style=color:#e6db74>export</span><span class="token plain"> </span><span class="token assign-left variable" style=color:#f8f8f2>LOCAL_RANK</span><span class="token operator" style=color:#66d9ef>=</span><span class="token number" style=color:#ae81ff>0</span><span class="token plain">  </span><span class="token comment" style=color:#8292a2;font-style:italic># 每个进程不同</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain" style=display:inline-block></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">python train.py</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label="Copy code to clipboard" title=Copy class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=分布式训练代码示例>分布式训练代码示例<a href=#分布式训练代码示例 class=hash-link aria-label="Direct link to 分布式训练代码示例" title="Direct link to 分布式训练代码示例">​</a></h3>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#f8f8f2;--prism-background-color:#272822><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-python codeBlock_bY9V thin-scrollbar" style=color:#f8f8f2;background-color:#272822><code class=codeBlockLines_e6Vv><span class=token-line style=color:#f8f8f2><span class="token keyword" style=color:#66d9ef>import</span><span class="token plain"> torch</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token keyword" style=color:#66d9ef>import</span><span class="token plain"> torch</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">nn </span><span class="token keyword" style=color:#66d9ef>as</span><span class="token plain"> nn</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token keyword" style=color:#66d9ef>import</span><span class="token plain"> torch</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">distributed </span><span class="token keyword" style=color:#66d9ef>as</span><span class="token plain"> dist</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token keyword" style=color:#66d9ef>from</span><span class="token plain"> torch</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">nn</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">parallel </span><span class="token keyword" style=color:#66d9ef>import</span><span class="token plain"> DistributedDataParallel </span><span class="token keyword" style=color:#66d9ef>as</span><span class="token plain"> DDP</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain" style=display:inline-block></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token keyword" style=color:#66d9ef>def</span><span class="token plain"> </span><span class="token function" style=color:#e6db74>setup</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token punctuation" style=color:#f8f8f2>:</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    </span><span class="token triple-quoted-string string" style=color:#a6e22e>"""初始化分布式环境"""</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    dist</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">init_process_group</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token plain">backend</span><span class="token operator" style=color:#66d9ef>=</span><span class="token string" style=color:#a6e22e>'nccl'</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    torch</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">cuda</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">set_device</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token builtin" style=color:#e6db74>int</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token plain">os</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">environ</span><span class="token punctuation" style=color:#f8f8f2>[</span><span class="token string" style=color:#a6e22e>'LOCAL_RANK'</span><span class="token punctuation" style=color:#f8f8f2>]</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain" style=display:inline-block></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token keyword" style=color:#66d9ef>def</span><span class="token plain"> </span><span class="token function" style=color:#e6db74>cleanup</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token punctuation" style=color:#f8f8f2>:</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    </span><span class="token triple-quoted-string string" style=color:#a6e22e>"""清理分布式环境"""</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    dist</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">destroy_process_group</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain" style=display:inline-block></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token keyword" style=color:#66d9ef>def</span><span class="token plain"> </span><span class="token function" style=color:#e6db74>train</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token punctuation" style=color:#f8f8f2>:</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    setup</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    </span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    </span><span class="token comment" style=color:#8292a2;font-style:italic># 创建模型并移到GPU</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    local_rank </span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain"> </span><span class="token builtin" style=color:#e6db74>int</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token plain">os</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">environ</span><span class="token punctuation" style=color:#f8f8f2>[</span><span class="token string" style=color:#a6e22e>'LOCAL_RANK'</span><span class="token punctuation" style=color:#f8f8f2>]</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    model </span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain"> SimpleModel</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">cuda</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token plain">local_rank</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    </span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    </span><span class="token comment" style=color:#8292a2;font-style:italic># 包装为DDP模型</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    model </span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain"> DDP</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token plain">model</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain"> device_ids</span><span class="token operator" style=color:#66d9ef>=</span><span class="token punctuation" style=color:#f8f8f2>[</span><span class="token plain">local_rank</span><span class="token punctuation" style=color:#f8f8f2>]</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    </span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    </span><span class="token comment" style=color:#8292a2;font-style:italic># 训练循环（省略数据加载部分）</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    </span><span class="token keyword" style=color:#66d9ef>for</span><span class="token plain"> epoch </span><span class="token keyword" style=color:#66d9ef>in</span><span class="token plain"> </span><span class="token builtin" style=color:#e6db74>range</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token number" style=color:#ae81ff>100</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token punctuation" style=color:#f8f8f2>:</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">        </span><span class="token comment" style=color:#8292a2;font-style:italic># 前向、反向、优化</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">        </span><span class="token comment" style=color:#8292a2;font-style:italic># DDP会自动同步梯度</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">        </span><span class="token keyword" style=color:#66d9ef>pass</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    </span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    cleanup</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain" style=display:inline-block></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token keyword" style=color:#66d9ef>if</span><span class="token plain"> __name__ </span><span class="token operator" style=color:#66d9ef>==</span><span class="token plain"> </span><span class="token string" style=color:#a6e22e>'__main__'</span><span class="token punctuation" style=color:#f8f8f2>:</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    train</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token punctuation" style=color:#f8f8f2>)</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label="Copy code to clipboard" title=Copy class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=常见问题排查>常见问题排查<a href=#常见问题排查 class=hash-link aria-label="Direct link to 常见问题排查" title="Direct link to 常见问题排查">​</a></h3>
<table><thead><tr><th>问题<th>可能原因<th>解决方案<tbody><tr><td><strong>进程卡住不动</strong><td>网络配置错误<td>检查<code>MASTER_ADDR</code>和端口连通性<tr><td><strong>NCCL初始化失败</strong><td>网卡选择错误<td>设置<code>NCCL_SOCKET_IFNAME</code><tr><td><strong>通信超时</strong><td>模型太大或网络慢<td>增加<code>NCCL_TIMEOUT</code><tr><td><strong>显存不足</strong><td>批次太大<td>减小<code>batch_size</code>或使用梯度累积<tr><td><strong>速度没提升</strong><td><code>CPU</code>瓶颈<td>调整<code>OMP_NUM_THREADS</code>和数据加载</table>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id=pytorch并行计算策略>PyTorch并行计算策略<a href=#pytorch并行计算策略 class=hash-link aria-label="Direct link to PyTorch并行计算策略" title="Direct link to PyTorch并行计算策略">​</a></h2>
<p><code>PyTorch</code>支持多种并行计算策略，每种策略适用于不同的场景和模型规模。理解这些策略对于高效训练大模型至关重要。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=并行策略概览>并行策略概览<a href=#并行策略概览 class=hash-link aria-label="Direct link to 并行策略概览" title="Direct link to 并行策略概览">​</a></h3>
<!-- -->
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=并行策略对比>并行策略对比<a href=#并行策略对比 class=hash-link aria-label="Direct link to 并行策略对比" title="Direct link to 并行策略对比">​</a></h3>
<table><thead><tr><th>策略<th>原理<th>适用场景<th>优势<th>劣势<tbody><tr><td><strong>数据并行</strong><td>每个<code>GPU</code>复制完整模型，处理不同数据<td>小到中型模型<td>简单易用、通信少<td>单卡需装下整个模型<tr><td><strong>模型并行</strong><td>模型切分到多个<code>GPU</code><td>超大模型<td>支持任意大模型<td>通信开销大、实现复杂<tr><td><strong>流水线并行</strong><td>模型按层切分，流水线执行<td>大模型、深层网络<td>平衡计算和通信<td>存在气泡时间<tr><td><strong>混合并行</strong><td>组合多种策略<td>超大规模训练<td>最优性能<td>配置复杂</table>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=数据并行data-parallelism>数据并行（Data Parallelism）<a href=#数据并行data-parallelism class=hash-link aria-label="Direct link to 数据并行（Data Parallelism）" title="Direct link to 数据并行（Data Parallelism）">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=原理>原理<a href=#原理 class=hash-link aria-label="Direct link to 原理" title="Direct link to 原理">​</a></h4>
<p>数据并行是最常用的并行策略，每个<code>GPU</code>持有完整模型的副本，处理不同的数据批次。</p>
<!-- -->
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=实现方式>实现方式<a href=#实现方式 class=hash-link aria-label="Direct link to 实现方式" title="Direct link to 实现方式">​</a></h4>
<p><strong>1. DataParallel (DP) - 单机多卡</strong></p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#f8f8f2;--prism-background-color:#272822><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-python codeBlock_bY9V thin-scrollbar" style=color:#f8f8f2;background-color:#272822><code class=codeBlockLines_e6Vv><span class=token-line style=color:#f8f8f2><span class="token plain">model </span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain"> nn</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">DataParallel</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token plain">model</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain"> device_ids</span><span class="token operator" style=color:#66d9ef>=</span><span class="token punctuation" style=color:#f8f8f2>[</span><span class="token number" style=color:#ae81ff>0</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain"> </span><span class="token number" style=color:#ae81ff>1</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain"> </span><span class="token number" style=color:#ae81ff>2</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain"> </span><span class="token number" style=color:#ae81ff>3</span><span class="token punctuation" style=color:#f8f8f2>]</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">model </span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain"> model</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">cuda</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain" style=display:inline-block></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token comment" style=color:#8292a2;font-style:italic># 自动分发数据到多卡</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">output </span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain"> model</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token builtin" style=color:#e6db74>input</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain">  </span><span class="token comment" style=color:#8292a2;font-style:italic># input会自动切分</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label="Copy code to clipboard" title=Copy class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<p><strong>特点</strong>：</p>
<ul>
<li>✅ 使用简单，一行代码即可</li>
<li>❌ 只支持单机</li>
<li>❌ <code>GPU 0</code>负载不均衡（汇聚梯度）</li>
<li>❌ 性能较差（推荐使用<code>DDP</code>）</li>
</ul>
<p><strong>2. DistributedDataParallel (DDP) - 多机多卡</strong></p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#f8f8f2;--prism-background-color:#272822><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-python codeBlock_bY9V thin-scrollbar" style=color:#f8f8f2;background-color:#272822><code class=codeBlockLines_e6Vv><span class=token-line style=color:#f8f8f2><span class="token comment" style=color:#8292a2;font-style:italic># 初始化进程组</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">dist</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">init_process_group</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token plain">backend</span><span class="token operator" style=color:#66d9ef>=</span><span class="token string" style=color:#a6e22e>'nccl'</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">local_rank </span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain"> </span><span class="token builtin" style=color:#e6db74>int</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token plain">os</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">environ</span><span class="token punctuation" style=color:#f8f8f2>[</span><span class="token string" style=color:#a6e22e>'LOCAL_RANK'</span><span class="token punctuation" style=color:#f8f8f2>]</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain" style=display:inline-block></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token comment" style=color:#8292a2;font-style:italic># 创建DDP模型</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">model </span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain"> model</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">cuda</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token plain">local_rank</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">model </span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain"> DDP</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token plain">model</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain"> device_ids</span><span class="token operator" style=color:#66d9ef>=</span><span class="token punctuation" style=color:#f8f8f2>[</span><span class="token plain">local_rank</span><span class="token punctuation" style=color:#f8f8f2>]</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain" style=display:inline-block></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token comment" style=color:#8292a2;font-style:italic># 使用分布式采样器</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">sampler </span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain"> torch</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">utils</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">data</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">DistributedSampler</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token plain">dataset</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">dataloader </span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain"> DataLoader</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token plain">dataset</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain"> sampler</span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain">sampler</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain" style=display:inline-block></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token comment" style=color:#8292a2;font-style:italic># 训练</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token keyword" style=color:#66d9ef>for</span><span class="token plain"> data</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain"> target </span><span class="token keyword" style=color:#66d9ef>in</span><span class="token plain"> dataloader</span><span class="token punctuation" style=color:#f8f8f2>:</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    output </span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain"> model</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token plain">data</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    loss </span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain"> criterion</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token plain">output</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain"> target</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    loss</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">backward</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    optimizer</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">step</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token punctuation" style=color:#f8f8f2>)</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label="Copy code to clipboard" title=Copy class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<p><strong>特点</strong>：</p>
<ul>
<li>✅ 支持多机多卡</li>
<li>✅ 性能优异，负载均衡</li>
<li>✅ 梯度同步高效（<code>all-reduce</code>）</li>
<li>⚠️ 需要配置分布式环境</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=适用场景>适用场景<a href=#适用场景 class=hash-link aria-label="Direct link to 适用场景" title="Direct link to 适用场景">​</a></h4>
<ul>
<li>模型能完整放入单个<code>GPU</code></li>
<li>希望通过增加批次大小加速训练</li>
<li>最常用的并行策略（<code>90%</code>的场景）</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=模型并行model-parallelism>模型并行（Model Parallelism）<a href=#模型并行model-parallelism class=hash-link aria-label="Direct link to 模型并行（Model Parallelism）" title="Direct link to 模型并行（Model Parallelism）">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=原理-1>原理<a href=#原理-1 class=hash-link aria-label="Direct link to 原理" title="Direct link to 原理">​</a></h4>
<p>模型并行将模型的不同部分放在不同的<code>GPU</code>上，适用于单卡装不下的超大模型。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=张量并行tensor-parallelism>张量并行（Tensor Parallelism）<a href=#张量并行tensor-parallelism class=hash-link aria-label="Direct link to 张量并行（Tensor Parallelism）" title="Direct link to 张量并行（Tensor Parallelism）">​</a></h4>
<p>将单个层的参数切分到多个<code>GPU</code>，常用于<code>Transformer</code>的注意力层和前馈层。</p>
<!-- -->
<p><strong>代码示例</strong>：</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#f8f8f2;--prism-background-color:#272822><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-python codeBlock_bY9V thin-scrollbar" style=color:#f8f8f2;background-color:#272822><code class=codeBlockLines_e6Vv><span class=token-line style=color:#f8f8f2><span class="token comment" style=color:#8292a2;font-style:italic># 手动实现张量并行</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token keyword" style=color:#66d9ef>class</span><span class="token plain"> </span><span class="token class-name" style=color:#e6db74>TensorParallelLinear</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token plain">nn</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">Module</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token punctuation" style=color:#f8f8f2>:</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    </span><span class="token keyword" style=color:#66d9ef>def</span><span class="token plain"> </span><span class="token function" style=color:#e6db74>__init__</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token plain">self</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain"> in_features</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain"> out_features</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain"> world_size</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token punctuation" style=color:#f8f8f2>:</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">        </span><span class="token builtin" style=color:#e6db74>super</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">__init__</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">        </span><span class="token comment" style=color:#8292a2;font-style:italic># 每个GPU只持有部分权重</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">        self</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">out_features_per_gpu </span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain"> out_features </span><span class="token operator" style=color:#66d9ef>//</span><span class="token plain"> world_size</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">        self</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">linear </span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain"> nn</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">Linear</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token plain">in_features</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain"> self</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">out_features_per_gpu</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    </span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    </span><span class="token keyword" style=color:#66d9ef>def</span><span class="token plain"> </span><span class="token function" style=color:#e6db74>forward</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token plain">self</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain"> x</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token punctuation" style=color:#f8f8f2>:</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">        </span><span class="token comment" style=color:#8292a2;font-style:italic># 本地计算</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">        output </span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain"> self</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">linear</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token plain">x</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">        </span><span class="token comment" style=color:#8292a2;font-style:italic># 收集所有GPU的输出</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">        output </span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain"> torch</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">cat</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token plain">dist</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">all_gather</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token plain">output</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain"> dim</span><span class="token operator" style=color:#66d9ef>=</span><span class="token operator" style=color:#66d9ef>-</span><span class="token number" style=color:#ae81ff>1</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">        </span><span class="token keyword" style=color:#66d9ef>return</span><span class="token plain"> output</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label="Copy code to clipboard" title=Copy class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<p><strong>特点</strong>：</p>
<ul>
<li>✅ 支持超大层（如<code>GPT</code>的<code>Linear</code>层）</li>
<li>❌ 通信频繁，需要高速互联</li>
<li>⚠️ 实现复杂，通常使用专门库如<code>Megatron-LM</code></li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=层间并行layer-wise-parallelism>层间并行（Layer-wise Parallelism）<a href=#层间并行layer-wise-parallelism class=hash-link aria-label="Direct link to 层间并行（Layer-wise Parallelism）" title="Direct link to 层间并行（Layer-wise Parallelism）">​</a></h4>
<p>将模型的不同层放在不同<code>GPU</code>上，串行执行。</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#f8f8f2;--prism-background-color:#272822><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-python codeBlock_bY9V thin-scrollbar" style=color:#f8f8f2;background-color:#272822><code class=codeBlockLines_e6Vv><span class=token-line style=color:#f8f8f2><span class="token keyword" style=color:#66d9ef>class</span><span class="token plain"> </span><span class="token class-name" style=color:#e6db74>ModelParallel</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token plain">nn</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">Module</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token punctuation" style=color:#f8f8f2>:</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    </span><span class="token keyword" style=color:#66d9ef>def</span><span class="token plain"> </span><span class="token function" style=color:#e6db74>__init__</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token plain">self</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token punctuation" style=color:#f8f8f2>:</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">        </span><span class="token builtin" style=color:#e6db74>super</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">__init__</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">        self</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">layer1 </span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain"> nn</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">Linear</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token number" style=color:#ae81ff>1000</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain"> </span><span class="token number" style=color:#ae81ff>1000</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">cuda</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token number" style=color:#ae81ff>0</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain">  </span><span class="token comment" style=color:#8292a2;font-style:italic># GPU 0</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">        self</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">layer2 </span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain"> nn</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">Linear</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token number" style=color:#ae81ff>1000</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain"> </span><span class="token number" style=color:#ae81ff>1000</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">cuda</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token number" style=color:#ae81ff>1</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain">  </span><span class="token comment" style=color:#8292a2;font-style:italic># GPU 1</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">        self</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">layer3 </span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain"> nn</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">Linear</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token number" style=color:#ae81ff>1000</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain"> </span><span class="token number" style=color:#ae81ff>10</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">cuda</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token number" style=color:#ae81ff>2</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain">    </span><span class="token comment" style=color:#8292a2;font-style:italic># GPU 2</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    </span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    </span><span class="token keyword" style=color:#66d9ef>def</span><span class="token plain"> </span><span class="token function" style=color:#e6db74>forward</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token plain">self</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain"> x</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token punctuation" style=color:#f8f8f2>:</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">        x </span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain"> self</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">layer1</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token plain">x</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">cuda</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token number" style=color:#ae81ff>0</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">        x </span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain"> self</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">layer2</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token plain">x</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">cuda</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token number" style=color:#ae81ff>1</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">        x </span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain"> self</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">layer3</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token plain">x</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">cuda</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token number" style=color:#ae81ff>2</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">        </span><span class="token keyword" style=color:#66d9ef>return</span><span class="token plain"> x</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label="Copy code to clipboard" title=Copy class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<p><strong>特点</strong>：</p>
<ul>
<li>✅ 实现简单</li>
<li>❌ <code>GPU</code>利用率低（串行执行）</li>
<li>❌ 存在大量<code>GPU</code>间数据传输</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=适用场景-1>适用场景<a href=#适用场景-1 class=hash-link aria-label="Direct link to 适用场景" title="Direct link to 适用场景">​</a></h4>
<ul>
<li>模型太大，单卡装不下</li>
<li>有高速<code>GPU</code>互联（<code>NVLink</code>、<code>InfiniBand</code>）</li>
<li>超大<code>Transformer</code>模型（如<code>GPT-3</code>、<code>LLaMA-70B</code>）</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=流水线并行pipeline-parallelism>流水线并行（Pipeline Parallelism）<a href=#流水线并行pipeline-parallelism class=hash-link aria-label="Direct link to 流水线并行（Pipeline Parallelism）" title="Direct link to 流水线并行（Pipeline Parallelism）">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=原理-2>原理<a href=#原理-2 class=hash-link aria-label="Direct link to 原理" title="Direct link to 原理">​</a></h4>
<p>流水线并行将模型按层分组成多个阶段（<code>stage</code>），每个阶段放在一个<code>GPU</code>上，通过流水线方式执行多个微批次（<code>micro-batch</code>）。</p>
<!-- -->
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=关键概念>关键概念<a href=#关键概念 class=hash-link aria-label="Direct link to 关键概念" title="Direct link to 关键概念">​</a></h4>
<table><thead><tr><th>概念<th>说明<th>示例<tbody><tr><td><strong>Stage</strong><td>模型的一部分，包含若干层<td>将<code>48</code>层模型分为<code>4</code>个<code>stage</code>，每个<code>12</code>层<tr><td><strong>Micro-batch</strong><td>原始批次的切分<td>批次<code>128</code>切分为<code>4</code>个微批次，每个<code>32</code><tr><td><strong>Bubble Time</strong><td><code>GPU</code>空闲等待时间<td>流水线启动和结束时的空闲期</table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=代码示例使用pytorch-pipelineparallel>代码示例（使用PyTorch PipelineParallel）<a href=#代码示例使用pytorch-pipelineparallel class=hash-link aria-label="Direct link to 代码示例（使用PyTorch PipelineParallel）" title="Direct link to 代码示例（使用PyTorch PipelineParallel）">​</a></h4>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#f8f8f2;--prism-background-color:#272822><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-python codeBlock_bY9V thin-scrollbar" style=color:#f8f8f2;background-color:#272822><code class=codeBlockLines_e6Vv><span class=token-line style=color:#f8f8f2><span class="token keyword" style=color:#66d9ef>from</span><span class="token plain"> torch</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">distributed</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">pipeline</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">sync </span><span class="token keyword" style=color:#66d9ef>import</span><span class="token plain"> Pipe</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain" style=display:inline-block></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token comment" style=color:#8292a2;font-style:italic># 定义模型阶段</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">model </span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain"> nn</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">Sequential</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    nn</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">Linear</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token number" style=color:#ae81ff>1000</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain"> </span><span class="token number" style=color:#ae81ff>1000</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain">  </span><span class="token comment" style=color:#8292a2;font-style:italic># Stage 0 - GPU 0</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    nn</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">ReLU</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    nn</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">Linear</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token number" style=color:#ae81ff>1000</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain"> </span><span class="token number" style=color:#ae81ff>1000</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain">  </span><span class="token comment" style=color:#8292a2;font-style:italic># Stage 1 - GPU 1</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    nn</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">ReLU</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    nn</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">Linear</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token number" style=color:#ae81ff>1000</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain"> </span><span class="token number" style=color:#ae81ff>10</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain">     </span><span class="token comment" style=color:#8292a2;font-style:italic># Stage 2 - GPU 2</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain" style=display:inline-block></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token comment" style=color:#8292a2;font-style:italic># 包装为Pipeline</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">model </span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain"> Pipe</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token plain">model</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain"> chunks</span><span class="token operator" style=color:#66d9ef>=</span><span class="token number" style=color:#ae81ff>8</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain">  </span><span class="token comment" style=color:#8292a2;font-style:italic># 切分为8个micro-batch</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain" style=display:inline-block></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token comment" style=color:#8292a2;font-style:italic># 训练</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token keyword" style=color:#66d9ef>for</span><span class="token plain"> data</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain"> target </span><span class="token keyword" style=color:#66d9ef>in</span><span class="token plain"> dataloader</span><span class="token punctuation" style=color:#f8f8f2>:</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    output </span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain"> model</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token plain">data</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    loss </span><span class="token operator" style=color:#66d9ef>=</span><span class="token plain"> criterion</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token plain">output</span><span class="token punctuation" style=color:#f8f8f2>,</span><span class="token plain"> target</span><span class="token punctuation" style=color:#f8f8f2>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    loss</span><span class="token punctuation" style=color:#f8f8f2>.</span><span class="token plain">backward</span><span class="token punctuation" style=color:#f8f8f2>(</span><span class="token punctuation" style=color:#f8f8f2>)</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label="Copy code to clipboard" title=Copy class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=优化技术>优化技术<a href=#优化技术 class=hash-link aria-label="Direct link to 优化技术" title="Direct link to 优化技术">​</a></h4>
<p><strong>1. GPipe</strong> - <code>Google</code>提出的流水线方案</p>
<ul>
<li>同步梯度更新</li>
<li>使用重计算节省显存</li>
</ul>
<p><strong>2. PipeDream</strong> - 微软提出的异步流水线</p>
<ul>
<li>异步梯度更新</li>
<li>减少气泡时间</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=适用场景-2>适用场景<a href=#适用场景-2 class=hash-link aria-label="Direct link to 适用场景" title="Direct link to 适用场景">​</a></h4>
<ul>
<li>模型层数多但每层不大</li>
<li>希望平衡模型并行和数据并行</li>
<li>中到大型模型（<code>10B-100B</code>参数）</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=混合并行hybrid-parallelism>混合并行（Hybrid Parallelism）<a href=#混合并行hybrid-parallelism class=hash-link aria-label="Direct link to 混合并行（Hybrid Parallelism）" title="Direct link to 混合并行（Hybrid Parallelism）">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=原理-3>原理<a href=#原理-3 class=hash-link aria-label="Direct link to 原理" title="Direct link to 原理">​</a></h4>
<p>混合并行组合多种并行策略，通常是<strong>数据并行 + 模型并行 + 流水线并行</strong>的组合，用于训练超大规模模型。</p>
<!-- -->
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=典型配置>典型配置<a href=#典型配置 class=hash-link aria-label="Direct link to 典型配置" title="Direct link to 典型配置">​</a></h4>
<p><strong>训练<code>GPT-3 175B</code>的混合并行策略</strong>：</p>
<table><thead><tr><th>并行维度<th>配置<th>说明<tbody><tr><td><strong>数据并行</strong><td><code>DP=64</code><td><code>64</code>个数据并行组<tr><td><strong>流水线并行</strong><td><code>PP=8</code><td>模型分<code>8</code>个<code>stage</code><tr><td><strong>张量并行</strong><td><code>TP=8</code><td>每个<code>stage</code>使用<code>8</code>卡张量并行<tr><td><strong>总GPU数</strong><td><code>64×8=512</code><td>需要<code>512</code>块<code>GPU</code></table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=代码示例使用megatron-lm>代码示例（使用Megatron-LM）<a href=#代码示例使用megatron-lm class=hash-link aria-label="Direct link to 代码示例（使用Megatron-LM）" title="Direct link to 代码示例（使用Megatron-LM）">​</a></h4>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#f8f8f2;--prism-background-color:#272822><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style=color:#f8f8f2;background-color:#272822><code class=codeBlockLines_e6Vv><span class=token-line style=color:#f8f8f2><span class="token comment" style=color:#8292a2;font-style:italic># Megatron-LM启动命令</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">torchrun </span><span class="token punctuation" style=color:#f8f8f2>\</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    </span><span class="token parameter variable" style=color:#f8f8f2>--nproc_per_node</span><span class="token operator" style=color:#66d9ef>=</span><span class="token number" style=color:#ae81ff>8</span><span class="token plain"> </span><span class="token punctuation" style=color:#f8f8f2>\</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    </span><span class="token parameter variable" style=color:#f8f8f2>--nnodes</span><span class="token operator" style=color:#66d9ef>=</span><span class="token number" style=color:#ae81ff>64</span><span class="token plain"> </span><span class="token punctuation" style=color:#f8f8f2>\</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    --tensor-model-parallel-size </span><span class="token number" style=color:#ae81ff>8</span><span class="token plain"> </span><span class="token punctuation" style=color:#f8f8f2>\</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    --pipeline-model-parallel-size </span><span class="token number" style=color:#ae81ff>8</span><span class="token plain"> </span><span class="token punctuation" style=color:#f8f8f2>\</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    --num-layers </span><span class="token number" style=color:#ae81ff>96</span><span class="token plain"> </span><span class="token punctuation" style=color:#f8f8f2>\</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    --hidden-size </span><span class="token number" style=color:#ae81ff>12288</span><span class="token plain"> </span><span class="token punctuation" style=color:#f8f8f2>\</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    --num-attention-heads </span><span class="token number" style=color:#ae81ff>96</span><span class="token plain"> </span><span class="token punctuation" style=color:#f8f8f2>\</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    --seq-length </span><span class="token number" style=color:#ae81ff>2048</span><span class="token plain"> </span><span class="token punctuation" style=color:#f8f8f2>\</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    --max-position-embeddings </span><span class="token number" style=color:#ae81ff>2048</span><span class="token plain"> </span><span class="token punctuation" style=color:#f8f8f2>\</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    --micro-batch-size </span><span class="token number" style=color:#ae81ff>1</span><span class="token plain"> </span><span class="token punctuation" style=color:#f8f8f2>\</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    --global-batch-size </span><span class="token number" style=color:#ae81ff>512</span><span class="token plain"> </span><span class="token punctuation" style=color:#f8f8f2>\</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    pretrain_gpt.py </span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label="Copy code to clipboard" title=Copy class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=并行策略选择指南>并行策略选择指南<a href=#并行策略选择指南 class=hash-link aria-label="Direct link to 并行策略选择指南" title="Direct link to 并行策略选择指南">​</a></h4>
<table><thead><tr><th>模型规模<th>推荐策略<th><code>GPU</code>数量<th>典型应用<tbody><tr><td><strong>&lt; 1B</strong><td>数据并行（<code>DDP</code>）<td><code>1-8</code><td>小型模型<tr><td><strong>1B-10B</strong><td><code>DP + PP</code><td><code>8-64</code><td>中型模型<tr><td><strong>10B-100B</strong><td><code>DP + TP + PP</code><td><code>64-512</code><td>大型模型<tr><td><strong>> 100B</strong><td><code>DP + TP + PP + ZeRO</code><td><code>512+</code><td>超大模型</table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=适用场景-3>适用场景<a href=#适用场景-3 class=hash-link aria-label="Direct link to 适用场景" title="Direct link to 适用场景">​</a></h4>
<ul>
<li>超大规模模型训练（<code>100B+</code>参数）</li>
<li>有大规模<code>GPU</code>集群</li>
<li>需要极致性能优化</li>
<li>工业级大模型训练（如<code>GPT</code>、<code>LLaMA</code>）</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=并行策略性能对比>并行策略性能对比<a href=#并行策略性能对比 class=hash-link aria-label="Direct link to 并行策略性能对比" title="Direct link to 并行策略性能对比">​</a></h3>
<table><thead><tr><th>指标<th>数据并行<th>模型并行<th>流水线并行<th>混合并行<tbody><tr><td><strong>实现难度</strong><td>⭐<td>⭐⭐⭐⭐<td>⭐⭐⭐<td>⭐⭐⭐⭐⭐<tr><td><strong>通信开销</strong><td>低<td>高<td>中<td>中-高<tr><td><strong>显存效率</strong><td>低（模型重复）<td>高<td>高<td>最高<tr><td><strong>计算效率</strong><td>高（并行度高）<td>低（串行部分多）<td>中（有气泡）<td>高<tr><td><strong>扩展性</strong><td>线性扩展<td>受限<td>受限<td>最好</table>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id=参考资料>参考资料<a href=#参考资料 class=hash-link aria-label="Direct link to 参考资料" title="Direct link to 参考资料">​</a></h2>
<ul>
<li><a href=https://docs.pytorch.org/docs/stable/index.html target=_blank rel="noopener noreferrer">https://docs.pytorch.org/docs/stable/index.html</a></li>
<li><a href=https://docs.pytorch.org/docs/stable/distributed.html target=_blank rel="noopener noreferrer">https://docs.pytorch.org/docs/stable/distributed.html</a></li>
</ul></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href=/ai/volcano-hpc-ecosystem><div class=pagination-nav__sublabel>Previous</div><div class=pagination-nav__label>云原生HPC生态组件对比分析（基于Volcano）</div></a><a class="pagination-nav__link pagination-nav__link--next" href=/ai/volcano-pytorch-plugin><div class=pagination-nav__sublabel>Next</div><div class=pagination-nav__label>Volcano Job PyTorch Plugin调研测试</div></a></nav><div class=docusaurus-mt-lg></div></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href=#pytorch是什么 class="table-of-contents__link toc-highlight">PyTorch是什么</a><ul><li><a href=#核心定位 class="table-of-contents__link toc-highlight">核心定位</a><li><a href=#通俗理解 class="table-of-contents__link toc-highlight">通俗理解</a></ul><li><a href=#pytorch解决什么问题 class="table-of-contents__link toc-highlight">PyTorch解决什么问题</a><ul><li><a href=#主要解决的问题 class="table-of-contents__link toc-highlight">主要解决的问题</a><li><a href=#核心特性详解 class="table-of-contents__link toc-highlight">核心特性详解</a><li><a href=#与其他框架对比 class="table-of-contents__link toc-highlight">与其他框架对比</a></ul><li><a href=#pytorch核心组件 class="table-of-contents__link toc-highlight">PyTorch核心组件</a><ul><li><a href=#核心模块说明 class="table-of-contents__link toc-highlight">核心模块说明</a><li><a href=#简单训练示例 class="table-of-contents__link toc-highlight">简单训练示例</a></ul><li><a href=#pytorch分布式训练 class="table-of-contents__link toc-highlight">PyTorch分布式训练</a><ul><li><a href=#分布式训练架构 class="table-of-contents__link toc-highlight">分布式训练架构</a><li><a href=#相关核心概念 class="table-of-contents__link toc-highlight">相关核心概念</a><li><a href=#分布式训练关键环境变量 class="table-of-contents__link toc-highlight">分布式训练关键环境变量</a><li><a href=#分布式训练代码示例 class="table-of-contents__link toc-highlight">分布式训练代码示例</a><li><a href=#常见问题排查 class="table-of-contents__link toc-highlight">常见问题排查</a></ul><li><a href=#pytorch并行计算策略 class="table-of-contents__link toc-highlight">PyTorch并行计算策略</a><ul><li><a href=#并行策略概览 class="table-of-contents__link toc-highlight">并行策略概览</a><li><a href=#并行策略对比 class="table-of-contents__link toc-highlight">并行策略对比</a><li><a href=#数据并行data-parallelism class="table-of-contents__link toc-highlight">数据并行（Data Parallelism）</a><li><a href=#模型并行model-parallelism class="table-of-contents__link toc-highlight">模型并行（Model Parallelism）</a><li><a href=#流水线并行pipeline-parallelism class="table-of-contents__link toc-highlight">流水线并行（Pipeline Parallelism）</a><li><a href=#混合并行hybrid-parallelism class="table-of-contents__link toc-highlight">混合并行（Hybrid Parallelism）</a><li><a href=#并行策略性能对比 class="table-of-contents__link toc-highlight">并行策略性能对比</a></ul><li><a href=#参考资料 class="table-of-contents__link toc-highlight">参考资料</a></ul></div></div></div></div></main></div></div></div><footer class=footer><div class="container container-fluid"><div class="footer__bottom text--center"><div class=footer__copyright>Copyright 2026 johng.cn</div></div></div></footer></div>