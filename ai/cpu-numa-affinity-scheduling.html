<!doctype html><html lang=en dir=ltr class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-docs/AI技术/基础架构/算力调度/CPU亲和性与NUMA亲和性调度" data-has-hydrated=false><meta charset=UTF-8><meta name=generator content="Docusaurus v3.6.3"><title data-rh=true>CPU亲和性与NUMA亲和性调度 | John's Blog</title><meta data-rh=true name=viewport content="width=device-width,initial-scale=1.0"><meta data-rh=true name=twitter:card content=summary_large_image><meta data-rh=true property=og:url content=https://johng.cn/ai/cpu-numa-affinity-scheduling><meta data-rh=true property=og:locale content=en><meta data-rh=true name=docusaurus_locale content=en><meta data-rh=true name=docsearch:language content=en><meta data-rh=true name=author content="John Guo"><meta data-rh=true property=og:image content=https://johng.cn/img/favicon.png><meta data-rh=true name=docusaurus_version content=current><meta data-rh=true name=docusaurus_tag content=docs-default-current><meta data-rh=true name=docsearch:version content=current><meta data-rh=true name=docsearch:docusaurus_tag content=docs-default-current><meta data-rh=true property=og:title content="CPU亲和性与NUMA亲和性调度 | John's Blog"><meta data-rh=true name=description content=深入探讨AI模型开发训练推理场景下的CPU亲和性与NUMA亲和性调度技术，介绍NUMA架构原理、GPU拓扑分析、Docker和Kubernetes环境下的亲和性配置方案，通过实际案例优化AI工作负载的性能表现><meta data-rh=true property=og:description content=深入探讨AI模型开发训练推理场景下的CPU亲和性与NUMA亲和性调度技术，介绍NUMA架构原理、GPU拓扑分析、Docker和Kubernetes环境下的亲和性配置方案，通过实际案例优化AI工作负载的性能表现><meta data-rh=true name=keywords content="CPU亲和性,NUMA亲和性,NUMA架构,GPU调度,AI训练,AI推理,性能优化,Docker亲和性,Kubernetes亲和性,CPU绑核,内存访问优化,跨NUMA节点,nvidia-smi,GPU拓扑,分布式训练,NVLINK,资源调度,Kubernetes Topology Manager,CPU Manager,静态策略"><link data-rh=true rel=icon href=/img/favicon.ico><link data-rh=true rel=canonical href=https://johng.cn/ai/cpu-numa-affinity-scheduling><link data-rh=true rel=alternate href=https://johng.cn/ai/cpu-numa-affinity-scheduling hreflang=en><link data-rh=true rel=alternate href=https://johng.cn/ai/cpu-numa-affinity-scheduling hreflang=x-default><link data-rh=true rel=preconnect href=https://XGS1CPQERK-dsn.algolia.net crossorigin><link rel=alternate type=application/rss+xml href=/blog/rss.xml title="John's Blog RSS Feed"><link rel=alternate type=application/atom+xml href=/blog/atom.xml title="John's Blog Atom Feed"><link rel=search type=application/opensearchdescription+xml title="John's Blog" href=/opensearch.xml><script src=https://hm.baidu.com/hm.js?6b4ae23dc83ee5efe875b7172af6c7c1 async></script><link rel=stylesheet href=/assets/css/styles.2f56d3c4.css><script src=/assets/js/runtime~main.75361818.js defer></script><script src=/assets/js/main.2361e6c6.js defer></script><body class=navigation-with-keyboard><script>!function(){var t,e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t=null!==e?e:"light",document.documentElement.setAttribute("data-theme",t)}(),function(){try{for(var[t,e]of new URLSearchParams(window.location.search).entries())if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id=__docusaurus><div role=region aria-label="Skip to main content"><a class=skipToContent_fXgn href=#__docusaurus_skipToContent_fallback>Skip to main content</a></div><nav aria-label=Main class="navbar navbar--fixed-top"><div class=navbar__inner><div class=navbar__items><button aria-label="Toggle navigation bar" aria-expanded=false class="navbar__toggle clean-btn" type=button><svg width=30 height=30 viewBox="0 0 30 30" aria-hidden=true><path stroke=currentColor stroke-linecap=round stroke-miterlimit=10 stroke-width=2 d="M4 7h22M4 15h22M4 23h22"/></svg></button><a class=navbar__brand href=/><b class="navbar__title text--truncate">John's Blog</b></a><a aria-current=page class="navbar__item navbar__link navbar__link--active" href=/ai>AI技术</a><a class="navbar__item navbar__link" href=/cloud-native>云原生</a><a class="navbar__item navbar__link" href=/notes>日常笔记</a><a class="navbar__item navbar__link" href=/programming>开发语言</a><a class="navbar__item navbar__link" href=/architecture>技术架构</a><a class="navbar__item navbar__link" href=/observability>可观测性</a><a class="navbar__item navbar__link" href=/life>生活笔记</a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href=/aboutme>关于我</a><a class="navbar__item navbar__link" href=/blog>博客</a><a href=https://goframe.org/ target=_blank rel="noopener noreferrer" class="navbar__item navbar__link header-goframe-link"></a><a href=https://github.com/gqcn target=_blank rel="noopener noreferrer" class="navbar__item navbar__link header-github-link"></a><div class=navbarSearchContainer_Bca1><button type=button class="DocSearch DocSearch-Button" aria-label="Search (Command+K)"><span class=DocSearch-Button-Container><svg width=20 height=20 class=DocSearch-Search-Icon viewBox="0 0 20 20" aria-hidden=true><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke=currentColor fill=none fill-rule=evenodd stroke-linecap=round stroke-linejoin=round /></svg><span class=DocSearch-Button-Placeholder>Search</span></span><span class=DocSearch-Button-Keys></span></button></div></div></div><div role=presentation class=navbar-sidebar__backdrop></div></nav><div id=__docusaurus_skipToContent_fallback class="main-wrapper mainWrapper_z2l0"><div class=docsWrapper_hBAB><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type=button></button><div class=docRoot_UBD9><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class=sidebarViewport_aRkj><div class=sidebar_njMd><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--active" href=/ai>AI技术</a><button aria-label="Collapse sidebar category 'AI技术'" aria-expanded=true type=button class="clean-btn menu__caret"></button></div><ul style=display:block;overflow:visible;height:auto class=menu__list><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" tabindex=0 href=/ai/agents>智能体</a><button aria-label="Expand sidebar category '智能体'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" tabindex=0 href=/ai/app>应用开发</a><button aria-label="Expand sidebar category '应用开发'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" tabindex=0 href=/ai/inference>推理服务</a><button aria-label="Expand sidebar category '推理服务'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" tabindex=0 href=/ai/training-fine-tuning>训练微调</a><button aria-label="Expand sidebar category '训练微调'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" tabindex=0 href=/ai/model-development>模型开发</a><button aria-label="Expand sidebar category '模型开发'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--active" tabindex=0 href=/ai/infra>基础架构</a><button aria-label="Collapse sidebar category '基础架构'" aria-expanded=true type=button class="clean-btn menu__caret"></button></div><ul style=display:block;overflow:visible;height:auto class=menu__list><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" tabindex=0 href=/ai/vgpu>vGPU</a><button aria-label="Expand sidebar category 'vGPU'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" tabindex=0 href=/ai/rdma>RDMA</a><button aria-label="Expand sidebar category 'RDMA'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" tabindex=0 href=/ai/nvidia>NVIDIA</a><button aria-label="Expand sidebar category 'NVIDIA'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--active" tabindex=0 href=/ai/scheduling>算力调度</a><button aria-label="Collapse sidebar category '算力调度'" aria-expanded=true type=button class="clean-btn menu__caret"></button></div><ul style=display:block;overflow:visible;height:auto class=menu__list><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class=menu__link tabindex=0 href=/ai/hybrid-scheduling-affinity-toleration>混合调度的亲和性、污点容忍设计思考</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class=menu__link tabindex=0 href=/ai/hybrid-scheduling-scale-down-control>混部调度中如何控制在线服务的缩容逻辑</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link menu__link--active" aria-current=page tabindex=0 href=/ai/cpu-numa-affinity-scheduling>CPU亲和性与NUMA亲和性调度</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class=menu__link tabindex=0 href=/ai/cpu-numa-affinity-in-docker>Docker中的CPU&NUMA亲和性配置</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class=menu__link tabindex=0 href=/ai/cpu-numa-affinity-in-kubernetes>Kubernetes中CPU&NUMA亲和性配置</a></ul><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/ai/what-is-llmops-mlops>LLMOps介绍</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/ai/common-acceleration-cards>常见智算加速卡汇总</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/ai/ai-training-inference-scenarios>AI基础架构中常见业务场景痛点</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/ai/cpu-gpu>CPU&GPU架构差异及AI场景中的应用</a></ul><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" tabindex=0 href=/ai/basic>入门知识</a><button aria-label="Expand sidebar category '入门知识'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div></ul><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/cloud-native>云原生</a><button aria-label="Expand sidebar category '云原生'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/notes>日常笔记</a><button aria-label="Expand sidebar category '日常笔记'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/programming>开发语言</a><button aria-label="Expand sidebar category '开发语言'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/architecture>技术架构</a><button aria-label="Expand sidebar category '技术架构'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/management>技术管理</a><button aria-label="Expand sidebar category '技术管理'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/observability>可观测性</a><button aria-label="Expand sidebar category '可观测性'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/database-and-middleware>数据库与中间件</a><button aria-label="Expand sidebar category '数据库与中间件'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/operating-systems-and-networks>操作系统和网络</a><button aria-label="Expand sidebar category '操作系统和网络'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/life>生活笔记</a><button aria-label="Expand sidebar category '生活笔记'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div></ul></nav></div></div></aside><main class=docMainContainer_TBSr><div class="container padding-top--md padding-bottom--lg"><div class=row><div class="col docItemCol_VOVn"><div class=docItemContainer_Djhp><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label=Breadcrumbs><ul class=breadcrumbs itemscope itemtype=https://schema.org/BreadcrumbList><li class=breadcrumbs__item><a aria-label="Home page" class=breadcrumbs__link href=/><svg viewBox="0 0 24 24" class=breadcrumbHomeIcon_YNFT><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill=currentColor /></svg></a><li itemscope itemprop=itemListElement itemtype=https://schema.org/ListItem class=breadcrumbs__item><a class=breadcrumbs__link itemprop=item href=/ai><span itemprop=name>AI技术</span></a><meta itemprop=position content=1><li itemscope itemprop=itemListElement itemtype=https://schema.org/ListItem class=breadcrumbs__item><a class=breadcrumbs__link itemprop=item href=/ai/infra><span itemprop=name>基础架构</span></a><meta itemprop=position content=2><li itemscope itemprop=itemListElement itemtype=https://schema.org/ListItem class=breadcrumbs__item><a class=breadcrumbs__link itemprop=item href=/ai/scheduling><span itemprop=name>算力调度</span></a><meta itemprop=position content=3><li itemscope itemprop=itemListElement itemtype=https://schema.org/ListItem class="breadcrumbs__item breadcrumbs__item--active"><span class=breadcrumbs__link itemprop=name>CPU亲和性与NUMA亲和性调度</span><meta itemprop=position content=4></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type=button class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h2 class="anchor anchorWithStickyNavbar_LWe7" id=引言>引言<a href=#引言 class=hash-link aria-label="Direct link to 引言" title="Direct link to 引言">​</a></h2>
<p>在<code>AI</code>模型开发、训练和推理场景中，计算密集型任务对硬件资源的高效利用提出了极高要求。除了<code>GPU</code>算力本身，<code>CPU</code>和内存的访问效率同样是影响整体性能的关键因素。不合理的<code>CPU</code>与内存分配可能导致跨<code>NUMA</code>节点的内存访问、频繁的进程迁移等问题，从而显著降低系统性能。</p>
<p><code>CPU</code>亲和性（<code>CPU Affinity</code>）和<code>NUMA</code>亲和性（<code>NUMA Affinity</code>）调度技术通过精确控制进程与<code>CPU</code>核心、内存节点的绑定关系，最大化利用硬件拓扑结构，减少资源访问延迟，提升<code>AI</code>工作负载的性能表现。本文将深入介绍这些核心技术的原理、应用场景及在<code>Docker</code>和<code>Kubernetes</code>环境下的具体实现方法。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id=cpu架构简介>CPU架构简介<a href=#cpu架构简介 class=hash-link aria-label="Direct link to CPU架构简介" title="Direct link to CPU架构简介">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=cpu架构层次>CPU架构层次<a href=#cpu架构层次 class=hash-link aria-label="Direct link to CPU架构层次" title="Direct link to CPU架构层次">​</a></h3>
<p>现代服务器的<code>CPU</code>架构呈现多层次的结构，理解这些层次对于配置<code>CPU</code>亲和性至关重要。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=1-物理处理器physical-processorsocket>1. 物理处理器（Physical Processor/Socket）<a href=#1-物理处理器physical-processorsocket class=hash-link aria-label="Direct link to 1. 物理处理器（Physical Processor/Socket）" title="Direct link to 1. 物理处理器（Physical Processor/Socket）">​</a></h4>
<p>物理处理器是指主板上的一个独立<code>CPU</code>芯片。例如：</p>
<ul>
<li>双路服务器：<code>2</code>个物理处理器（<code>Socket 0</code>、<code>Socket 1</code>）</li>
<li>四路服务器：<code>4</code>个物理处理器（<code>Socket 0-3</code>）</li>
</ul>
<p>每个物理处理器拥有独立的：</p>
<ul>
<li>内存控制器（<code>Memory Controller</code>）</li>
<li><code>PCIe</code>控制器（<code>PCIe Root Complex</code>）</li>
<li>最后级缓存（<code>LLC - Last Level Cache</code>，通常是<code>L3</code>缓存）</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=2-cpu核心cpu-core>2. CPU核心（CPU Core）<a href=#2-cpu核心cpu-core class=hash-link aria-label="Direct link to 2. CPU核心（CPU Core）" title="Direct link to 2. CPU核心（CPU Core）">​</a></h4>
<p>每个物理处理器包含多个<code>CPU</code>核心，每个核心是一个独立的执行单元：</p>
<ul>
<li>现代服务器级<code>CPU</code>通常有<code>8-64</code>个核心/处理器</li>
<li>例如<code>Intel Xeon Platinum 8358</code>：<code>32</code>核心/处理器</li>
<li>例如<code>AMD EPYC 9654</code>：<code>96</code>核心/处理器</li>
</ul>
<p>每个<code>CPU</code>核心拥有：</p>
<ul>
<li>独立的<code>L1</code>指令缓存（<code>L1i Cache</code>，通常<code>32-64 KB</code>）</li>
<li>独立的<code>L1</code>数据缓存（<code>L1d Cache</code>，通常<code>32-64 KB</code>）</li>
<li>独立的<code>L2</code>缓存（通常<code>256 KB - 2 MB</code>）</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=3-逻辑处理器logical-processor>3. 逻辑处理器（Logical Processor）<a href=#3-逻辑处理器logical-processor class=hash-link aria-label="Direct link to 3. 逻辑处理器（Logical Processor）" title="Direct link to 3. 逻辑处理器（Logical Processor）">​</a></h4>
<p>通过超线程技术（<code>Hyper-Threading</code>或<code>SMT - Simultaneous Multi-Threading</code>），一个物理核心可以模拟为多个逻辑处理器：</p>
<ul>
<li><code>Intel</code>的超线程：<code>1</code>个物理核心 = <code>2</code>个逻辑处理器</li>
<li><code>AMD</code>的<code>SMT</code>：<code>1</code>个物理核心 = <code>2</code>个逻辑处理器</li>
</ul>
<p>逻辑处理器共享：</p>
<ul>
<li>物理核心的执行单元</li>
<li><code>L1</code>和<code>L2</code>缓存</li>
<li>功能单元（<code>ALU</code>、<code>FPU</code>等）</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=cpu架构层次示例>CPU架构层次示例<a href=#cpu架构层次示例 class=hash-link aria-label="Direct link to CPU架构层次示例" title="Direct link to CPU架构层次示例">​</a></h4>
<p>以一个典型的双路服务器为例：</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#f8f8f2;--prism-background-color:#272822><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-text codeBlock_bY9V thin-scrollbar" style=color:#f8f8f2;background-color:#272822><code class=codeBlockLines_e6Vv><span class=token-line style=color:#f8f8f2><span class="token plain">┌─────────────────────────────────────────────────────────────────────────┐</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">│                            Dual-Socket Server                           │</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">├────────────────────────────────┬────────────────────────────────────────┤</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">│     Socket 0 (NUMA Node 0)     │      Socket 1 (NUMA Node 1)            │</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">├────────────────────────────────┼────────────────────────────────────────┤</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">│  32 Physical Cores (Core 0-31) │   32 Physical Cores (Core 32-63)       │</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">│  64 Logical Processors         │   64 Logical Processors                │</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">│  (0-31, 64-95)                 │   (32-63, 96-127)                      │</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">│                                │                                        │</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">│  Per Core:                     │   Per Core:                            │</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">│  ├─ L1i: 32 KB                 │   ├─ L1i: 32 KB                        │</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">│  ├─ L1d: 48 KB                 │   ├─ L1d: 48 KB                        │</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">│  └─ L2:  2 MB                  │   └─ L2:  2 MB                         │</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">│                                │                                        │</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">│  Shared L3: 60 MB              │   Shared L3: 60 MB                     │</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">│  Local Memory: 256 GB          │   Local Memory: 256 GB                 │</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">│  PCIe Devices: GPU0-3          │   PCIe Devices: GPU4-7                 │</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">└────────────────────────────────┴────────────────────────────────────────┘</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label="Copy code to clipboard" title=Copy class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=cpu缓存架构>CPU缓存架构<a href=#cpu缓存架构 class=hash-link aria-label="Direct link to CPU缓存架构" title="Direct link to CPU缓存架构">​</a></h3>
<p><img decoding=async loading=lazy alt=CPU缓存架构 src=/assets/images/image-44267aaec754cbc5350ddf558fc968e3.png width=1077 height=697 class=img_ev3q></p>
<p><code>CPU</code>缓存是影响<code>CPU</code>亲和性效果的关键因素，采用分层设计：</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=l1-缓存一级缓存>L1 缓存（一级缓存）<a href=#l1-缓存一级缓存 class=hash-link aria-label="Direct link to L1 缓存（一级缓存）" title="Direct link to L1 缓存（一级缓存）">​</a></h4>
<ul>
<li><strong>容量</strong>：每个核心<code>L1i 32 KB</code> + <code>L1d 48 KB</code></li>
<li><strong>访问延迟</strong>：<code>~4</code>个时钟周期（约<code>1ns</code>）</li>
<li><strong>作用域</strong>：每个物理核心私有，同一核心的超线程共享</li>
<li><strong>命中率影响</strong>：进程在同一核心运行，<code>L1</code>命中率最高</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=l2-缓存二级缓存>L2 缓存（二级缓存）<a href=#l2-缓存二级缓存 class=hash-link aria-label="Direct link to L2 缓存（二级缓存）" title="Direct link to L2 缓存（二级缓存）">​</a></h4>
<ul>
<li><strong>容量</strong>：每个核心<code>2 MB</code></li>
<li><strong>访问延迟</strong>：<code>~12</code>个时钟周期（约<code>4-5ns</code>）</li>
<li><strong>作用域</strong>：每个物理核心私有，同一核心的超线程共享</li>
<li><strong>命中率影响</strong>：进程固定在同一核心，<code>L2</code>命中率显著提高</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=l3-缓存三级缓存llc>L3 缓存（三级缓存/LLC）<a href=#l3-缓存三级缓存llc class=hash-link aria-label="Direct link to L3 缓存（三级缓存/LLC）" title="Direct link to L3 缓存（三级缓存/LLC）">​</a></h4>
<ul>
<li><strong>容量</strong>：<code>60 MB</code>（每个处理器/Socket 共享）</li>
<li><strong>访问延迟</strong>：<code>~20-30</code>个时钟周期（约<code>7-10ns</code>）</li>
<li><strong>作用域</strong>：同一物理处理器的所有核心共享</li>
<li><strong>命中率影响</strong>：进程在同一物理处理器内迁移，仍可共享<code>L3</code>缓存</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=缓存一致性协议>缓存一致性协议<a href=#缓存一致性协议 class=hash-link aria-label="Direct link to 缓存一致性协议" title="Direct link to 缓存一致性协议">​</a></h4>
<p>在多核<code>CPU</code>系统中，<code>MESI</code>协议（<code>Modified</code>、<code>Exclusive</code>、<code>Shared</code>、<code>Invalid</code>）维护缓存一致性：</p>
<ul>
<li>当进程在不同核心间迁移时，需要触发缓存失效和重新加载</li>
<li>跨核心访问同一数据需要通过缓存一致性协议同步</li>
<li>频繁的进程迁移会导致大量的缓存一致性流量</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=cpu亲和性的工作原理>CPU亲和性的工作原理<a href=#cpu亲和性的工作原理 class=hash-link aria-label="Direct link to CPU亲和性的工作原��理" title="Direct link to CPU亲和性的工作原理">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=进程与cpu核心的绑定>进程与CPU核心的绑定<a href=#进程与cpu核心的绑定 class=hash-link aria-label="Direct link to 进程与CPU核心的绑定" title="Direct link to 进程与CPU核心的绑定">​</a></h4>
<p>操作系统通过<code>CPU</code>亲和性机制控制进程在哪些<code>CPU</code>核心上运行：</p>
<blockquote>
<p>亲和性掩码（<code>CPU Affinity Mask</code>）是一段位图，每一位对应一个<code>CPU</code>编号，位为<code>1</code>表示允许在该<code>CPU</code>上运行，位为<code>0</code>表示禁止。通过设置掩码，可以精确限制进程的可运行核心集合。</p>
</blockquote>
<p><strong>亲和性掩码（CPU Affinity Mask）</strong>：</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#f8f8f2;--prism-background-color:#272822><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-text codeBlock_bY9V thin-scrollbar" style=color:#f8f8f2;background-color:#272822><code class=codeBlockLines_e6Vv><span class=token-line style=color:#f8f8f2><span class="token plain">┌─────────────────────────────────────────────────────────────────┐</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">│ CPU IDs:    0    1    2    3    4    5    6    7    ...         │</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">│ Affinity:   1    1    0    0    0    0    0    0    ...         │</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">│ Meaning:  allow allow block block block block block block ...   │</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">└─────────────────────────────────────────────────────────────────┘</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">Process can run only on CPU 0 and CPU 1</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label="Copy code to clipboard" title=Copy class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=默认调度行为>默认调度行为<a href=#默认调度行为 class=hash-link aria-label="Direct link to 默认调度行为" title="Direct link to 默认调度行为">​</a></h4>
<p><strong>无亲和性设置时</strong>：</p>
<ol>
<li>操作系统调度器根据负载均衡算法分配进程</li>
<li>进程可能在任意<code>CPU</code>核心间迁移</li>
<li>每次迁移导致：<!-- -->
<ul>
<li><code>L1/L2</code>缓存全部失效，需重新加载（<code>Cold Cache</code>）</li>
<li>上下文切换开销（寄存器保存/恢复）</li>
<li><code>TLB</code>（<code>Translation Lookaside Buffer</code>）失效</li>
</ul>
</li>
</ol>
<p><strong>示例：进程迁移的性能损耗</strong>：</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#f8f8f2;--prism-background-color:#272822><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-text codeBlock_bY9V thin-scrollbar" style=color:#f8f8f2;background-color:#272822><code class=codeBlockLines_e6Vv><span class=token-line style=color:#f8f8f2><span class="token plain">时间线:</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">t0: 进程在 CPU0 运行，L1/L2 缓存已预热，工作集已加载</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">t1: 系统负载均衡，进程迁移到 CPU5</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">t2: CPU5 的 L1/L2 缓存是冷的，需要重新加载工作集</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    - L1/L2 缓存预热: 数千到数万次内存访问</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    - 性能损耗: 首次访问延迟增加 50-100x</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">t3: L1/L2 缓存预热完成，性能恢复</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">t4: 系统再次负载均衡，进程迁移到 CPU12</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">t5: 重复 t2 的缓存预热过程...</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label="Copy code to clipboard" title=Copy class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=设置亲和性后的行为>设置亲和性后的行为<a href=#设置亲和性后的行为 class=hash-link aria-label="Direct link to 设��置亲和性后的行为" title="Direct link to 设置亲和性后的行为">​</a></h4>
<p><strong>绑定到特定核心</strong>（例如绑定到<code>CPU 0-3</code>）：</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#f8f8f2;--prism-background-color:#272822><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-text codeBlock_bY9V thin-scrollbar" style=color:#f8f8f2;background-color:#272822><code class=codeBlockLines_e6Vv><span class=token-line style=color:#f8f8f2><span class="token plain">┌─────────────────────────────────────────────────────────────────┐</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">│ Socket 0                                                        │</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">│ ┌────────┐ ┌────────┐ ┌────────┐ ┌────────┐                     │</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">│ │  CPU0  │ │  CPU1  │ │  CPU2  │ │  CPU3  │  ...                │</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">│ │ ┌────┐ │ │ ┌────┐ │ │ ┌────┐ │ │ ┌────┐ │                     │</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">│ │ │ L1 │ │ │ │ L1 │ │ │ │ L1 │ │ │ │ L1 │ │                     │</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">│ │ │ L2 │ │ │ │ L2 │ │ │ │ L2 │ │ │ │ L2 │ │                     │</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">│ │ └────┘ │ │ └────┘ │ │ └────┘ │ │ └────┘ │                     │</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">│ └────────┘ └────────┘ └────────┘ └────────┘                     │</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">│              Shared L3 Cache (60 MB)                            │</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">│ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━                   │</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">│ Process pinned to these 4 cores to maximize cache locality      │</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">└─────────────────────────────────────────────────────────────────┘</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label="Copy code to clipboard" title=Copy class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<p>优势：</p>
<ol>
<li><strong>减少缓存失效</strong>：进程在少数核心间运行，缓存数据可重复利用</li>
<li><strong>提高缓存命中率</strong>：<!-- -->
<ul>
<li><code>L1/L2</code>：如果固定在单核，命中率接近<code>100%</code></li>
<li><code>L3</code>：在同一<code>Socket</code>内的核心间共享，命中率高</li>
</ul>
</li>
<li><strong>减少内存访问</strong>：缓存命中减少了对远程内存的访问次数</li>
<li><strong>降低缓存一致性开销</strong>：减少跨核心的缓存同步流量</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=超线程与cpu亲和性>超线程与CPU亲和性<a href=#超线程与cpu亲和性 class=hash-link aria-label="Direct link to 超线程与CPU亲和性" title="Direct link to 超线程与CPU亲和性">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=超线程的优劣势>超线程的优劣势<a href=#超线程的优劣势 class=hash-link aria-label="Direct link to 超线程的优劣势" title="Direct link to 超线程的优劣势">​</a></h4>
<p><strong>优势</strong>：</p>
<ul>
<li>提高<code>CPU</code>利用率：当一个线程等待内存时，另一个线程可以使用执行单元</li>
<li>提升吞吐量：在<code>I/O</code>密集型场景下可以达到<code>1.2-1.3x</code>性能提升</li>
</ul>
<p><strong>劣势</strong>：</p>
<ul>
<li>共享执行资源：两个逻辑处理器竞争同一物理核心的执行单元</li>
<li>共享缓存：<code>L1/L2</code>缓存容量减半（每个逻辑处理器只能使用一半）</li>
<li>计算密集型任务：<code>AI</code>训练/推理是计算密集型，超线程带来的性能提升很小甚至负面</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=cpu编号规则>CPU编号规则<a href=#cpu编号规则 class=hash-link aria-label="Direct link to CPU编号规则" title="Direct link to CPU编号规则">​</a></h4>
<p><strong>Linux系统的CPU编号规则</strong>：</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#f8f8f2;--prism-background-color:#272822><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-text codeBlock_bY9V thin-scrollbar" style=color:#f8f8f2;background-color:#272822><code class=codeBlockLines_e6Vv><span class=token-line style=color:#f8f8f2><span class="token plain">物理核心先排列，然后是对应的超线程：</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">Socket 0: 物理核心 0-31  → CPU 0-31</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">Socket 1: 物理核心 32-63 → CPU 32-63</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">Socket 0: 超线程核心     → CPU 64-95</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">Socket 1: 超线程核心     → CPU 96-127</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain" style=display:inline-block></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">映射关系：</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">CPU 0  (物理核心0)  ←→  CPU 64 (核心0的超线程)</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">CPU 1  (物理核心1)  ←→  CPU 65 (核心1的超线程)</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">CPU 32 (物理核心32) ←→  CPU 96 (核心32的超线程)</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">...</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label="Copy code to clipboard" title=Copy class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<p><strong>查看CPU拓扑</strong>：</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#f8f8f2;--prism-background-color:#272822><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style=color:#f8f8f2;background-color:#272822><code class=codeBlockLines_e6Vv><span class=token-line style=color:#f8f8f2><span class="token comment" style=color:#8292a2;font-style:italic># 查看CPU拓扑信息</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">lscpu</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain" style=display:inline-block></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token comment" style=color:#8292a2;font-style:italic># 查看详细的CPU线程映射</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token function" style=color:#e6db74>cat</span><span class="token plain"> /proc/cpuinfo </span><span class="token operator" style=color:#66d9ef>|</span><span class="token plain"> </span><span class="token function" style=color:#e6db74>grep</span><span class="token plain"> </span><span class="token parameter variable" style=color:#f8f8f2>-E</span><span class="token plain"> </span><span class="token string" style=color:#a6e22e>"processor|physical id|core id"</span><span class="token plain"> </span><span class="token operator" style=color:#66d9ef>|</span><span class="token plain"> </span><span class="token function" style=color:#e6db74>paste</span><span class="token plain"> - - -</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label="Copy code to clipboard" title=Copy class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id=ai场景的最佳实践>AI场景的最佳实践<a href=#ai场景的最佳实践 class=hash-link aria-label="Direct link to AI场景的最佳实践" title="Direct link to AI场景的最佳实践">​</a></h4>
<p><strong>推荐配置</strong>：仅使用物理核心，禁用超线程逻辑处理器</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#f8f8f2;--prism-background-color:#272822><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-text codeBlock_bY9V thin-scrollbar" style=color:#f8f8f2;background-color:#272822><code class=codeBlockLines_e6Vv><span class=token-line style=color:#f8f8f2><span class="token plain">❌ 错误配置（包含超线程）：</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">--cpuset-cpus="0-7,64-71"  # CPU 0-7的物理核心 + 超线程</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain" style=display:inline-block></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">✅ 正确配置（仅物理核心）：</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">--cpuset-cpus="0-7"        # 仅CPU 0-7的物理核心</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label="Copy code to clipboard" title=Copy class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<p><strong>原因</strong>：</p>
<ol>
<li><code>AI</code>训练/推理是计算密集型，不受益于超线程</li>
<li>超线程会导致缓存和执行单元竞争，降低单线程性能</li>
<li>避免不同任务的超线程在同一物理核心上竞争</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=验证cpu拓扑的命令>验证CPU拓扑的命令<a href=#验证cpu拓扑的命令 class=hash-link aria-label="Direct link to 验证CPU拓扑的命令" title="Direct link to 验证CPU拓扑的命令">​</a></h3>
<p><strong>1. 查看CPU基本信息</strong>：</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#f8f8f2;--prism-background-color:#272822><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style=color:#f8f8f2;background-color:#272822><code class=codeBlockLines_e6Vv><span class=token-line style=color:#f8f8f2><span class="token plain">lscpu</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label="Copy code to clipboard" title=Copy class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<p>输出示例：</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#f8f8f2;--prism-background-color:#272822><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-text codeBlock_bY9V thin-scrollbar" style=color:#f8f8f2;background-color:#272822><code class=codeBlockLines_e6Vv><span class=token-line style=color:#f8f8f2><span class="token plain">Architecture:             x86_64</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">  CPU op-mode(s):         32-bit, 64-bit</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">  Address sizes:          52 bits physical, 57 bits virtual</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">  Byte Order:             Little Endian</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">CPU(s):                   128</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">  On-line CPU(s) list:    0-127</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">Vendor ID:                GenuineIntel</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">  Model name:             Intel(R) Xeon(R) Gold 6430</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    CPU family:           6</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    Model:                143</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    Thread(s) per core:   2</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    Core(s) per socket:   32</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    Socket(s):            2</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    Stepping:             8</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    BogoMIPS:             4200.00</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">Virtualization features:</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">  Virtualization:         VT-x</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">Caches (sum of all):</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">  L1d:                    3 MiB (64 instances)</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">  L1i:                    2 MiB (64 instances)</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">  L2:                     128 MiB (64 instances)</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">  L3:                     120 MiB (2 instances)</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">NUMA:</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">  NUMA node(s):           2</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">  NUMA node0 CPU(s):      0-31,64-95</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">  NUMA node1 CPU(s):      32-63,96-127</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">...</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label="Copy code to clipboard" title=Copy class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<p><strong>2. 查看CPU缓存信息</strong>：</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#f8f8f2;--prism-background-color:#272822><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style=color:#f8f8f2;background-color:#272822><code class=codeBlockLines_e6Vv><span class=token-line style=color:#f8f8f2><span class="token plain">lscpu </span><span class="token parameter variable" style=color:#f8f8f2>--caches</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label="Copy code to clipboard" title=Copy class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<p><strong>3. 查看详细的NUMA拓扑</strong>：</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#f8f8f2;--prism-background-color:#272822><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style=color:#f8f8f2;background-color:#272822><code class=codeBlockLines_e6Vv><span class=token-line style=color:#f8f8f2><span class="token plain">numactl </span><span class="token parameter variable" style=color:#f8f8f2>--hardware</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label="Copy code to clipboard" title=Copy class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<p><strong>4. 查看进程的CPU亲和性</strong>：</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#f8f8f2;--prism-background-color:#272822><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style=color:#f8f8f2;background-color:#272822><code class=codeBlockLines_e6Vv><span class=token-line style=color:#f8f8f2><span class="token comment" style=color:#8292a2;font-style:italic># 查看进程PID的CPU亲和性</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">taskset </span><span class="token parameter variable" style=color:#f8f8f2>-c</span><span class="token plain"> </span><span class="token parameter variable" style=color:#f8f8f2>-p</span><span class="token plain"> </span><span class="token operator" style=color:#66d9ef>&lt;</span><span class="token plain">PID</span><span class="token operator" style=color:#66d9ef>></span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain" style=display:inline-block></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain"></span><span class="token comment" style=color:#8292a2;font-style:italic># 设置进程的CPU亲和性</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">taskset </span><span class="token parameter variable" style=color:#f8f8f2>-c</span><span class="token plain"> </span><span class="token number" style=color:#ae81ff>0</span><span class="token plain">-7 </span><span class="token operator" style=color:#66d9ef>&lt;</span><span class="token plain">command</span><span class="token operator" style=color:#66d9ef>></span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label="Copy code to clipboard" title=Copy class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id=numa架构简介>NUMA架构简介<a href=#numa架构简介 class=hash-link aria-label="Direct link to NUMA架构简介" title="Direct link to NUMA架构简介">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=什么是numa>什么是NUMA<a href=#什么是numa class=hash-link aria-label="Direct link to 什么是NUMA" title="Direct link to 什么是NUMA">​</a></h3>
<p><code>NUMA</code>（<code>Non-Uniform Memory Access</code>，非统一内存访问）是现代多处理器系统采用的一种内存访问架构。在<code>NUMA</code>架构中，系统内存被划分为多个<code>NUMA</code>节点（<code>NUMA Node</code>），每个节点包含一组<code>CPU</code>核心和本地内存。</p>
<p>与传统的<code>UMA</code>（<code>Uniform Memory Access</code>，统一内存访问）架构相比，<code>NUMA</code>架构具有以下特点：</p>
<ul>
<li><strong>本地访问优化</strong>：<code>CPU</code>访问本地<code>NUMA</code>节点的内存速度最快</li>
<li><strong>远程访问代价</strong>：<code>CPU</code>访问其他<code>NUMA</code>节点的内存（跨节点访问）会产生额外延迟</li>
<li><strong>可扩展性强</strong>：通过增加<code>NUMA</code>节点可以线性扩展系统规模</li>
</ul>
<p><img decoding=async loading=lazy alt=CPU处理器架构：SMP、NUMA、MPP src=/assets/images/image-7-63d636af9ae21944724181c150a612e1.png width=1080 height=772 class=img_ev3q></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=numa架构的层级结构>NUMA架构的层级结构<a href=#numa架构的层级结构 class=hash-link aria-label="Direct link to NUMA架构的层级结构" title="Direct link to NUMA架构的层级结构">​</a></h3>
<p>例如一个典型的<code>NUMA</code>系统具有以下层级结构：</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#f8f8f2;--prism-background-color:#272822><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-text codeBlock_bY9V thin-scrollbar" style=color:#f8f8f2;background-color:#272822><code class=codeBlockLines_e6Vv><span class=token-line style=color:#f8f8f2><span class="token plain">┌─────────────────────────────────────────────────────────────┐</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">│                        NUMA 系统                              │</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">├──────────────────────────┬──────────────────────────────────┤</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">│     NUMA Node 0          │        NUMA Node 1               │</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">├──────────────────────────┼──────────────────────────────────┤</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">│  CPU 0-31, 64-95         │     CPU 32-63, 96-127            │</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">│  Local Memory            │     Local Memory                 │</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">│  PCIe Devices (GPU0-3)   │     PCIe Devices (GPU4-7)        │</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">└──────────────────────────┴──────────────────────────────────┘</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label="Copy code to clipboard" title=Copy class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<p>在上述架构中：</p>
<ul>
<li>每个<code>NUMA</code>节点包含一组<code>CPU</code>核心</li>
<li>每个<code>NUMA</code>节点有自己的本地内存</li>
<li><code>PCIe</code>设备（如<code>GPU</code>）也归属于特定的<code>NUMA</code>节点</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=numa对性能的影响>NUMA对性能的影响<a href=#numa对性能的�影响 class=hash-link aria-label="Direct link to NUMA对性能的影响" title="Direct link to NUMA对性能的影响">​</a></h3>
<p>在<code>AI</code>训练和推理场景中，<code>NUMA</code>架构对性能的影响主要体现在：</p>
<ol>
<li>
<p><strong>内存访问延迟</strong>：本地内存访问延迟通常为<code>100-200ns</code>，而跨<code>NUMA</code>节点访问延迟可达<code>300-500ns</code>，差距达<code>2-3</code>倍</p>
</li>
<li>
<p><strong>内存带宽</strong>：跨节点访问会占用<code>NUMA</code>互连总线，降低整体内存带宽</p>
</li>
<li>
<p><strong>PCIe通信延迟</strong>：</p>
<ul>
<li><code>GPU</code>物理连接在特定<code>NUMA</code>节点的<code>PCIe</code>总线上</li>
<li><code>CPU</code>访问非本地<code>NUMA</code>节点的<code>GPU</code>需要经过<code>NUMA</code>互联（<code>QPI</code>/<code>UPI</code>）</li>
<li>跨<code>NUMA</code>的<code>PCIe</code>访问会增加<code>100-200ns</code>额外延迟</li>
<li><code>DMA(Direct Memory Access)</code>传输带宽可能降低<code>50%</code>以上</li>
</ul>
</li>
<li>
<p><strong>GPU-CPU通信效率</strong>：</p>
<ul>
<li><code>GPU kernel</code>启动、状态查询、寄存器访问等<code>PCIe</code>事务受跨<code>NUMA</code>影响</li>
<li>频繁的<code>CPU-GPU</code>交互会放大跨<code>NUMA</code>开销</li>
<li>影响整体<code>GPU</code>利用率和吞吐量</li>
</ul>
</li>
<li>
<p><strong>数据传输效率</strong>：跨<code>NUMA</code>节点的数据传输会影响<code>GPU</code>与<code>CPU</code>之间的数据交换效率，包括：</p>
<ul>
<li>主机到设备（<code>Host-to-Device</code>）传输</li>
<li>设备到主机（<code>Device-to-Host</code>）传输</li>
<li>统一内存（<code>Unified Memory</code>）的页面迁移</li>
</ul>
</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=numa的更多介绍>NUMA的更多介绍<a href=#numa的更多介绍 class=hash-link aria-label="Direct link to NUMA的更多介绍" title="Direct link to NUMA的更多介绍">​</a></h3>
<p>关于<code>NUMA</code>架构的更多细节，可以参考我的另一篇文章：<a href=/operating-systems-and-networks/cpu-architecture-smp-numa-mpp>CPU处理器架构：SMP、NUMA、MPP</a></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id=cpunuma亲和性的重要性>CPU&NUMA亲和性的重要性<a href=#cpunuma亲和性的重要性 class=hash-link aria-label="Direct link to CPU&NUMA亲和性的重要性" title="Direct link to CPU&NUMA亲和性的重要性">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=cpu亲和性的作用>CPU亲和性的作用<a href=#cpu亲和性的作用 class=hash-link aria-label="Direct link to CPU亲和性的作用" title="Direct link to CPU亲和性的作用">​</a></h3>
<p><code>CPU</code>亲和性（<code>CPU Affinity</code>）是指将进程或线程绑定到特定的<code>CPU</code>核心上运行。在<code>AI</code>工作负载中，合理的<code>CPU</code>亲和性配置可以：</p>
<ol>
<li><strong>减少上下文切换</strong>：避免进程在不同<code>CPU</code>核心间频繁迁移，减少上下文切换开销</li>
<li><strong>提升缓存命中率</strong>：进程固定在特定核心运行，可以更好地利用<code>CPU</code>的<code>L1</code>、<code>L2</code>、<code>L3</code>缓存</li>
<li><strong>降低延迟抖动</strong>：避免进程迁移带来的性能波动，提供更稳定的延迟表现</li>
<li><strong>避免资源竞争</strong>：将不同任务绑定到不同的核心，减少<code>CPU</code>资源争抢</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=numa亲和性的作用>NUMA亲和性的作用<a href=#numa亲和性的作用 class=hash-link aria-label="Direct link to NUMA亲和性的作用" title="Direct link to NUMA亲和性的作用">​</a></h3>
<p><code>NUMA</code>亲和性（<code>NUMA Affinity</code>）是指将进程、内存分配和<code>I/O</code>设备绑定到同一<code>NUMA</code>节点，以<strong>优化内存访问性能</strong>。在<code>AI</code>场景中的价值包括：</p>
<ol>
<li><strong>降低内存访问延迟</strong>：确保进程访问本地内存，避免跨<code>NUMA</code>节点的远程内存访问</li>
<li><strong>提升内存带宽</strong>：本地内存访问可以充分利用<code>NUMA</code>节点的内存带宽</li>
<li><strong>优化GPU-CPU通信</strong>：将<code>GPU</code>、对应的<code>CPU</code>核心和内存绑定到同一<code>NUMA</code>节点，最小化数据传输延迟</li>
<li><strong>提高整体吞吐量</strong>：通过减少跨节点通信，提升系统整体的数据处理能力</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=ai模型训练推理场景中的影响>AI模型训练推理场景中的影响<a href=#ai模型训练推理场景中的影响 class=hash-link aria-label="Direct link to AI模型训练推理场景中的影响" title="Direct link to AI模型训练推理场景中的影响">​</a></h3>
<p>在<code>AI</code>模型训练和推理场景中，不合理的亲和性配置可能导致：</p>
<ul>
<li><strong>训练速度下降</strong>：数据加载、预处理过程中的跨<code>NUMA</code>访问会拖累整体训练速度</li>
<li><strong>推理延迟增加</strong>：推理服务中的请求处理涉及频繁的<code>CPU-GPU</code>交互，跨<code>NUMA</code>访问会增加延迟</li>
<li><strong>吞吐量降低</strong>：在高并发推理场景下，跨<code>NUMA</code>访问会成为系统瓶颈</li>
<li><strong>性能不稳定</strong>：进程迁移和非本地内存访问会导致性能抖动</li>
</ul>
<p>通过合理配置<code>CPU</code>亲和性和<code>NUMA</code>亲和性，通常可以获得<code>10%-30%</code>的性能提升，在某些场景下甚至可以达到<code>50%</code>以上的优化效果。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id=cpunuma亲和性示例分析>CPU&NUMA亲和性示例分析<a href=#cpunuma亲和性示例分析 class=hash-link aria-label="Direct link to CPU&NUMA亲�和性示例分析" title="Direct link to CPU&NUMA亲和性示例分析">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=理解nvidia-smi-topo命令输出>理解nvidia-smi topo命令输出<a href=#理解nvidia-smi-topo命令输出 class=hash-link aria-label="Direct link to 理解nvidia-smi topo命令输出" title="Direct link to 理解nvidia-smi topo命令输出">​</a></h3>
<p><code>NVIDIA</code>提供了<code>nvidia-smi topo -m</code>命令来查看<code>GPU</code>之间以及<code>GPU</code>与<code>CPU</code>之间的拓扑关系。让我们详细分析提供的拓扑信息：</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#f8f8f2;--prism-background-color:#272822><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-text codeBlock_bY9V thin-scrollbar" style=color:#f8f8f2;background-color:#272822><code class=codeBlockLines_e6Vv><span class=token-line style=color:#f8f8f2><span class="token plain">        GPU0    GPU1    GPU2    GPU3    GPU4    GPU5    GPU6    GPU7    CPU Affinity    NUMA Affinity   GPU NUMA ID</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">GPU0     X      PIX     NODE    NODE    SYS     SYS     SYS     SYS     0-31,64-95      0               N/A</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">GPU1    PIX      X      NODE    NODE    SYS     SYS     SYS     SYS     0-31,64-95      0               N/A</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">GPU2    NODE    NODE     X      PIX     SYS     SYS     SYS     SYS     0-31,64-95      0               N/A</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">GPU3    NODE    NODE    PIX      X      SYS     SYS     SYS     SYS     0-31,64-95      0               N/A</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">GPU4    SYS     SYS     SYS     SYS      X      PIX     NODE    NODE    32-63,96-127    1               N/A</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">GPU5    SYS     SYS     SYS     SYS     PIX      X      NODE    NODE    32-63,96-127    1               N/A</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">GPU6    SYS     SYS     SYS     SYS     NODE    NODE     X      PIX     32-63,96-127    1               N/A</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">GPU7    SYS     SYS     SYS     SYS     NODE    NODE    PIX      X      32-63,96-127    1               N/A</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain" style=display:inline-block></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">$ k logs pod/numa-affinity-test</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">        GPU0    GPU1    GPU2    GPU3    CPU Affinity    NUMA Affinity   GPU NUMA ID</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">GPU0     X      PIX     NODE    NODE    4-7,68-71       0               N/A</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">GPU1    PIX      X      NODE    NODE    4-7,68-71       0               N/A</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">GPU2    NODE    NODE     X      PIX     4-7,68-71       0               N/A</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">GPU3    NODE    NODE    PIX      X      4-7,68-71       0               N/A</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain" style=display:inline-block></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">Legend:</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain" style=display:inline-block></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">  X    = Self</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">  SYS  = Connection traversing PCIe as well as the SMP interconnect between NUMA nodes (e.g., QPI/UPI)</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">  NODE = Connection traversing PCIe as well as the interconnect between PCIe Host Bridges within a NUMA node</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">  PHB  = Connection traversing PCIe as well as a PCIe Host Bridge (typically the CPU)</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">  PXB  = Connection traversing multiple PCIe bridges (without traversing the PCIe Host Bridge)</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">  PIX  = Connection traversing at most a single PCIe bridge</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">  NV#  = Connection traversing a bonded set of # NVLinks</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label="Copy code to clipboard" title=Copy class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=连接类型说明>连接类型说明<a href=#连接类型说明 class=hash-link aria-label="Direct link to 连接类型说明" title="Direct link to 连��接类型说明">​</a></h3>
<p>矩阵中的符号表示<code>GPU</code>之间的连接类型，按照性能从高到低排列：</p>
<table><thead><tr><th>连接类型<th>说明<th>典型带宽<th>适用场景<tbody><tr><td><code>X</code><td>自身<td><code>N/A</code><td>同一<code>GPU</code><tr><td><code>NV#</code><td><code>NVLink</code>连接（#表示链接数量）<td><code>300-900 GB/s</code><td>高性能<code>GPU</code>间通信（如<code>NVLink 3.0/4.0</code>）<tr><td><code>PIX</code><td>同一<code>PCIe</code>交换机<br>可能包含<code>NVLink Bridge</code><td><code>PCIe: 16-64 GB/s</code><br><code>NVLink Bridge: 100-200 GB/s</code><td>同<code>PCIe</code>树<code>GPU</code>通信<br>部分消费级<code>GPU</code>使用<code>NVLink Bridge</code>互联<tr><td><code>NODE</code><td>同一<code>NUMA</code>节点，不同<code>PCIe</code>交换机<td><code>16-32 GB/s</code><td>同<code>NUMA</code>节点<code>GPU</code>跨<code>PCIe</code>交换机通信<tr><td><code>SYS</code><td>跨<code>NUMA</code>节点，通过<code>CPU</code>互联<td><code>8-16 GB/s</code><td>跨<code>NUMA</code>节点<code>GPU</code>通信，性能最低</table>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=cpu-affinity字段解析>CPU Affinity字段解析<a href=#cpu-affinity字段解析 class=hash-link aria-label="Direct link to CPU Affinity字段解析" title="Direct link to CPU Affinity字段解析">​</a></h3>
<p><code>CPU Affinity</code>列显示了每个<code>GPU</code>关联的最优<code>CPU</code>核心范围：</p>
<ul>
<li>
<p><strong>GPU0-GPU3</strong>: <code>0-31, 64-95</code></p>
<ul>
<li>物理核心：<code>0-31</code></li>
<li>超线程核心：<code>64-95</code></li>
<li>总共<code>32</code>个物理核心，<code>64</code>个逻辑核心（启用超线程）</li>
</ul>
</li>
<li>
<p><strong>GPU4-GPU7</strong>: <code>32-63, 96-127</code></p>
<ul>
<li>物理核心：<code>32-63</code></li>
<li>超线程核心：<code>96-127</code></li>
<li>总共<code>32</code>个物理核心，<code>64</code>个逻辑核心（启用超线程）</li>
</ul>
</li>
</ul>
<p><strong>关键理解</strong>：当进程需要使用特定<code>GPU</code>时，应将其绑定到该<code>GPU</code>的<code>CPU Affinity</code>范围内的核心，以实现最优性能。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=numa-affinity字段解析>NUMA Affinity字段解析<a href=#numa-affinity字段解析 class=hash-link aria-label="Direct link to NUMA Affinity字段解析" title="Direct link to NUMA Affinity字段解析">​</a></h3>
<p><code>NUMA Affinity</code>列显示了每个<code>GPU</code>所属的<code>NUMA</code>节点：</p>
<ul>
<li><strong>GPU0-GPU3</strong>: 属于<code>NUMA Node 0</code></li>
<li><strong>GPU4-GPU7</strong>: 属于<code>NUMA Node 1</code></li>
</ul>
<p>这意味着：</p>
<ul>
<li>使用<code>GPU0-GPU3</code>的任务应绑定到<code>NUMA Node 0</code>的<code>CPU</code>核心和内存</li>
<li>使用<code>GPU4-GPU7</code>的任务应绑定到<code>NUMA Node 1</code>的<code>CPU</code>核心和内存</li>
</ul>
<p><strong>NUMA与PCIe拓扑的关系</strong>：</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#f8f8f2;--prism-background-color:#272822><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-text codeBlock_bY9V thin-scrollbar" style=color:#f8f8f2;background-color:#272822><code class=codeBlockLines_e6Vv><span class=token-line style=color:#f8f8f2><span class="token plain">NUMA Node 0                          NUMA Node 1</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">├── CPU 0-31, 64-95                  ├── CPU 32-63, 96-127</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">├── Local Memory                     ├── Local Memory</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">└── PCIe Root Complex                └── PCIe Root Complex</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    ├── PCIe Switch 0                    ├── PCIe Switch 2</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    │   ├── GPU0                         │   ├── GPU4</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    │   └── GPU1                         │   └── GPU5</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">    └── PCIe Switch 1                    └── PCIe Switch 3</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">        ├── GPU2                             ├── GPU6</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">        └── GPU3                             └── GPU7</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label="Copy code to clipboard" title=Copy class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<p><strong>关键理解</strong>：</p>
<ul>
<li>每个<code>GPU</code>物理连接到特定<code>NUMA</code>节点的<code>PCIe</code>总线</li>
<li><code>CPU</code>访问非本地<code>NUMA</code>节点的<code>GPU</code>需要经过<code>NUMA</code>互联（<code>QPI/UPI</code>）</li>
<li>跨<code>NUMA</code>的<code>PCIe</code>访问会显著增加延迟并降低带宽</li>
<li>最佳性能需要<code>CPU</code>、内存、<code>GPU</code>都在同一<code>NUMA</code>节点</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=gpu-numa-id字段解析>GPU NUMA ID字段解析<a href=#gpu-numa-id字段解析 class=hash-link aria-label="Direct link to GPU NUMA ID字段解析" title="Direct link to GPU NUMA ID字段解析">​</a></h3>
<p><code>GPU NUMA ID</code>列在支持的平台上显示<code>GPU</code>设备本身的<code>NUMA</code>节点<code>ID</code>。在上述示例中，所有<code>GPU</code>的<code>GPU NUMA ID</code>都显示为<code>N/A</code>，这表示：</p>
<p><strong><code>N/A</code>的含义</strong>：</p>
<ul>
<li><code>GPU</code>没有自己的独立<code>NUMA</code>节点</li>
<li><code>GPU</code>作为<code>PCIe</code>设备挂载在<code>CPU</code>的<code>NUMA</code>节点下</li>
<li>应该参考<code>NUMA Affinity</code>列来确定<code>GPU</code>所属的<code>NUMA</code>节点</li>
</ul>
<p><strong>何时会显示具体的NUMA ID</strong>：
在某些高端系统架构中（如<code>AMD Infinity Fabric</code>架构或<code>NVIDIA Grace Hopper Superchip</code>），<code>GPU</code>可能拥有自己的<code>NUMA</code>节点：</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#f8f8f2;--prism-background-color:#272822><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-text codeBlock_bY9V thin-scrollbar" style=color:#f8f8f2;background-color:#272822><code class=codeBlockLines_e6Vv><span class=token-line style=color:#f8f8f2><span class="token plain">        GPU0    ...    CPU Affinity    NUMA Affinity   GPU NUMA ID</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">GPU0     X      ...    0-31,64-95      0               2</span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">GPU1    PIX     ...    0-31,64-95      0               3</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label="Copy code to clipboard" title=Copy class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<p>在这种情况下：</p>
<ul>
<li><code>NUMA Affinity: 0</code>表示<code>GPU</code>物理连接在<code>NUMA Node 0</code>的<code>PCIe</code>总线上</li>
<li><code>GPU NUMA ID: 2</code>表示<code>GPU</code>本身被系统识别为<code>NUMA Node 2</code></li>
<li>这种架构下，<code>GPU</code>内存（显存）可以作为独立的<code>NUMA</code>节点被<code>CPU</code>直接访问</li>
<li>支持<code>CPU</code>直接访问<code>GPU</code>内存，实现更高效的异构内存管理</li>
</ul>
<p><strong>对配置的影响</strong>：</p>
<ul>
<li><strong>N/A场景</strong>（最常见）：按照<code>NUMA Affinity</code>列配置<code>CPU</code>和内存亲和性即可</li>
<li><strong>独立NUMA ID场景</strong>：需要考虑<code>GPU</code>显存作为额外<code>NUMA</code>节点的影响，可能需要配置更复杂的内存策略（如允许访问<code>GPU NUMA</code>节点）</li>
</ul>
<p><strong>验证命令</strong>：</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#f8f8f2;--prism-background-color:#272822><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style=color:#f8f8f2;background-color:#272822><code class=codeBlockLines_e6Vv><span class=token-line style=color:#f8f8f2><span class="token comment" style=color:#8292a2;font-style:italic># 查看系统所有NUMA节点</span><span class="token plain"></span><br></span><span class=token-line style=color:#f8f8f2><span class="token plain">numactl </span><span class="token parameter variable" style=color:#f8f8f2>--hardware</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label="Copy code to clipboard" title=Copy class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=拓扑分析总结>拓扑分析总结<a href=#拓扑分析总结 class=hash-link aria-label="Direct link to 拓扑分析总结" title="Direct link to 拓扑分析总结">​</a></h3>
<p>从上述拓扑信息可以得出以下结论：</p>
<ol>
<li>
<p><strong>GPU分组</strong>：</p>
<ul>
<li>组1：<code>GPU0-GPU3</code>（<code>NUMA Node 0</code>）</li>
<li>组2：<code>GPU4-GPU7</code>（<code>NUMA Node 1</code>）</li>
</ul>
</li>
<li>
<p><strong>GPU间连接模式</strong>：</p>
<ul>
<li><code>GPU0-GPU1</code>通过<code>PIX</code>连接（同<code>PCIe</code>交换机）</li>
<li><code>GPU2-GPU3</code>通过<code>PIX</code>连接（同<code>PCIe</code>交换机）</li>
<li><code>GPU0/1</code>与<code>GPU2/3</code>通过<code>NODE</code>连接（同<code>NUMA</code>节点，不同<code>PCIe</code>交换机）</li>
<li>跨<code>NUMA</code>节点的<code>GPU</code>通过<code>SYS</code>连接（性能最低）</li>
</ul>
</li>
<li>
<p><strong>最佳实践</strong>：</p>
<ul>
<li>单卡任务：使用任意一张<code>GPU</code>，绑定到对应的<code>CPU</code>核心和<code>NUMA</code>节点</li>
<li>2卡任务：优先选择<code>GPU0-GPU1</code>或<code>GPU2-GPU3</code>等<code>PIX</code>连接的<code>GPU</code>对</li>
<li>4卡任务：选择<code>GPU0-GPU3</code>或<code>GPU4-GPU7</code>（同<code>NUMA</code>节点，性能最优）</li>
<li>5卡任务：例如<code>GPU0-GPU4</code>，会跨<code>NUMA</code>节点，<code>GPU4</code>与<code>GPU0-3</code>通信性能较低（<code>SYS</code>连接）</li>
<li>跨<code>NUMA</code>任务：尽量选择<code>4+4</code>的组合（如<code>GPU0-3</code> + <code>GPU4-7</code>在不同节点），避免<code>5</code>卡这种不均衡配置</li>
</ul>
</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id=docker中的cpunuma亲和性配置>Docker中的CPU&NUMA亲和性配置<a href=#docker中的cpunuma亲和性配置 class=hash-link aria-label="Direct link to Docker中的CPU&NUMA亲和性配置" title="Direct link to Docker中的CPU&NUMA亲和性配置">​</a></h2>
<p>参考章节：<a href=/ai/cpu-numa-affinity-in-docker>Docker中的CPU&NUMA亲和性配置</a></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id=kubernetes中cpunuma亲和性配置>Kubernetes中CPU&NUMA亲和性配置<a href=#kubernetes中cpunuma亲和性配置 class=hash-link aria-label="Direct link to Kubernetes中CPU&NUMA亲和性配置" title="Direct link to Kubernetes中CPU&NUMA亲和性配置">​</a></h2>
<p>参考章节：<a href=/cloud-native/kubernetes-cpu-numa-affinity>Kubernetes CPU&NUMA亲和性调度调度</a></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href=/ai/hybrid-scheduling-scale-down-control><div class=pagination-nav__sublabel>Previous</div><div class=pagination-nav__label>混部调度中如何控制在线服务的缩容逻辑</div></a><a class="pagination-nav__link pagination-nav__link--next" href=/ai/cpu-numa-affinity-in-docker><div class=pagination-nav__sublabel>Next</div><div class=pagination-nav__label>Docker中的CPU&NUMA亲和性配置</div></a></nav><div class=docusaurus-mt-lg></div></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href=#引言 class="table-of-contents__link toc-highlight">引言</a><li><a href=#cpu架构简介 class="table-of-contents__link toc-highlight">CPU架构简介</a><ul><li><a href=#cpu架构层次 class="table-of-contents__link toc-highlight">CPU架构层次</a><li><a href=#cpu缓存架构 class="table-of-contents__link toc-highlight">CPU缓存架构</a><li><a href=#cpu亲和性的工作原理 class="table-of-contents__link toc-highlight">CPU亲和性的工作原理</a><li><a href=#超线程与cpu亲和性 class="table-of-contents__link toc-highlight">超线程与CPU亲和性</a><li><a href=#验证cpu拓扑的命令 class="table-of-contents__link toc-highlight">验证CPU拓扑的命令</a></ul><li><a href=#numa架构简介 class="table-of-contents__link toc-highlight">NUMA架构简介</a><ul><li><a href=#什么是numa class="table-of-contents__link toc-highlight">什么是NUMA</a><li><a href=#numa架构的层级结构 class="table-of-contents__link toc-highlight">NUMA架构的层级结构</a><li><a href=#numa对性能的影响 class="table-of-contents__link toc-highlight">NUMA对性能的影响</a><li><a href=#numa的更多介绍 class="table-of-contents__link toc-highlight">NUMA的更多介绍</a></ul><li><a href=#cpunuma亲和性的重要性 class="table-of-contents__link toc-highlight">CPU&NUMA亲和性的重要性</a><ul><li><a href=#cpu亲和性的作用 class="table-of-contents__link toc-highlight">CPU亲和性的作用</a><li><a href=#numa亲和性的作用 class="table-of-contents__link toc-highlight">NUMA亲和性的作用</a><li><a href=#ai模型训练推理场景中的影响 class="table-of-contents__link toc-highlight">AI模型训练推理场景中的影响</a></ul><li><a href=#cpunuma亲和性示例分析 class="table-of-contents__link toc-highlight">CPU&NUMA亲和性示例分析</a><ul><li><a href=#理解nvidia-smi-topo命令输出 class="table-of-contents__link toc-highlight">理解nvidia-smi topo命令输出</a><li><a href=#连接类型说明 class="table-of-contents__link toc-highlight">连接类型说明</a><li><a href=#cpu-affinity字段解析 class="table-of-contents__link toc-highlight">CPU Affinity字段解析</a><li><a href=#numa-affinity字段解析 class="table-of-contents__link toc-highlight">NUMA Affinity字段解析</a><li><a href=#gpu-numa-id字段解析 class="table-of-contents__link toc-highlight">GPU NUMA ID字段解析</a><li><a href=#拓扑分析总结 class="table-of-contents__link toc-highlight">拓扑分析总结</a></ul><li><a href=#docker中的cpunuma亲和性配置 class="table-of-contents__link toc-highlight">Docker中的CPU&NUMA亲和性配置</a><li><a href=#kubernetes中cpunuma亲和性配置 class="table-of-contents__link toc-highlight">Kubernetes中CPU&NUMA亲和性配置</a></ul></div></div></div></div></main></div></div></div><footer class=footer><div class="container container-fluid"><div class="footer__bottom text--center"><div class=footer__copyright>Copyright 2026 johng.cn</div></div></div></footer></div>