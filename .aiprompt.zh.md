


# NFD&GFD

角色：你是一名AI算力系统研发转结，也是一名Kubernetes云原生研发专家，同时也是NVIDIA GPU的使用专家。
背景：
1. 我正在编写一篇文章，介绍NFD&GFD技术，文章的文件路径: /Users/john/Workspace/github/gqcn/johns-blog/docs/docs/4000-AI技术/NFD&GFD.md


要求：我需要你按照以下要求完成文章的编写：
1. 分别介绍NFD&GFD的基本介绍、背景、作用、实现原理
2. 文章结尾附带NFD和GFD的参考资料链接，特别是开源项目的地址链接

# GPU Share常见方案

角色：你是一名AI算力系统研发专家，也是一名Kubernetes云原生研发专家，同时也是NVIDIA GPU的使用专家。
背景：
1. 我正在编写一篇文章，介绍GPU Share常见方案，文章的文件路径: /Users/john/Workspace/github/gqcn/johns-blog/docs/docs/1000-AI技术/0-NVIDIA/5000-GPU Share 常见方案.md


要求：我需要你按照以下要求完成文章的编写：
1. 介绍几个GPU Share的常见方案，包括：
- Single Process In CUDA
- Multi-Process with CUDA MPS
- Time-slicing
- MIG
- Virtualization with vGPU

2. 按照以下表格对这几种GPU Share的技术方案进行对比：

| 特性 | MPS (Multi-Process Service) | MIG (Multi-Instance GPU) |
|------|----------------------------|-------------------------|
| 隔离级别 | 软件级隔离 | 硬件级隔离 |
| 资源分配 | 动态分配，共享计算单元 | 静态分配，独立计算单元 |
| 故障传播 | 存在故障传播风险 | 完全隔离，无故障传播 |
| 灵活性 | 高，可动态调整资源分配 | 低，需要预先定义分区方案 |
| 部署复杂度 | 较低，软件配置即可 | 较高，需要完全驱逐业务后操作 |
| 支持的`GPU` | 计算能力 `>= 3.5`的`GPU` | 仅`Ampere`架构及之后的特定`GPU` |
| 适用场景 | 多副本推理服务、小模型训练 | 多租户环境、需要强隔离的业务 |

3. 从算力隔离、显存隔离、故障隔离这3个维度给一个总结，哪种方案最好。


# GPU监控方案

角色：你是一名AI算力系统研发专家，也是一名Kubernetes云原生研发专家，同时也是NVIDIA GPU的使用专家。
背景：
1. 我正在编写一篇文章，介绍GPU的监控方案，文章的文件路径: /Users/john/Workspace/github/gqcn/johns-blog/docs/docs/4000-AI技术/GPU监控方案.md


要求：我需要你按照以下要求完成文章的编写：
1. 介绍几个GPU监控的常见方案
2. 推荐一款GPU的监控方案详细介绍
3. 介绍该监控方案提供的完整的监控指标，以表格的形式展示
4. 介绍使用Prometheus对接该监控的配置示例

# 常见厂商加速卡DevicePlugin标签

角色：你是一名AI算力系统研发转结，也是一名Kubernetes云原生研发专家，同时也是NVIDIA GPU的使用专家。
背景：
1. 我正在编写一篇文章，介绍常见厂商加速卡DevicePlugin标签，文章的文件路径: /Users/john/Workspace/github/gqcn/johns-blog/docs/docs/4000-AI技术/2500-常见厂商加速卡DevicePlugin介绍.md
2. 关于NVIDIA的加速卡DevicePlugin自动生成的节点标签介绍请参考另一篇文章，文章地址：/Users/john/Workspace/github/gqcn/johns-blog/docs/docs/4000-AI技术/2000-NFD&GFD技术介绍.md


要求：我需要你按照以下要求完成文章的编写：
1. 简单介绍DevicePlugin的背景和用途
2. 介绍几个常见厂商的加速卡
3. 介绍每个厂商的加速卡DevicePlugin自动生成的节点标签，以表格的形式展示

# 常见厂商加速卡DevicePlugin标签

角色：你是一名AI算力系统研发转结，也是一名Kubernetes云原生研发专家，同时也是NVIDIA GPU的使用专家。
背景：
1. 我正在编写一篇文章，介绍常见厂商加速卡DevicePlugin标签，文章的文件路径: /Users/john/Workspace/github/gqcn/johns-blog/docs/docs/4000-AI技术/2500-常见厂商加速卡DevicePlugin介绍.md
2. 关于NVIDIA的加速卡DevicePlugin自动生成的节点标签介绍请参考另一篇文章，文章地址：/Users/john/Workspace/github/gqcn/johns-blog/docs/docs/4000-AI技术/2000-NFD&GFD技术介绍.md


要求：我需要你按照以下要求完成文章的编写：
1. 简单介绍DevicePlugin的背景和用途
2. 介绍几个常见厂商的加速卡
3. 介绍每个厂商的加速卡DevicePlugin自动生成的节点标签，以表格的形式展示


# RAG技术原理

角色：你是一名RAG技术专家。
背景：
1. 我正在编写一篇文章，介绍RAG技术原理，文章的文件路径: /Users/john/Workspace/github/gqcn/johns-blog/docs/docs/4000-AI技术/1500-RAG技术原理.md


要求：我需要你按照以下要求完成文章的编写：
1. 介绍RAG技术的背景和用途。
2. 介绍RAG技术的实现原理，以及实现方式。
3. 介绍RAG技术的常见应用场景，以及实际业务场景中的痛点。


# Kubernetes审计日志开启与查看

角色：你是一名Kubernetes云原生技术专家。
背景：
1. 工作上出现Deployment资源被莫名其妙删除的问题，但是不知道哪里触发了删除操作。
2. 因此我需要编写一篇文章，介绍kubernetes审计日志的开启与查看，文章的文件路径: /Users/john/Workspace/github/gqcn/johns-blog/docs/docs/2000-云原生/200-Kubernetes/12000-Kubernetes审计日志开启与查看.md


要求：我需要你按照以下要求完成文章的编写：
1. 介绍kubernetes审计日志的背景和用途。
2. 如何开启审计日志
3. 到哪里去查看审计日志
4. 审计日志的内容格式


# vGPU方案调研

背景：
我需要编写一篇文章，介绍vGPU的方案调研，文章的文件路径: /Users/john/Workspace/github/gqcn/johns-blog/docs/docs/1000-AI技术/500-vGPU/1000-vGPU方案调研.md

要求：我需要你按照以下要求完成文章的编写：
1. 介绍vGPU的背景和价值。
2. 介绍业界主流的vGPU方案以及比较，通过表格的形式来展示，例如：
- nvidia mps&mig，特别是需要介绍mps的隔离性缺点
- 用户态API劫持的hami、nexusgpu
- 基于内核态API劫持的阿里云cGPU、腾讯云的qGPU，但需要注意内核态劫持可能会存在一些版权问题。
3. 介绍用户态API劫持和内核态API劫持的区别，包括隔离性、性能损耗、稳定性等方面。
4. 着重介绍hami开源项目的实现原理，以及实现方式、关键组件。


# Prometheus查询函数

背景：
我需要编写一篇文章，介绍Prometheus完整的查询函数以及对应的用法，文章的文件路径: /Users/john/Workspace/github/gqcn/johns-blog/docs/docs/5000-可观测性/1-监控技术/1500-Prometheus: 查询函数.md

要求：我需要你按照以下要求完成文章的编写：
1. 文档中包含2个分类，一个是介绍Prometheus的查询函数，另一个是介绍在Grafana中查询Prometheus数据时的一些自有函数（若有），grafana官网文档你自行搜索互联网资料。
2. 参考Prometheus的官方文档，文档地址：https://prometheus.io/docs/prometheus/latest/querying/functions/
3. 函数以表格形式展示，表格中需要包含函数名称、函数描述、函数参数、函数返回值等信息。


# Volcano网络拓扑调度

背景：
1. 需求背景：目前工作中接触到GPU多机多卡的分布式调度，针对于AI大模型的训练和推理场景，其中我们多机有IB设备，但IB设备的机器有组网，8台为一个IB网络，总共有2个IB网络；其他单节点内部的多张卡也有NVLINK的功能；在对多实例的任务调度时，由用户来指定是使用多机多卡IB网络还是多卡单机NVLINK通信，因此我们需要考虑通过Volcano的网络拓扑调度来实现我们的需求。
2. 我需要编写一篇文章，介绍Volcano网络拓扑调度，主要针对 network-topology-aware 插件，文章的文件路径: /Users/john/Workspace/github/gqcn/johns-blog/docs/docs/2000-云原生/400-Volcano/250-Volcano高级特性/1000-Volcano网络拓扑调度.md

要求：我需要你按照以下要求完成文章的编写：
1. 介绍Volcano网络拓扑调度的背景和价值。
2. 介绍Volcano网络拓扑调度的实现原理。
3. 介绍Volcano网络拓扑调度的配置方式，比如自动发现机制和手动配置HyperNode方式（基于标签）。
4. 基于network-topology-aware 插件，介绍Volcano网络拓扑调度的具体使用示例。
5. 介绍通过Volcano的网络拓扑调度特性，如何解决我的需求背景诉求。
6. 在编写文档之前，参考以下资料，以保证文档内容的准确性：
- 官网资料：https://volcano.sh/zh/docs/network_topology_aware_scheduling/
- Volcano源码：/Users/john/Workspace/github/volcano-sh/volcano
- Volcano源码中的使用文档：/Users/john/Workspace/github/volcano-sh/volcano/docs
- 搜索网络上相关资料

针对【5. 业务场景实战】章节中的内容，做以下调整：
1. 去掉使用NVLINK的业务场景示例，NVLINK的业务场景不符合网络拓扑调度的案例。因此去掉该章节下所有涉及NVLINK的描述信息。
2. 使用IB设备的多Pod任务采用PD分布式推理的业务场景示例，并在业务需求中简单描述PD分离的业务场景介绍。

# AI Agents介绍及应用


背景：
我需要编写一篇文章，介绍AI Agents介绍及应用，文章的文件路径: /Users/john/Workspace/github/gqcn/johns-blog/docs/docs/1000-AI技术/600-Agents/1000-AI Agents介绍及应用.md

该文档内容为空，你补充内容即可。

要求：我需要你按照以下要求完成文章的编写：
1. 简要介绍人工智能，以及发展历史。
2. 简要介绍大模型，核心特点、主要能力、能力边界。
3. 随后引出AI Agents的介绍，描述其背景和价值。
4. 对比大模型的能力，引出AI Agents的关键能力和应用场景介绍。
5. 当前主流AI Agents平台介绍，开源项目介绍。
6. 在文章中需要阐述出AI Agents的核心概念：智能体 = 大模型（核心引擎）× [感知 + 记忆 + 规划 + 工具 + 执行 + 反馈]（闭环模块）





# Kubeflow Trainer In HPC

背景：
我需要编写一篇文章，介绍Kubeflow Trainer在HPC中的应用，文章的文件路径: /Users/john/Workspace/github/gqcn/johns-blog/docs/docs/1000-AI技术/200-算力基础设施与调度技术/550-AI-HPC/4000-Kubeflow Trainer In HPC.md

要求：我需要你按照以下要求完成文章的编写：
1. 根据最新的Kubeflow Trainer的官方介绍及源码来完善该文档编写。
- 官网介绍文档本地路径：/Users/john/Workspace/github/kubeflow/website/content
- 源码文件本地路径：/Users/john/Workspace/github/kubeflow/trainer
2. 同时需要从互联网检索资料，看看网上的用户对该组件的使用和评价，随后完成后续的资料编写。
3. 先简要介绍Kubeflow项目，随后再详细介绍Kubeflow Trainer。
4. 介绍HPC训练场景下常见的技术挑战有哪些，而Kubeflow Trainer是怎么解决这些痛点的。
5. 介绍Kubeflow Trainer所支持的框架，如PyTorch、DeepSpeed等。
6. 介绍训练任务创建的完整流程，使用mermaid来展示。
7. 介绍Kubeflow Trainer能否集成到Volcano调度器中，并展示所需的配置、代码示例。
8. 介绍能否直接使用Volcano Job来实现HPC上的训练任务执行；对比而言，使用Kubeflow Trainer的CRD提供了哪些优势。


# Kubeflow Trainer PyTorch并行计算

背景：
1. 我需要编写一篇文章，以PyTorch框架为例，介绍Kubeflow Trainer在HPC中的并行计算实现原理，文章的文件路径: /Users/john/Workspace/github/gqcn/johns-blog/docs/docs/1000-AI技术/200-算力基础设施与调度技术/550-AI-HPC/5000-Kubeflow Trainer PyTorch并行计算.md
2. 本次环境现有的Kubeflow Trainer相关资料：
- 源码文件：/Users/john/Workspace/github/kubeflow/trainer
- 官网文档：/Users/john/Workspace/github/kubeflow/website

要求：你需要结合我现有提供的资料，并结合互联网上检索相关资料，随后按照以下要求完成文章的编写：
1. 大规模并行计算时HPC的基本且关键功能特性，简要介绍HPC中并行计算功能特性。
2. 以PyTorch框架为例，介绍Kubeflow Trainer如何支持该框架实现并行计算能力，包括CRD、关联的组件爱你介绍。
3. 需要结合示例详细介绍Kubeflow Trainer支持PyTorch框架并行计算能力的实现原理，包括使用mermaid展示整体上下游架构、执行流程图。
4. 如果是算法工程师使用PyTorch框架时，在代码中如何使用该Kubeflow Trainer提供的并行计算能力，是否需要对底层架构有感知？

# Kubeflow TrainJob&Runtime格式

背景：
1. 我需要编写一篇文章，介绍Kubeflow Trainer开源项目的TrainJob、TrainingRuntime及ClusterTrainingRuntime格式，以便于使用的时候参考格式。文章生成到该目录下: /Users/john/Workspace/github/gqcn/johns-blog/docs/docs/1000-AI技术/200-算力基础设施与调度技术/550-AI-HPC/
2. 本次环境现有的Kubeflow Trainer相关资料：
- 源码项目地址：/Users/john/Workspace/github/kubeflow/trainer
- 文档项目地址：/Users/john/Workspace/github/kubeflow/website

要求：你需要结合我现有提供的资料，并结合互联网上检索相关资料，随后按照以下要求完成文章的编写：
1. 分别介绍TrainJob、TrainingRuntime及ClusterTrainingRuntime这3个CRD的格式，每个CRD按照完整的YAML示例的形式展示，并且为每个配置项增加注释说明
2. 如果是比较复杂的配置项，例如枚举类型的配置项，或者单个示例YAML难以完整说明，那么在示例YAML下面增加一个表格介绍复杂的配置项。

对该文章完成以下改进，每个改进项创建独立的任务跟进：
1. 分析trainer项目源码以及文档介绍，修正并完善【环境变量注入】栏目介绍内容。例如，使用PyTorch的时候，应该有一些PET_*开头的环境变量，但是该栏目并没有介绍，所以我怀疑该栏目内容不完整或者有错误，需要审查、修正并完善该栏目内容。
2. 改进完成后，审查文档内容，修正格式错误的内容，保证文档格式正确，无重复内容。

# Kubeflow Trainer安装、部署及使用

背景：
1. 我需要编写一篇文章，介绍使用Kubeflow Trainer开源项目的真实安装、部署以及使用介绍，根据真实的基于CPU训练的案例来介绍该项目的使用。文章生成到该目录下: /Users/john/Workspace/github/gqcn/johns-blog/docs/docs/1000-AI技术/200-AI基础架构/550-HPC/100-Kubeflow Trainer/
2. 本次环境现有的Kubeflow Trainer相关资料：
- 源码项目地址：/Users/john/Workspace/github/kubeflow/trainer
- 文档项目地址：/Users/john/Workspace/github/kubeflow/website
- 示例代码及部署YAML文件、说明文件：/Users/john/Documents/马上消费/算力系统/AI-HPC/KubeflowTrainer/pytorch-demo

要求：
1. 首先介绍Kubeflow Trainer的安装部署，相关介绍文档：/Users/john/Documents/马上消费/算力系统/AI-HPC/KubeflowTrainer/README.md
2. 其次介绍通过PyTorch框架进行分布式训练的案例，需要介绍环境信息以及对应的Kubeflow Trainer版本信息，当前运行的系统信息MacOS M4、Kubernetes 1.27.3等。
3. 介绍分别通过3中方式来部署PyTorch分布式训练任务，分别是ConfigMap方式、HostPath方式、镜像构建方式。

# Volcano网络拓扑感知调度测试

背景：
1. 我需要编写一篇文章，介绍使用Volcano网络拓扑感知调度测试，该文章会真实部署kind k8s集群，并且真实构造HyperNode、运行任务来真实测试Volcano的该调度测试能力。文章生成到该目录下: /Users/john/Workspace/github/gqcn/johns-blog/docs/docs/2000-云原生/400-Volcano/250-Volcano高级特性/
2. 编写该文章需要提前了解的一些相关资料：Volcano源码项目地址：/Users/john/Workspace/github/volcano-sh/volcano
3. 节点拓扑信息如下：
```
  tier2                     s4                                 s5                         
                    /               \                   /              \                 
  tier1           s0                s1                 s2              s3              
               /      \          /      \           /      \        /      \         
            node0    node1    node2    node3      node4   node5   node6   node7   
```

要求：
1. 提供创建Kind集群的YAML内容。
2. 提供创建HyperNode的YAML内容。
3. 提供测试任务的YAML内容，该测试任务使用busybox镜像，运行一个简单的sleep命令即可，关键是能够按照网络拓扑感知调度实现预期的调度。



改进该文章内容：/Users/john/Workspace/github/gqcn/johns-blog/docs/docs/2000-云原生/400-Volcano/250-Volcano高级特性/260-Volcano网络拓扑感知调度实践.md 要求如下：
1. 标题修改为【Volcano网络拓扑感知调度测试】，同时需要对应修改该文章的文件名。
2. 文章顶部的frontmatter参考同级目录下的其他文章。
3. 测试环境拓扑结构内容中的node与s节点没有线路对齐。
4. 