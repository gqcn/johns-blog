---
slug: "/cloud-native/kubernettes-kind-mock-ai-test-cluster"
title: "ä½¿ç”¨Kubernetes Kindæ¨¡æ‹ŸAIç®—åŠ›æµ‹è¯•é›†ç¾¤"
hide_title: true
keywords:
  [
    "Kubernetes", "Kind", "Volcano", "AIç®—åŠ›", "èµ„æºè°ƒåº¦", "æµ‹è¯•é›†ç¾¤", "Docker", "k8s", "äº‘åŸç”Ÿ", "é«˜æ€§èƒ½è®¡ç®—"
  ]
description: "æœ¬æ–‡è¯¦ç»†ä»‹ç»äº†å¦‚ä½•ä½¿ç”¨Kindå·¥å…·å¿«é€Ÿæ­å»ºæ¨¡æ‹ŸAIç®—åŠ›åœºæ™¯çš„Kubernetesæœ¬åœ°æµ‹è¯•é›†ç¾¤ï¼Œå¹¶å®‰è£…Volcanoè°ƒåº¦å™¨è¿›è¡Œèµ„æºç®¡ç†ã€‚é€‚ç”¨äºéœ€è¦åœ¨æœ¬åœ°ç¯å¢ƒä¸­æµ‹è¯•AIè®­ç»ƒä»»åŠ¡è°ƒåº¦å’Œèµ„æºæŠ¢å æœºåˆ¶çš„å¼€å‘è€…ã€‚"
---

åœ¨å¼€å‘å’Œæµ‹è¯•`AI`åº”ç”¨æ—¶ï¼Œæˆ‘ä»¬å¸¸éœ€è¦ä¸€ä¸ªèƒ½æ¨¡æ‹Ÿç”Ÿäº§ç¯å¢ƒçš„æœ¬åœ°`Kubernetes`é›†ç¾¤ã€‚ç‰¹åˆ«æ˜¯å¯¹äº`AI`è®­ç»ƒä»»åŠ¡ï¼Œéœ€è¦æµ‹è¯•ä¸åŒç±»å‹çš„`GPU`èµ„æºè°ƒåº¦å’ŒæŠ¢å æœºåˆ¶ã€‚`Kind`ï¼ˆ`Kubernetes IN Docker`ï¼‰æ˜¯ä¸€ä¸ªä½¿ç”¨`Docker`å®¹å™¨ä½œä¸ºèŠ‚ç‚¹è¿è¡Œ`Kubernetes`é›†ç¾¤çš„å·¥å…·ï¼Œéå¸¸é€‚åˆåœ¨æœ¬åœ°å¿«é€Ÿæ­å»ºæµ‹è¯•ç¯å¢ƒã€‚ç»“åˆ`Volcano`è°ƒåº¦å™¨ï¼Œæˆ‘ä»¬å¯ä»¥å®ç°å¯¹`AI`è®­ç»ƒä»»åŠ¡çš„é«˜çº§è°ƒåº¦å’Œèµ„æºç®¡ç†ã€‚

> æœ¬æ–‡ä½¿ç”¨`Kind v0.27.0`ã€`Volcano v1.11.2`ã€`Kubernetes v1.32.2`ç‰ˆæœ¬ã€‚
> åŸºäº`MacOS 15.3.2`ï¼Œ`apple m4`èŠ¯ç‰‡ã€‚

## åˆ›å»ºæµ‹è¯•é›†ç¾¤

é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦åˆ›å»ºä¸€ä¸ªå…·æœ‰å¤šä¸ªèŠ‚ç‚¹çš„`Kubernetes`é›†ç¾¤ï¼Œå…¶ä¸­åŒ…å«ä¸€ä¸ªæ§åˆ¶å¹³é¢èŠ‚ç‚¹å’Œå¤šä¸ªæ¨¡æ‹Ÿ`GPU`çš„å·¥ä½œèŠ‚ç‚¹ã€‚

### åˆ›å»º Kind é…ç½®æ–‡ä»¶
```yaml title="kind-config.yaml"
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
name: ai-cluster
nodes:
  # æ§åˆ¶å¹³é¢èŠ‚ç‚¹
  - role: control-plane
  
  # GPUå·¥ä½œèŠ‚ç‚¹1 - æ¨¡æ‹ŸNVIDIA A100 GPUèŠ‚ç‚¹
  - role: worker
    labels:
      gpu-type: nvidia-a100
  
  # GPUå·¥ä½œèŠ‚ç‚¹2 - æ¨¡æ‹ŸNVIDIA V100 GPUèŠ‚ç‚¹
  - role: worker
    labels:
      gpu-type: nvidia-v100
  
  # GPUå·¥ä½œèŠ‚ç‚¹3 - æ¨¡æ‹ŸNVIDIA T4 GPUèŠ‚ç‚¹
  - role: worker
    labels:
      gpu-type: nvidia-t4
```

### æ‰§è¡Œé›†ç¾¤åˆ›å»º

æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼š

```bash
kind create cluster --config kind-config.yaml
```

æ‰§è¡Œåè¾“å‡ºï¼š

```text
% kind create cluster --config kind.yaml
Creating cluster "ai-cluster" ...
 âœ“ Ensuring node image (kindest/node:v1.32.2) ğŸ–¼ 
 âœ“ Preparing nodes ğŸ“¦ ğŸ“¦ ğŸ“¦ ğŸ“¦  
 âœ“ Writing configuration ğŸ“œ 
 âœ“ Starting control-plane ğŸ•¹ï¸ 
 âœ“ Installing CNI ğŸ”Œ 
 âœ“ Installing StorageClass ğŸ’¾ 
 âœ“ Joining worker nodes ğŸšœ 
Set kubectl context to "kind-ai-cluster"
You can now use your cluster with:

kubectl cluster-info --context kind-ai-cluster
```


## å®‰è£… Volcano

é›†ç¾¤åˆ›å»ºæˆåŠŸåï¼Œæˆ‘ä»¬éœ€è¦å®‰è£…`Volcano`è°ƒåº¦å™¨ã€‚`Volcano`æ˜¯ä¸€ä¸ªä¸ºé«˜æ€§èƒ½è®¡ç®—å’ŒAI/MLå·¥ä½œè´Ÿè½½ä¼˜åŒ–çš„`Kubernetes`åŸç”Ÿæ‰¹å¤„ç†ç³»ç»Ÿï¼Œæä¾›äº†ä¸°å¯Œçš„è°ƒåº¦ç­–ç•¥å’Œèµ„æºç®¡ç†åŠŸèƒ½ã€‚æˆ‘ä»¬å°†ä½¿ç”¨`Helm`æ¥å®‰è£…`Volcano`ï¼š

å‚è€ƒå®˜æ–¹æ–‡æ¡£ï¼šhttps://volcano.sh/en/docs/v1-11-0/installation/

```bash
# æ·»åŠ Volcano Helmä»“åº“
helm repo add volcano-sh https://volcano-sh.github.io/helm-charts

# æ›´æ–°ä»“åº“
helm repo update

# å®‰è£…Volcano
helm install volcano volcano-sh/volcano -n volcano-system --create-namespace

# æŸ¥çœ‹å®‰è£…ç»“æœ
kubectl get all -n volcano-system
```

æœ€ç»ˆè¾“å‡ºç»“æœï¼š

```text
% kubectl get all -n volcano-system
NAME                                       READY   STATUS    RESTARTS   AGE
pod/volcano-admission-784ff9c4f-vx6sp      1/1     Running   0          3m48s
pod/volcano-controllers-555c955d58-69j4k   1/1     Running   0          3m48s
pod/volcano-scheduler-9b977dd77-hdqjz      1/1     Running   0          3m48s

NAME                                  TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)    AGE
service/volcano-admission-service     ClusterIP   10.96.62.159   <none>        443/TCP    3m48s
service/volcano-controllers-service   ClusterIP   10.96.243.25   <none>        8081/TCP   3m48s
service/volcano-scheduler-service     ClusterIP   10.96.34.86    <none>        8080/TCP   3m48s

NAME                                  READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/volcano-admission     1/1     1            1           3m48s
deployment.apps/volcano-controllers   1/1     1            1           3m48s
deployment.apps/volcano-scheduler     1/1     1            1           3m48s

NAME                                             DESIRED   CURRENT   READY   AGE
replicaset.apps/volcano-admission-784ff9c4f      1         1         1       3m48s
replicaset.apps/volcano-controllers-555c955d58   1         1         1       3m48s
replicaset.apps/volcano-scheduler-9b977dd77      1         1         1       3m48s
```


### å¸¸è§é—®é¢˜è§£å†³

#### æœ¬åœ°VPNç¯å¢ƒå˜é‡ä»£ç†å¼•èµ·Kindæ‹‰å–é•œåƒå¤±è´¥

å¦‚æœæœ¬åœ°æœ‰å¯ç”¨`VPN`çš„ç¯å¢ƒå˜é‡ä»£ç†ï¼Œæ¯”å¦‚ä½¿ç”¨äº†ï¼š
```bash
export https_proxy=http://127.0.0.1:7890 http_proxy=http://127.0.0.1:7890 all_proxy=socks5://127.0.0.1:7890
```

é‚£ä¹ˆåœ¨åˆ›å»º`Pod`çš„æ—¶å€™ä¼šæŠ¥é”™ï¼š`proxyconnect tcp: dial tcp 127.0.0.1:7890: connect: connection refused`

```text
% kubectl get pod -A
NAMESPACE            NAME                                               READY   STATUS         RESTARTS   AGE
kube-system          coredns-668d6bf9bc-4s2tl                           1/1     Running        0          2m1s
kube-system          coredns-668d6bf9bc-gl4c6                           1/1     Running        0          2m1s
kube-system          etcd-ai-cluster-control-plane                      1/1     Running        0          2m8s
kube-system          kindnet-7m28t                                      1/1     Running        0          2m
kube-system          kindnet-d6fjg                                      1/1     Running        0          2m
kube-system          kindnet-f597l                                      1/1     Running        0          2m1s
kube-system          kindnet-lmrjr                                      1/1     Running        0          2m
kube-system          kube-apiserver-ai-cluster-control-plane            1/1     Running        0          2m8s
kube-system          kube-controller-manager-ai-cluster-control-plane   1/1     Running        0          2m7s
kube-system          kube-proxy-746fp                                   1/1     Running        0          2m
kube-system          kube-proxy-fxqj9                                   1/1     Running        0          2m
kube-system          kube-proxy-m5j7t                                   1/1     Running        0          2m
kube-system          kube-proxy-xl887                                   1/1     Running        0          2m1s
kube-system          kube-scheduler-ai-cluster-control-plane            1/1     Running        0          2m8s
local-path-storage   local-path-provisioner-7dc846544d-h9kxl            1/1     Running        0          2m1s
volcano-system       volcano-admission-init-lj7t6                       0/1     ErrImagePull   0          96s

% kubectl describe pod -n volcano-system volcano-admission-init-lj7t6

...

Events:
  Type     Reason     Age                   From               Message
  ----     ------     ----                  ----               -------
  Normal   Scheduled  2m52s                 default-scheduler  Successfully assigned volcano-system/volcano-admission-init-lj7t6 to ai-cluster-worker3
  Normal   BackOff    16s (x10 over 2m51s)  kubelet            Back-off pulling image "docker.io/volcanosh/vc-webhook-manager:v1.11.2"
  Warning  Failed     16s (x10 over 2m51s)  kubelet            Error: ImagePullBackOff
  Normal   Pulling    3s (x5 over 2m51s)    kubelet            Pulling image "docker.io/volcanosh/vc-webhook-manager:v1.11.2"
  Warning  Failed     3s (x5 over 2m51s)    kubelet            Failed to pull image "docker.io/volcanosh/vc-webhook-manager:v1.11.2": failed to pull and unpack image "docker.io/volcanosh/vc-webhook-manager:v1.11.2": failed to resolve reference "docker.io/volcanosh/vc-webhook-manager:v1.11.2": failed to do request: Head "https://registry-1.docker.io/v2/volcanosh/vc-webhook-manager/manifests/v1.11.2": proxyconnect tcp: dial tcp 127.0.0.1:7890: connect: connection refused
  Warning  Failed     3s (x5 over 2m51s)    kubelet            Error: ErrImagePull
```

è¿™æ˜¯å› ä¸ºåœ¨åˆ›å»º`Kind`é›†ç¾¤çš„æ—¶å€™ä¼šå°†å½“å‰çš„ç¯å¢ƒå˜é‡å…¨éƒ¨å¤åˆ¶åˆ°é›†ç¾¤ä¸­ï¼Œç‰¹åˆ«æ˜¯æ‹‰å–é•œåƒæ—¶ã€‚è§£å†³è¿™ä¸ªæ–¹æ³•æ˜¯æ–°å¼€ä¸å¸¦ä»£ç†ç¯å¢ƒå˜é‡çš„ç»ˆç«¯ï¼Œåˆ é™¤é›†ç¾¤åå†æ–°å»ºé›†ç¾¤ã€‚

## æ¨¡æ‹ŸNFD&GFDæ ‡ç­¾

`Volcano`å®‰è£…å®Œæˆåï¼Œæˆ‘ä»¬éœ€è¦æ¨¡æ‹ŸèŠ‚ç‚¹ç‰¹å¾å‘ç°ï¼ˆ`Node Feature Discovery`ï¼Œ`NFD`ï¼‰å’ŒGPUç‰¹å¾å‘ç°ï¼ˆ`GPU Feature Discovery`ï¼Œ`GFD`ï¼‰çš„æ ‡ç­¾ã€‚åœ¨çœŸå®é›†ç¾¤ä¸­ï¼Œè¿™äº›æ ‡ç­¾ä¼šç”±`NFD`å’Œ`GFD`è‡ªåŠ¨å‘ç°å¹¶æ·»åŠ åˆ°èŠ‚ç‚¹ä¸Šï¼Œä½†åœ¨æˆ‘ä»¬çš„æ¨¡æ‹Ÿç¯å¢ƒä¸­ï¼Œéœ€è¦æ‰‹åŠ¨æ·»åŠ è¿™äº›æ ‡ç­¾ã€‚è¿™äº›æ ‡ç­¾å°†ç”¨äºè®©è°ƒåº¦å™¨è¯†åˆ«ä¸åŒèŠ‚ç‚¹çš„ç¡¬ä»¶ç‰¹æ€§ï¼Œä¾¿äºè¿›è¡Œç²¾å‡†è°ƒåº¦ï¼š

å…³äº`NFD&GFD`çš„ä»‹ç»è¯·å‚è€ƒæˆ‘å¦ä¸€ç¯‡æ–‡ç« ï¼š[NFD&GFDæŠ€æœ¯ä»‹ç»](../4000-AIæŠ€æœ¯/2000-NFD&GFDæŠ€æœ¯ä»‹ç».md)

### æ¨¡æ‹Ÿæ ‡ç­¾è„šæœ¬

```shell title="kind-label.sh"
#!/bin/sh

# è®¾ç½®é¢œè‰²è¾“å‡º
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

echo "${GREEN}å¼€å§‹ä¸ºKindé›†ç¾¤èŠ‚ç‚¹æ·»åŠ NFDå’ŒGFDæ ‡ç­¾...${NC}"

# ç¡®ä¿è„šæœ¬æœ‰æ‰§è¡Œæƒé™
chmod +x "$0"

# æ£€æŸ¥kubectlæ˜¯å¦å¯ç”¨
if ! command -v kubectl &> /dev/null; then
    echo "é”™è¯¯: kubectlå‘½ä»¤æœªæ‰¾åˆ°ï¼Œè¯·ç¡®ä¿å·²å®‰è£…kubectlå¹¶é…ç½®æ­£ç¡®"
    exit 1
fi

# æ£€æŸ¥é›†ç¾¤è¿æ¥
if ! kubectl cluster-info &> /dev/null; then
    echo "é”™è¯¯: æ— æ³•è¿æ¥åˆ°Kubernetesé›†ç¾¤ï¼Œè¯·ç¡®ä¿é›†ç¾¤å·²å¯åŠ¨"
    exit 1
fi

# ç­‰å¾…æ‰€æœ‰èŠ‚ç‚¹å°±ç»ª
echo "ç­‰å¾…æ‰€æœ‰èŠ‚ç‚¹å°±ç»ª..."
kubectl wait --for=condition=Ready nodes --all --timeout=300s

# è·å–å·¥ä½œèŠ‚ç‚¹åˆ—è¡¨
WORKER_NODES=($(kubectl get nodes --no-headers | grep -v control-plane | awk '{print $1}'))

if [ ${#WORKER_NODES[@]} -ne 3 ]; then
    echo "è­¦å‘Š: é¢„æœŸæœ‰3ä¸ªå·¥ä½œèŠ‚ç‚¹ï¼Œä½†å®é™…æ‰¾åˆ° ${#WORKER_NODES[@]} ä¸ª"
fi

echo "${YELLOW}æ‰¾åˆ°ä»¥ä¸‹å·¥ä½œèŠ‚ç‚¹:${NC}"
for node in "${WORKER_NODES[@]}"; do
    echo " - $node"
done

# ä¸ºæ¯ä¸ªèŠ‚ç‚¹æ·»åŠ æ ‡ç­¾
# å¦‚æœæ²¡æœ‰è¶³å¤Ÿçš„å·¥ä½œèŠ‚ç‚¹ï¼Œåˆ™é€€å‡º
if [ ${#WORKER_NODES[@]} -lt 3 ]; then
    echo "${YELLOW}é”™è¯¯: éœ€è¦è‡³å°‘3ä¸ªå·¥ä½œèŠ‚ç‚¹ï¼Œä½†åªæ‰¾åˆ° ${#WORKER_NODES[@]} ä¸ª${NC}"
    exit 1
fi

# èŠ‚ç‚¹1: æ¨¡æ‹ŸA100 GPUèŠ‚ç‚¹
echo "${GREEN}ä¸ºèŠ‚ç‚¹ ${WORKER_NODES[0]} æ·»åŠ NFDå’ŒGFDæ ‡ç­¾ (A100 GPU)...${NC}"

# NFDæ ‡ç­¾ - CPUç›¸å…³
kubectl label node ${WORKER_NODES[0]} \
    feature.node.kubernetes.io/cpu-model.vendor_id=GenuineIntel \
    feature.node.kubernetes.io/cpu-model.family=6 \
    feature.node.kubernetes.io/cpu-model.id=85 \
    feature.node.kubernetes.io/cpu-cpuid.AVX=true \
    feature.node.kubernetes.io/cpu-cpuid.AVX2=true \
    feature.node.kubernetes.io/cpu-cpuid.AVX512F=true \
    feature.node.kubernetes.io/cpu-cpuid.AMXBF16=true \
    feature.node.kubernetes.io/cpu-cpuid.AMXINT8=true \
    feature.node.kubernetes.io/cpu-hardware_multithreading=true \
    feature.node.kubernetes.io/cpu-pstate.status=active \
    feature.node.kubernetes.io/cpu-pstate.turbo=true \
    feature.node.kubernetes.io/cpu-pstate.scaling_governor=performance \
    feature.node.kubernetes.io/cpu-cstate.enabled=true \
    --overwrite

# NFDæ ‡ç­¾ - å†…æ ¸ç›¸å…³
kubectl label node ${WORKER_NODES[0]} \
    feature.node.kubernetes.io/kernel-version.full=5.15.0-76-generic \
    feature.node.kubernetes.io/kernel-version.major=5 \
    feature.node.kubernetes.io/kernel-version.minor=15 \
    feature.node.kubernetes.io/kernel-version.revision=0 \
    --overwrite

# NFDæ ‡ç­¾ - å†…å­˜ç›¸å…³
kubectl label node ${WORKER_NODES[0]} \
    feature.node.kubernetes.io/memory-numa=true \
    feature.node.kubernetes.io/memory-nv.present=true \
    --overwrite

# NFDæ ‡ç­¾ - PCIè®¾å¤‡ç›¸å…³ (NVIDIA GPU)
kubectl label node ${WORKER_NODES[0]} \
    feature.node.kubernetes.io/pci-10de.present=true \
    feature.node.kubernetes.io/pci-10de.device-10de.model-name=NVIDIA_A100-SXM4-80GB \
    --overwrite

# GFDæ ‡ç­¾ - NVIDIA GPUç›¸å…³
kubectl label node ${WORKER_NODES[0]} \
    nvidia.com/gpu.present=true \
    nvidia.com/gpu.count=8 \
    nvidia.com/gpu.product=A100-SXM4-80GB \
    nvidia.com/gpu.family=ampere \
    nvidia.com/gpu.compute.major=8 \
    nvidia.com/gpu.compute.minor=0 \
    nvidia.com/gpu.machine=NVIDIA_A100-SXM4-80GB \
    nvidia.com/gpu.memory=81920 \
    nvidia.com/gpu.clock=1410 \
    nvidia.com/gpu.driver.major=535 \
    nvidia.com/gpu.driver.minor=104 \
    nvidia.com/gpu.driver.rev=05 \
    nvidia.com/gpu.cuda.major=12 \
    nvidia.com/gpu.cuda.minor=2 \
    nvidia.com/gpu.cuda.patch=0 \
    nvidia.com/mig.capable=true \
    nvidia.com/mps.capable=true \
    nvidia.com/gpu.multiprocessors=108 \
    nvidia.com/gpu.slices.ci=1 \
    nvidia.com/gpu.slices.gi=1 \
    nvidia.com/gpu.slices.mem=1 \
    nvidia.com/gpu.max-instances=7 \
    nvidia.com/gpu.virtualization=false \
    --overwrite

# èŠ‚ç‚¹2: æ¨¡æ‹ŸV100 GPUèŠ‚ç‚¹
echo "${GREEN}ä¸ºèŠ‚ç‚¹ ${WORKER_NODES[1]} æ·»åŠ NFDå’ŒGFDæ ‡ç­¾ (V100 GPU)...${NC}"

# NFDæ ‡ç­¾ - CPUç›¸å…³
kubectl label node ${WORKER_NODES[1]} \
    feature.node.kubernetes.io/cpu-model.vendor_id=GenuineIntel \
    feature.node.kubernetes.io/cpu-model.family=6 \
    feature.node.kubernetes.io/cpu-model.id=85 \
    feature.node.kubernetes.io/cpu-cpuid.AVX=true \
    feature.node.kubernetes.io/cpu-cpuid.AVX2=true \
    feature.node.kubernetes.io/cpu-cpuid.AVX512F=true \
    feature.node.kubernetes.io/cpu-hardware_multithreading=true \
    feature.node.kubernetes.io/cpu-pstate.status=active \
    feature.node.kubernetes.io/cpu-pstate.turbo=true \
    feature.node.kubernetes.io/cpu-pstate.scaling_governor=performance \
    feature.node.kubernetes.io/cpu-cstate.enabled=true \
    --overwrite

# NFDæ ‡ç­¾ - å†…æ ¸ç›¸å…³
kubectl label node ${WORKER_NODES[1]} \
    feature.node.kubernetes.io/kernel-version.full=5.15.0-76-generic \
    feature.node.kubernetes.io/kernel-version.major=5 \
    feature.node.kubernetes.io/kernel-version.minor=15 \
    feature.node.kubernetes.io/kernel-version.revision=0 \
    --overwrite

# NFDæ ‡ç­¾ - å†…å­˜ç›¸å…³
kubectl label node ${WORKER_NODES[1]} \
    feature.node.kubernetes.io/memory-numa=true \
    --overwrite

# NFDæ ‡ç­¾ - PCIè®¾å¤‡ç›¸å…³ (NVIDIA GPU)
kubectl label node ${WORKER_NODES[1]} \
    feature.node.kubernetes.io/pci-10de.present=true \
    feature.node.kubernetes.io/pci-10de.device-10de.model-name=NVIDIA_V100-SXM2-32GB \
    --overwrite

# GFDæ ‡ç­¾ - NVIDIA GPUç›¸å…³
kubectl label node ${WORKER_NODES[1]} \
    nvidia.com/gpu.present=true \
    nvidia.com/gpu.count=4 \
    nvidia.com/gpu.product=V100-SXM2-32GB \
    nvidia.com/gpu.family=volta \
    nvidia.com/gpu.compute.major=7 \
    nvidia.com/gpu.compute.minor=0 \
    nvidia.com/gpu.machine=NVIDIA_V100-SXM2-32GB \
    nvidia.com/gpu.memory=32768 \
    nvidia.com/gpu.clock=1530 \
    nvidia.com/gpu.driver.major=535 \
    nvidia.com/gpu.driver.minor=104 \
    nvidia.com/gpu.driver.rev=05 \
    nvidia.com/gpu.cuda.major=12 \
    nvidia.com/gpu.cuda.minor=0 \
    nvidia.com/gpu.cuda.patch=0 \
    nvidia.com/mig.capable=false \
    nvidia.com/mps.capable=true \
    nvidia.com/gpu.multiprocessors=80 \
    nvidia.com/gpu.virtualization=false \
    --overwrite

# èŠ‚ç‚¹3: æ¨¡æ‹ŸT4 GPUèŠ‚ç‚¹
echo "${GREEN}ä¸ºèŠ‚ç‚¹ ${WORKER_NODES[2]} æ·»åŠ NFDå’ŒGFDæ ‡ç­¾ (T4 GPU)...${NC}"

# NFDæ ‡ç­¾ - CPUç›¸å…³
kubectl label node ${WORKER_NODES[2]} \
    feature.node.kubernetes.io/cpu-model.vendor_id=GenuineIntel \
    feature.node.kubernetes.io/cpu-model.family=6 \
    feature.node.kubernetes.io/cpu-model.id=85 \
    feature.node.kubernetes.io/cpu-cpuid.AVX=true \
    feature.node.kubernetes.io/cpu-cpuid.AVX2=true \
    feature.node.kubernetes.io/cpu-hardware_multithreading=true \
    feature.node.kubernetes.io/cpu-pstate.status=active \
    feature.node.kubernetes.io/cpu-pstate.turbo=true \
    feature.node.kubernetes.io/cpu-pstate.scaling_governor=performance \
    feature.node.kubernetes.io/cpu-cstate.enabled=true \
    --overwrite

# NFDæ ‡ç­¾ - å†…æ ¸ç›¸å…³
kubectl label node ${WORKER_NODES[2]} \
    feature.node.kubernetes.io/kernel-version.full=5.15.0-76-generic \
    feature.node.kubernetes.io/kernel-version.major=5 \
    feature.node.kubernetes.io/kernel-version.minor=15 \
    feature.node.kubernetes.io/kernel-version.revision=0 \
    --overwrite

# NFDæ ‡ç­¾ - å†…å­˜ç›¸å…³
kubectl label node ${WORKER_NODES[2]} \
    feature.node.kubernetes.io/memory-numa=false \
    --overwrite

# NFDæ ‡ç­¾ - PCIè®¾å¤‡ç›¸å…³ (NVIDIA GPU)
kubectl label node ${WORKER_NODES[2]} \
    feature.node.kubernetes.io/pci-10de.present=true \
    feature.node.kubernetes.io/pci-10de.device-10de.model-name=NVIDIA_T4 \
    --overwrite

# GFDæ ‡ç­¾ - NVIDIA GPUç›¸å…³
kubectl label node ${WORKER_NODES[2]} \
    nvidia.com/gpu.present=true \
    nvidia.com/gpu.count=2 \
    nvidia.com/gpu.product=T4 \
    nvidia.com/gpu.family=turing \
    nvidia.com/gpu.compute.major=7 \
    nvidia.com/gpu.compute.minor=5 \
    nvidia.com/gpu.machine=NVIDIA_T4 \
    nvidia.com/gpu.memory=16384 \
    nvidia.com/gpu.clock=1590 \
    nvidia.com/gpu.driver.major=535 \
    nvidia.com/gpu.driver.minor=104 \
    nvidia.com/gpu.driver.rev=05 \
    nvidia.com/gpu.cuda.major=11 \
    nvidia.com/gpu.cuda.minor=8 \
    nvidia.com/gpu.cuda.patch=0 \
    nvidia.com/mig.capable=false \
    nvidia.com/mps.capable=true \
    nvidia.com/gpu.multiprocessors=40 \
    nvidia.com/gpu.virtualization=false \
    --overwrite

echo "${GREEN}æ‰€æœ‰èŠ‚ç‚¹æ ‡ç­¾æ·»åŠ å®Œæˆ!${NC}"
echo "${YELLOW}éªŒè¯èŠ‚ç‚¹æ ‡ç­¾:${NC}"

# éªŒè¯æ ‡ç­¾
for node in "${WORKER_NODES[@]}"; do
    echo "${GREEN}èŠ‚ç‚¹ $node çš„NFDæ ‡ç­¾:${NC}"
    kubectl get node $node -o json | jq -r '.metadata.labels | with_entries(select(.key | startswith("feature.node.kubernetes.io"))) | to_entries | .[] | "\(.key)=\(.value)"'
    
    echo "${GREEN}èŠ‚ç‚¹ $node çš„GFDæ ‡ç­¾:${NC}"
    kubectl get node $node -o json | jq -r '.metadata.labels | with_entries(select(.key | startswith("nvidia.com"))) | to_entries | .[] | "\(.key)=\(.value)"'
    
    echo ""
done

echo "${GREEN}è„šæœ¬æ‰§è¡Œå®Œæˆ!${NC}"
```


### æ‰§è¡Œæ ‡ç­¾è„šæœ¬

```bash
./kind-label.sh
```

### éªŒè¯æ‰§è¡Œç»“æœ

```bash
kubectl describe node ai-cluster-worker
```

![alt text](<assets/4000-ä½¿ç”¨Kubernetes Kindæ­å»ºAIç®—åŠ›æµ‹è¯•é›†ç¾¤/image.png>)

## æ¨¡æ‹ŸGPUèµ„æºç±»å‹

æ·»åŠ èŠ‚ç‚¹æ ‡ç­¾åï¼Œæˆ‘ä»¬è¿˜éœ€è¦æ¨¡æ‹ŸèŠ‚ç‚¹ä¸Šçš„GPUèµ„æºã€‚åœ¨çœŸå®é›†ç¾¤ä¸­ï¼ŒGPUèµ„æºä¼šç”±NVIDIAè®¾å¤‡æ’ä»¶è‡ªåŠ¨æ³¨å†Œï¼Œä½†åœ¨æˆ‘ä»¬çš„æ¨¡æ‹Ÿç¯å¢ƒä¸­ï¼Œéœ€è¦æ‰‹åŠ¨æ·»åŠ è¿™äº›èµ„æºã€‚æˆ‘ä»¬å°†ä¸ºä¸åŒèŠ‚ç‚¹æ·»åŠ ä¸åŒæ•°é‡å’Œç±»å‹çš„GPUèµ„æºï¼š

ä¸ºèŠ‚ç‚¹æ¨¡æ‹ŸGPUèµ„æºç±»å‹ï¼Œè¿™é‡Œæ¨¡æ‹Ÿçš„æ˜¯`NVIDIA`çš„å¡ï¼Œå› æ­¤éœ€è¦åŠ ä¸Š`nvidia.com/gpu`çš„èµ„æºã€‚

### æ¨¡æ‹ŸGPUèµ„æºè„šæœ¬
```shell title="add-gpu-resources.sh"
#!/bin/sh

# è®¾ç½®é¢œè‰²è¾“å‡º
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

echo "${GREEN}å¼€å§‹ä¸ºKindé›†ç¾¤èŠ‚ç‚¹æ·»åŠ æ¨¡æ‹ŸGPUèµ„æº...${NC}"

# è·å–å·¥ä½œèŠ‚ç‚¹åˆ—è¡¨
WORKER_NODES=($(kubectl get nodes --no-headers | grep -v control-plane | awk '{print $1}'))

if [ ${#WORKER_NODES[@]} -lt 3 ]; then
    echo "${YELLOW}è­¦å‘Š: é¢„æœŸæœ‰3ä¸ªå·¥ä½œèŠ‚ç‚¹ï¼Œä½†å®é™…æ‰¾åˆ° ${#WORKER_NODES[@]} ä¸ª${NC}"
fi

echo "${YELLOW}æ‰¾åˆ°ä»¥ä¸‹å·¥ä½œèŠ‚ç‚¹:${NC}"
for node in "${WORKER_NODES[@]}"; do
    echo " - $node"
done

# ä½¿ç”¨kubectl patchå‘½ä»¤ç›´æ¥ä¿®æ”¹èŠ‚ç‚¹èµ„æº

# ä¸ºç¬¬ä¸€ä¸ªèŠ‚ç‚¹æ·»åŠ 8ä¸ªA100 GPU
echo "${GREEN}ä¸ºèŠ‚ç‚¹ ${WORKER_NODES[0]} æ·»åŠ 8ä¸ªæ¨¡æ‹ŸA100 GPU...${NC}"

# ä½¿ç”¨kubectl patchå‘½ä»¤ä¿®æ”¹èŠ‚ç‚¹èµ„æº
kubectl get node ${WORKER_NODES[0]} -o json | jq '.status.capacity["nvidia.com/gpu"]="8" | .status.allocatable["nvidia.com/gpu"]="8"' | kubectl replace --raw /api/v1/nodes/${WORKER_NODES[0]}/status -f -

# ä¸ºç¬¬äºŒä¸ªèŠ‚ç‚¹æ·»åŠ 4ä¸ªV100 GPU
echo "${GREEN}ä¸ºèŠ‚ç‚¹ ${WORKER_NODES[1]} æ·»åŠ 4ä¸ªæ¨¡æ‹ŸV100 GPU...${NC}"
kubectl get node ${WORKER_NODES[1]} -o json | jq '.status.capacity["nvidia.com/gpu"]="4" | .status.allocatable["nvidia.com/gpu"]="4"' | kubectl replace --raw /api/v1/nodes/${WORKER_NODES[1]}/status -f -

# ä¸ºç¬¬ä¸‰ä¸ªèŠ‚ç‚¹æ·»åŠ 2ä¸ªT4 GPU
echo "${GREEN}ä¸ºèŠ‚ç‚¹ ${WORKER_NODES[2]} æ·»åŠ 2ä¸ªæ¨¡æ‹ŸT4 GPU...${NC}"
kubectl get node ${WORKER_NODES[2]} -o json | jq '.status.capacity["nvidia.com/gpu"]="2" | .status.allocatable["nvidia.com/gpu"]="2"' | kubectl replace --raw /api/v1/nodes/${WORKER_NODES[2]}/status -f -

# éªŒè¯GPUèµ„æºæ˜¯å¦æ·»åŠ æˆåŠŸ
echo "${GREEN}éªŒè¯èŠ‚ç‚¹GPUèµ„æº:${NC}"
kubectl get nodes -o=custom-columns=NAME:.metadata.name,GPU:.status.capacity.\'nvidia\.com/gpu\'

echo "${GREEN}æ¨¡æ‹ŸGPUèµ„æºæ·»åŠ å®Œæˆ!${NC}"
```


### æ‰§è¡ŒGPUèµ„æºè„šæœ¬

```bash
./add-gpu-resources.sh
```

### éªŒè¯GPUèµ„æºç»“æœ

```bash
kubectl describe node ai-cluster-worker
```

![alt text](<assets/4000-ä½¿ç”¨Kubernetes Kindæ­å»ºAIç®—åŠ›æµ‹è¯•é›†ç¾¤/image-1.png>)


## åˆ›å»ºæµ‹è¯•é˜Ÿåˆ—

ç°åœ¨æˆ‘ä»¬çš„é›†ç¾¤å·²ç»æœ‰äº†æ¨¡æ‹Ÿçš„`GPU`èµ„æºå’ŒèŠ‚ç‚¹æ ‡ç­¾ï¼Œæ¥ä¸‹æ¥éœ€è¦åˆ›å»ºæµ‹è¯•é˜Ÿåˆ—ã€‚åœ¨`Volcano`ä¸­ï¼Œ`é˜Ÿåˆ—`ï¼ˆ`Queue`ï¼‰æ˜¯èµ„æºç®¡ç†çš„é‡è¦æ¦‚å¿µï¼Œç”¨äºå®ç°å¤šç§Ÿæˆ·èµ„æºéš”ç¦»å’Œä¼˜å…ˆçº§ç®¡ç†ã€‚æˆ‘ä»¬å°†åˆ›å»ºä¸åŒä¼˜å…ˆçº§å’Œèµ„æºé…é¢çš„é˜Ÿåˆ—ï¼š

### æµ‹è¯•é˜Ÿåˆ—YAML

```yaml title="test-queue.yaml"
apiVersion: scheduling.volcano.sh/v1beta1
kind: Queue
metadata:
  name: default
spec:
  weight: 1
  reclaimable: false
---
apiVersion: scheduling.volcano.sh/v1beta1
kind: Queue
metadata:
  name: high-priority
spec:
  weight: 10
  capability:
    cpu: 100
    memory: 100Gi
    nvidia.com/gpu: 8
  reclaimable: true
---
apiVersion: scheduling.volcano.sh/v1beta1
kind: Queue
metadata:
  name: ai-training
spec:
  weight: 5
  capability:
    cpu: 50
    memory: 50Gi
    nvidia.com/gpu: 4
  reclaimable: true
```

### åˆ›å»ºæµ‹è¯•é˜Ÿåˆ—

```bash
% kubectl apply -f test-queue.yaml
```

### æŸ¥çœ‹åˆ›å»ºé˜Ÿåˆ—

```bash
% kubectl get queue
NAME            AGE
ai-training     11s
default         4m9s
high-priority   11s
root            4m9s
```

## åˆ›å»ºæµ‹è¯•ä»»åŠ¡

é˜Ÿåˆ—åˆ›å»ºå®Œæˆåï¼Œæˆ‘ä»¬å¯ä»¥åˆ›å»ºæµ‹è¯•ä»»åŠ¡æ¥éªŒè¯æˆ‘ä»¬çš„è®¾ç½®ã€‚æˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªè¯·æ±‚`GPU`èµ„æºçš„`Volcano Job`ï¼Œå¹¶æŒ‡å®šå…¶è¿è¡Œåœ¨æˆ‘ä»¬åˆ›å»ºçš„é«˜ä¼˜å…ˆçº§é˜Ÿåˆ—ä¸­ã€‚è¿™ä¸ªä»»åŠ¡å°†ä½¿ç”¨èŠ‚ç‚¹é€‰æ‹©å™¨æ¥é€‰æ‹©æœ‰`NVIDIA GPU`çš„èŠ‚ç‚¹ï¼š

### æµ‹è¯•ä»»åŠ¡YAML

```yaml title="test-job.yaml"
apiVersion: batch.volcano.sh/v1alpha1
kind: Job
metadata:
  name: gpu-test-job
spec:
  minAvailable: 1
  schedulerName: volcano
  queue: high-priority
  policies:
    - event: PodEvicted
      action: RestartJob
  maxRetry: 1
  tasks:
    - replicas: 1
      name: gpu-test
      template:
        spec:
          containers:
            - name: gpu-test-container
              image: alpine:latest
              command:
                - sh
                - -c
                - "nvidia-smi || echo 'No GPU found, but scheduled to GPU node' && sleep 300"
              resources:
                limits:
                  cpu: 1
                  memory: 1Gi
                  nvidia.com/gpu: 1
                requests:
                  cpu: 500m
                  memory: 512Mi
                  nvidia.com/gpu: 1
          restartPolicy: Never
          nodeSelector:
            feature.node.kubernetes.io/pci-10de.present: "true"  # é€‰æ‹©æœ‰NVIDIA GPUçš„èŠ‚ç‚¹
```

### åˆ›å»ºæµ‹è¯•ä»»åŠ¡

```bash
% kubectl apply -f test-job.yaml
```

### æŸ¥çœ‹æµ‹è¯•ä»»åŠ¡

```bash
% k get vcjob -A
NAMESPACE   NAME           STATUS    MINAVAILABLE   RUNNINGS   AGE
default     gpu-test-job   Running   1              1          47s
```
