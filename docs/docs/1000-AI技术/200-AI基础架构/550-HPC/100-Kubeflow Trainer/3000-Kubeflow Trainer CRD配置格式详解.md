---
slug: "/ai/kubeflow-trainer-crd-reference"
title: "Kubeflow Trainer CRDé…ç½®æ ¼å¼è¯¦è§£"
hide_title: true
keywords:
  [
    "Kubeflow Trainer",
    "TrainJob",
    "TrainingRuntime",
    "ClusterTrainingRuntime",
    "CRD",
    "Custom Resource Definition",
    "åˆ†å¸ƒå¼è®­ç»ƒ",
    "PyTorch",
    "DeepSpeed",
    "MPI",
    "YAMLé…ç½®",
    "Kubernetes",
    "è®­ç»ƒä»»åŠ¡",
    "è¿è¡Œæ—¶æ¨¡æ¿",
    "Gang Scheduling",
    "æ•°æ®é›†åˆå§‹åŒ–",
    "æ¨¡å‹åˆå§‹åŒ–",
    "Podæ¨¡æ¿è¦†ç›–",
    "å¼¹æ€§è®­ç»ƒ",
    "HPC"
  ]
description: "è¯¦ç»†ä»‹ç»Kubeflow Trainerçš„ä¸‰ä¸ªæ ¸å¿ƒCRDï¼ˆTrainJobã€TrainingRuntimeã€ClusterTrainingRuntimeï¼‰çš„å®Œæ•´é…ç½®æ ¼å¼ï¼ŒåŒ…æ‹¬æ¯ä¸ªé…ç½®é¡¹çš„æ³¨é‡Šè¯´æ˜ã€å¤æ‚é…ç½®é¡¹çš„è¡¨æ ¼è§£é‡Šã€ç‰¹æ®Šæ ‡ç­¾å’Œæ³¨è§£çš„ä½¿ç”¨ï¼Œä»¥åŠæœ€ä½³å®è·µæŒ‡å—"
---

## 1. æ¦‚è¿°

`Kubeflow Trainer`æä¾›äº†ä¸‰ä¸ªæ ¸å¿ƒçš„`CRDï¼ˆCustom Resource Definitionï¼‰`æ¥æ”¯æŒåˆ†å¸ƒå¼è®­ç»ƒä»»åŠ¡çš„å®šä¹‰å’Œæ‰§è¡Œï¼š

| CRDåç§° | ä½œç”¨åŸŸ | ä¸»è¦ä½œç”¨ |
|----------|-----------|--------|
| `TrainJob` | å‘½åç©ºé—´ | å®šä¹‰å…·ä½“çš„è®­ç»ƒä»»åŠ¡ï¼ŒåŒ…æ‹¬è®­ç»ƒçš„é…ç½®å‚æ•°ã€èµ„æºéœ€æ±‚ã€æ•°æ®é›†å’Œæ¨¡å‹åˆå§‹åŒ–ç­‰ |
| `TrainingRuntime` | å‘½åç©ºé—´ | å‘½åç©ºé—´çº§åˆ«çš„è®­ç»ƒè¿è¡Œæ—¶æ¨¡æ¿ï¼Œå®šä¹‰äº†ç‰¹å®šæ¡†æ¶ï¼ˆå¦‚ `PyTorch`ã€`DeepSpeed`ï¼‰çš„æ‰§è¡Œç¯å¢ƒï¼Œåªèƒ½è¢«åŒä¸€å‘½åç©ºé—´çš„`TrainJob`å¼•ç”¨ |
| `ClusterTrainingRuntime` | é›†ç¾¤ | é›†ç¾¤çº§åˆ«çš„è®­ç»ƒè¿è¡Œæ—¶æ¨¡æ¿ï¼Œå¯ä»¥è¢«ä»»ä½•å‘½åç©ºé—´çš„ `TrainJob`å¼•ç”¨ï¼Œé€‚ç”¨äºè·¨å›¢é˜Ÿå…±äº«çš„æ ‡å‡†è¿è¡Œæ—¶é…ç½® |

æœ¬æ–‡å°†è¯¦ç»†ä»‹ç»è¿™ä¸‰ä¸ª`CRD`çš„å®Œæ•´é…ç½®æ ¼å¼ï¼Œå¹¶å¯¹æ¯ä¸ªé…ç½®é¡¹è¿›è¡Œè¯´æ˜ã€‚

## 2. TrainJob

`TrainJob`æ˜¯ç”¨æˆ·åˆ›å»ºåˆ†å¸ƒå¼è®­ç»ƒä»»åŠ¡çš„æ ¸å¿ƒ`CRD`ï¼Œå®ƒå®šä¹‰äº†è®­ç»ƒä»»åŠ¡çš„æ‰€æœ‰é…ç½®å‚æ•°ã€‚

### 2.1 å®Œæ•´æ¨¡æ¿ç¤ºä¾‹

```yaml
apiVersion: trainer.kubeflow.org/v1alpha1
kind: TrainJob
metadata:
  # TrainJob çš„åç§°ï¼Œå¿…é¡»ç¬¦åˆ RFC 1035 DNS æ ‡ç­¾æ ¼å¼ï¼ˆå°å†™å­—æ¯ã€æ•°å­—ã€è¿å­—ç¬¦ï¼Œæœ€å¤š63ä¸ªå­—ç¬¦ï¼‰
  name: pytorch-distributed-training
  # TrainJob æ‰€åœ¨çš„å‘½åç©ºé—´
  namespace: kubeflow
  # å¯é€‰çš„æ ‡ç­¾
  labels:
    app: training
    framework: pytorch
  # å¯é€‰çš„æ³¨è§£
  annotations:
    description: "PyTorch distributed training example"
spec:
  # å¼•ç”¨çš„è®­ç»ƒè¿è¡Œæ—¶é…ç½®ï¼ˆå¿…å¡«ï¼‰
  runtimeRef:
    # è¿è¡Œæ—¶çš„åç§°ï¼ˆå¿…å¡«ï¼Œæœ€å°é•¿åº¦ä¸º1ï¼‰
    name: torch-distributed
    # è¿è¡Œæ—¶çš„ API ç»„ï¼Œé»˜è®¤ä¸º trainer.kubeflow.org
    apiGroup: trainer.kubeflow.org
    # è¿è¡Œæ—¶çš„ç±»å‹ï¼Œå¯é€‰å€¼ï¼šTrainingRuntime æˆ– ClusterTrainingRuntime
    # é»˜è®¤ä¸º ClusterTrainingRuntime
    kind: ClusterTrainingRuntime

  # åˆå§‹åŒ–å™¨é…ç½®ï¼Œç”¨äºæ•°æ®é›†å’Œæ¨¡å‹çš„åˆå§‹åŒ–ï¼ˆå¯é€‰ï¼‰
  initializer:
    # æ•°æ®é›†åˆå§‹åŒ–é…ç½®
    dataset:
      # æ•°æ®é›†å­˜å‚¨çš„ URIï¼Œæ”¯æŒå„ç§å­˜å‚¨åè®®ï¼ˆå¦‚ s3://ã€gs://ã€pvc:// ç­‰ï¼‰
      storageUri: s3://my-bucket/datasets/fashion-mnist
      # ç¯å¢ƒå˜é‡åˆ—è¡¨ï¼Œç”¨äºæ•°æ®é›†åˆå§‹åŒ–å®¹å™¨
      env:
        - name: AWS_REGION
          value: us-west-2
        - name: DATASET_FORMAT
          value: pytorch
      # Secret å¼•ç”¨ï¼ŒåŒ…å«è®¿é—®æ•°æ®é›†çš„å‡­è¯
      # Secret å¿…é¡»åœ¨ TrainJob æ‰€åœ¨çš„å‘½åç©ºé—´ä¸­åˆ›å»º
      secretRef:
        name: s3-credentials

    # é¢„è®­ç»ƒæ¨¡å‹åˆå§‹åŒ–é…ç½®
    model:
      # é¢„è®­ç»ƒæ¨¡å‹å­˜å‚¨çš„ URI
      storageUri: s3://my-bucket/models/pretrained-resnet
      # ç¯å¢ƒå˜é‡åˆ—è¡¨ï¼Œç”¨äºæ¨¡å‹åˆå§‹åŒ–å®¹å™¨
      env:
        - name: MODEL_FORMAT
          value: pytorch
        - name: MODEL_VERSION
          value: v1.0
      # Secret å¼•ç”¨ï¼ŒåŒ…å«è®¿é—®æ¨¡å‹çš„å‡­è¯
      secretRef:
        name: s3-credentials

  # è®­ç»ƒå™¨é…ç½®ï¼ˆå¯é€‰ï¼‰
  trainer:
    # è®­ç»ƒå®¹å™¨çš„é•œåƒ
    image: pytorch/pytorch:2.7.1-cuda12.8-cudnn9-runtime
    # å®¹å™¨çš„å¯åŠ¨å‘½ä»¤
    command:
      - python
      - /workspace/train.py
    # å®¹å™¨çš„å‚æ•°
    args:
      - --epochs=10
      - --batch-size=64
      - --learning-rate=0.001
    # ç¯å¢ƒå˜é‡åˆ—è¡¨
    env:
      - name: NCCL_DEBUG
        value: INFO
      - name: PYTORCH_CUDA_ALLOC_CONF
        value: max_split_size_mb:512
    # è®­ç»ƒèŠ‚ç‚¹æ•°é‡
    numNodes: 4
    # æ¯ä¸ªèŠ‚ç‚¹çš„èµ„æºé…ç½®
    resourcesPerNode:
      requests:
        cpu: "4"
        memory: 16Gi
        nvidia.com/gpu: "1"
      limits:
        cpu: "8"
        memory: 32Gi
        nvidia.com/gpu: "1"
    # æ¯ä¸ªèŠ‚ç‚¹çš„è¿›ç¨‹/worker æ•°é‡
    # å¯¹äº PyTorchï¼šå¯ä»¥è®¾ç½®ä¸º autoã€cpuã€gpu æˆ–æ•´æ•°å€¼
    # å¯¹äº MPIï¼šåªèƒ½è®¾ç½®ä¸ºæ•´æ•°å€¼
    numProcPerNode: auto

  # åº”ç”¨åˆ°è¡ç”Ÿ JobSet å’Œ Jobs çš„æ ‡ç­¾ï¼ˆå¯é€‰ï¼‰
  # è¿™äº›æ ‡ç­¾ä¼šä¸ TrainingRuntime ä¸­çš„æ ‡ç­¾åˆå¹¶
  # æ³¨æ„ï¼šå½“å­˜åœ¨ç›¸åŒé”®æ—¶ï¼ŒTrainJob ä¸­çš„æ ‡ç­¾å€¼ä¼šè¦†ç›– TrainingRuntime ä¸­çš„æ ‡ç­¾å€¼
  labels:
    team: ml-team
    project: image-classification

  # åº”ç”¨åˆ°è¡ç”Ÿ JobSet å’Œ Jobs çš„æ³¨è§£ï¼ˆå¯é€‰ï¼‰
  # è¿™äº›æ³¨è§£ä¼šä¸ TrainingRuntime ä¸­çš„æ³¨è§£åˆå¹¶
  # æ³¨æ„ï¼šå½“å­˜åœ¨ç›¸åŒé”®æ—¶ï¼ŒTrainJob ä¸­çš„æ³¨è§£å€¼ä¼šè¦†ç›– TrainingRuntime ä¸­çš„æ³¨è§£å€¼
  annotations:
    owner: john@example.com
    cost-center: "1234"

  # Pod æ¨¡æ¿è¦†ç›–é…ç½®ï¼Œç”¨äºè‡ªå®šä¹‰ç‰¹å®š Job çš„ Pod é…ç½®ï¼ˆå¯é€‰ï¼‰
  podTemplateOverrides:
    # å¯ä»¥é…ç½®å¤šä¸ªè¦†ç›–è§„åˆ™ï¼Œåé¢çš„è§„åˆ™ä¼šè¦†ç›–å‰é¢çš„å­—æ®µå€¼
    - targetJobs:
        # ç›®æ ‡ Job åç§°åˆ—è¡¨
        - name: node
      # Pod å…ƒæ•°æ®è¦†ç›–
      metadata:
        labels:
          custom-label: custom-value
        annotations:
          custom-annotation: custom-value
      # Pod Spec è¦†ç›–
      spec:
        # æœåŠ¡è´¦å·åç§°
        serviceAccountName: training-sa
        # èŠ‚ç‚¹é€‰æ‹©å™¨
        nodeSelector:
          node-type: gpu-node
          gpu-type: nvidia-a100
        # äº²å’Œæ€§é…ç½®
        affinity:
          nodeAffinity:
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
                - matchExpressions:
                    - key: gpu-type
                      operator: In
                      values:
                        - nvidia-a100
                        - nvidia-v100
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                      - key: app
                        operator: In
                        values:
                          - training
                  topologyKey: kubernetes.io/hostname
        # å®¹å¿åº¦é…ç½®
        tolerations:
          - key: nvidia.com/gpu
            operator: Exists
            effect: NoSchedule
          - key: training-workload
            operator: Equal
            value: "true"
            effect: NoSchedule
        # å·é…ç½®
        volumes:
          - name: workspace
            persistentVolumeClaim:
              claimName: training-workspace-pvc
          - name: shared-memory
            emptyDir:
              medium: Memory
              sizeLimit: 8Gi
        # åˆå§‹åŒ–å®¹å™¨è¦†ç›–
        initContainers:
          - name: setup
            env:
              - name: SETUP_MODE
                value: distributed
            volumeMounts:
              - name: workspace
                mountPath: /workspace
        # å®¹å™¨è¦†ç›–
        containers:
          - name: node
            env:
              - name: CUSTOM_ENV
                value: custom-value
            volumeMounts:
              - name: workspace
                mountPath: /workspace
              - name: shared-memory
                mountPath: /dev/shm
        # è°ƒåº¦é—¨æ§ï¼ˆç”¨äº Pod è°ƒåº¦å°±ç»ªæ€§æ§åˆ¶ï¼‰
        schedulingGates:
          - name: custom-gate
        # é•œåƒæ‹‰å– Secret
        imagePullSecrets:
          - name: docker-registry-secret

  # æ˜¯å¦æš‚åœè¿è¡Œä¸­çš„ TrainJobï¼ˆå¯é€‰ï¼‰
  # é»˜è®¤ä¸º false
  suspend: false

  # ç®¡ç†è€…æ ‡è¯†ï¼ŒæŒ‡ç¤ºç”±å“ªä¸ªæ§åˆ¶å™¨æˆ–å®ä½“ç®¡ç†æ­¤ TrainJobï¼ˆå¯é€‰ï¼‰
  # å¯é€‰å€¼ï¼š
  # - trainer.kubeflow.org/trainjob-controllerï¼ˆé»˜è®¤ï¼Œç”±å†…ç½®æ§åˆ¶å™¨ç®¡ç†ï¼‰
  # - kueue.x-k8s.io/multikueueï¼ˆå§”æ‰˜ç»™ Kueue ç®¡ç†ï¼‰
  # æ­¤å­—æ®µä¸å¯å˜
  managedBy: trainer.kubeflow.org/trainjob-controller
```

### 2.2 é‡è¦å­—æ®µè¯´æ˜

#### 2.2.1 runtimeRef

`runtimeRef` æ˜¯å¿…å¡«å­—æ®µï¼Œç”¨äºå¼•ç”¨è®­ç»ƒè¿è¡Œæ—¶é…ç½®ï¼š

| å­—æ®µ | ç±»å‹ | å¿…å¡« | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|------|--------|------|
| `name` | `string` | æ˜¯ | - | è¿è¡Œæ—¶åç§°ï¼Œæœ€å°é•¿åº¦ä¸º`1` |
| `apiGroup` | `string` | å¦ | `trainer.kubeflow.org` | è¿è¡Œæ—¶çš„`API`ç»„ |
| `kind` | `string` | å¦ | `ClusterTrainingRuntime` | è¿è¡Œæ—¶ç±»å‹ï¼Œå¯é€‰ `TrainingRuntime` æˆ– `ClusterTrainingRuntime` |

#### 2.2.2 numProcPerNode

æ¯ä¸ªèŠ‚ç‚¹çš„è¿›ç¨‹/`worker`æ•°é‡é…ç½®ï¼š

| æ¡†æ¶ | æ”¯æŒçš„å€¼ | è¯´æ˜ |
|------|----------|------|
| `PyTorch` | `auto`ã€`cpu`ã€`gpu`ã€æ•´æ•° | `auto`è¡¨ç¤ºè‡ªåŠ¨æ£€æµ‹ï¼Œ`cpu`/`gpu`è¡¨ç¤ºä½¿ç”¨æ‰€æœ‰ `CPU`/`GPU`ï¼Œæ•´æ•°è¡¨ç¤ºå…·ä½“è¿›ç¨‹æ•° |
| `MPI` | æ•´æ•° | åªèƒ½è®¾ç½®å…·ä½“çš„æ•´æ•°å€¼ |
| `DeepSpeed` | æ•´æ•° | åªèƒ½è®¾ç½®å…·ä½“çš„æ•´æ•°å€¼ |

#### 2.2.3 managedBy

æ§åˆ¶`TrainJob`çš„ç®¡ç†è€…ï¼š

| å€¼ | è¯´æ˜ |
|----|------|
| `trainer.kubeflow.org/trainjob-controller` | ç”±å†…ç½®çš„ `TrainJob` æ§åˆ¶å™¨ç®¡ç†ï¼ˆé»˜è®¤ï¼‰ |
| `kueue.x-k8s.io/multikueue` | å§”æ‰˜ç»™ Kueue è¿›è¡Œç®¡ç†ï¼Œæ”¯æŒå¤šé›†ç¾¤è°ƒåº¦ |


#### 2.2.4 initializerï¼ˆåˆå§‹åŒ–å™¨ï¼‰

åˆå§‹åŒ–å™¨ç”¨äºåœ¨è®­ç»ƒå¼€å§‹å‰è‡ªåŠ¨å®Œæˆæ•°æ®é›†å’Œé¢„è®­ç»ƒæ¨¡å‹çš„å‡†å¤‡å·¥ä½œï¼Œæå¤§ç®€åŒ–äº†è®­ç»ƒä»»åŠ¡çš„é…ç½®å’Œç®¡ç†ã€‚

##### 2.2.4.1 datasetï¼ˆæ•°æ®é›†åˆå§‹åŒ–å™¨ï¼‰

æ•°æ®é›†åˆå§‹åŒ–å™¨çš„ä½œç”¨ï¼š

- **è‡ªåŠ¨ä¸‹è½½æ•°æ®é›†**ï¼šä»å„ç§å­˜å‚¨æºï¼ˆ`S3`ã€`GCS`ã€`Hugging Face`ã€`PVC` ç­‰ï¼‰è‡ªåŠ¨ä¸‹è½½è®­ç»ƒæ‰€éœ€çš„æ•°æ®é›†
- **æ•°æ®é¢„å¤„ç†**ï¼šå¯ä»¥åœ¨åˆå§‹åŒ–é˜¶æ®µå¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†å’Œæ ¼å¼è½¬æ¢
- **æ•°æ®æŒä¹…åŒ–**ï¼šå°†ä¸‹è½½çš„æ•°æ®é›†å­˜å‚¨åˆ°å…±äº«å·ä¸­ï¼Œä¾›æ‰€æœ‰è®­ç»ƒèŠ‚ç‚¹è®¿é—®
- **å‡­è¯ç®¡ç†**ï¼šé€šè¿‡`secretRef`å®‰å…¨åœ°ç®¡ç†è®¿é—®ç§æœ‰æ•°æ®é›†æ‰€éœ€çš„å‡­è¯

é…ç½®ç¤ºä¾‹ï¼š
```yaml
initializer:
  dataset:
    # æ•°æ®é›† URIï¼Œæ”¯æŒå¤šç§åè®®ï¼š
    # - s3://bucket/pathï¼ˆAWS S3ï¼‰
    # - gs://bucket/pathï¼ˆGoogle Cloud Storageï¼‰
    # - hf://dataset-nameï¼ˆHugging Faceï¼‰
    # - pvc://pvc-name/pathï¼ˆKubernetes PVCï¼‰
    storageUri: s3://my-bucket/datasets/imagenet
    env:
      - name: AWS_REGION
        value: us-west-2
    secretRef:
      name: s3-credentials  # åŒ…å« AWS_ACCESS_KEY_ID å’Œ AWS_SECRET_ACCESS_KEY
```

æ•°æ®é›†åˆå§‹åŒ–å®Œæˆåï¼Œæ•°æ®ä¼šè¢«æŒ‚è½½åˆ°è®­ç»ƒå®¹å™¨çš„`/workspace/dataset`è·¯å¾„ã€‚

##### modelï¼ˆæ¨¡å‹åˆå§‹åŒ–å™¨ï¼‰

æ¨¡å‹åˆå§‹åŒ–å™¨çš„ä½œç”¨ï¼š

- **è‡ªåŠ¨ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹**ï¼šä»æ¨¡å‹ä»“åº“ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹æƒé‡
- **æ¨¡å‹æ ¼å¼è½¬æ¢**ï¼šæ”¯æŒä¸åŒæ¡†æ¶é—´çš„æ¨¡å‹æ ¼å¼è½¬æ¢
- **æ¨¡å‹æŒä¹…åŒ–**ï¼šå°†æ¨¡å‹æ–‡ä»¶å­˜å‚¨åˆ°å…±äº«å·ä¸­
- **ç‰ˆæœ¬ç®¡ç†**ï¼šå¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡æŒ‡å®šå…·ä½“çš„æ¨¡å‹ç‰ˆæœ¬

é…ç½®ç¤ºä¾‹ï¼š
```yaml
initializer:
  model:
    # é¢„è®­ç»ƒæ¨¡å‹ URI
    storageUri: hf://meta-llama/Llama-2-7b-hf
    env:
      - name: MODEL_VERSION
        value: v1.0
      - name: HUGGING_FACE_TOKEN
        valueFrom:
          secretKeyRef:
            name: hf-token
            key: token
    secretRef:
      name: hf-credentials
```

æ¨¡å‹åˆå§‹åŒ–å®Œæˆåï¼Œæ¨¡å‹æ–‡ä»¶ä¼šè¢«æŒ‚è½½åˆ°è®­ç»ƒå®¹å™¨çš„`/workspace/model`è·¯å¾„ã€‚

##### åˆå§‹åŒ–å™¨çš„æ‰§è¡Œæµç¨‹

1. `dataset-initializer Job`é¦–å…ˆå¯åŠ¨ï¼Œä¸‹è½½å¹¶å‡†å¤‡æ•°æ®é›†
2. `model-initializer Job`éšåå¯åŠ¨ï¼Œä¸‹è½½å¹¶å‡†å¤‡é¢„è®­ç»ƒæ¨¡å‹
3. ä¸¤ä¸ªåˆå§‹åŒ–`Job`éƒ½æˆåŠŸå®Œæˆåï¼Œ`trainer Job`æ‰ä¼šå¯åŠ¨
4. è®­ç»ƒå®¹å™¨å¯ä»¥ç›´æ¥è®¿é—®`/workspace/dataset`å’Œ`/workspace/model`è·¯å¾„ä¸‹çš„æ•°æ®å’Œæ¨¡å‹

è¿™ç§æœºåˆ¶ç¡®ä¿äº†è®­ç»ƒä»»åŠ¡å¯åŠ¨æ—¶æ‰€æœ‰å¿…éœ€çš„èµ„æºéƒ½å·²å°±ç»ªï¼Œé¿å…äº†è®­ç»ƒè¿‡ç¨‹ä¸­çš„èµ„æºåŠ è½½å¤±è´¥ã€‚

#### 2.2.5 Status Conditions

| Type | Reason | è¯´æ˜ |
|------|--------|------|
| `Suspended` | `Suspended` | `TrainJob` è¢«æš‚åœ |
| `Suspended` | `Resumed` | `TrainJob` ä»æš‚åœçŠ¶æ€æ¢å¤ |
| `Failed` | `TrainingRuntimeNotSupported` | å¼•ç”¨çš„`TrainingRuntime`ä¸å—æ”¯æŒ |
| `Complete` | `JobsCompleted` | `TrainJob` æˆåŠŸå®Œæˆ |

## 3. TrainingRuntime

`TrainingRuntime`æ˜¯å‘½åç©ºé—´çº§åˆ«çš„è®­ç»ƒè¿è¡Œæ—¶æ¨¡æ¿ï¼Œå®šä¹‰äº†ç‰¹å®š`ML`æ¡†æ¶çš„æ‰§è¡Œç¯å¢ƒã€‚å®ƒåªèƒ½è¢«åŒä¸€å‘½åç©ºé—´ä¸­çš„`TrainJob`å¼•ç”¨ã€‚

### 3.1 å®Œæ•´æ¨¡æ¿ç¤ºä¾‹

```yaml
apiVersion: trainer.kubeflow.org/v1alpha1
kind: TrainingRuntime
metadata:
  # TrainingRuntime çš„åç§°
  name: pytorch-distributed
  # TrainingRuntime æ‰€åœ¨çš„å‘½åç©ºé—´
  namespace: kubeflow
  # æ ‡ç­¾ï¼Œé€šå¸¸æ ‡è¯†æ¡†æ¶ç±»å‹
  labels:
    trainer.kubeflow.org/framework: pytorch
    environment: production
spec:
  # ML ç­–ç•¥é…ç½®ï¼Œæä¾›MLç‰¹å®šçš„å‚æ•°ï¼ˆå¯é€‰ï¼‰
  mlPolicy:
    # è®­ç»ƒèŠ‚ç‚¹æ•°é‡ï¼Œé»˜è®¤ä¸º1
    numNodes: 2
    
    # PyTorchè¿è¡Œæ—¶é…ç½®
    torch:
      # æ¯ä¸ªèŠ‚ç‚¹çš„è¿›ç¨‹æ•°é‡
      # æ”¯æŒçš„å€¼ï¼šautoï¼ˆè‡ªåŠ¨æ£€æµ‹ï¼‰ã€cpuï¼ˆCPUæ•°é‡ï¼‰ã€gpuï¼ˆGPUæ•°é‡ï¼‰æˆ–æ•´æ•°å€¼
      # é»˜è®¤ä¸º auto
      numProcPerNode: auto
      
      # PyTorch å¼¹æ€§è®­ç»ƒç­–ç•¥ï¼ˆå¯é€‰ï¼‰
      # æ³¨æ„ï¼šå¦‚æœé…ç½®äº† elasticPolicyï¼Œåˆ™ä¸èƒ½åŒæ—¶è®¾ç½® mlPolicy.numNodes
      elasticPolicy:
        # è®­ç»ƒä»»åŠ¡å¯ä»¥é‡å¯çš„æœ€å¤§æ¬¡æ•°
        # æ­¤å€¼ä¼šæ’å…¥åˆ° torchrun çš„ --max-restarts å‚æ•°ä¸­
        maxRestarts: 3
        # å¯ä»¥ç¼©å‡åˆ°çš„æœ€å°èŠ‚ç‚¹æ•°
        minNodes: 1
        # å¯ä»¥æ‰©å±•åˆ°çš„æœ€å¤§èŠ‚ç‚¹æ•°
        maxNodes: 4
        # ç”¨äºè®¡ç®—æœŸæœ›èŠ‚ç‚¹æ•°çš„æŒ‡æ ‡
        # å°†åˆ›å»º HPA æ¥æ‰§è¡Œè‡ªåŠ¨ç¼©æ”¾
        metrics:
          - type: Resource
            resource:
              name: cpu
              target:
                type: Utilization
                averageUtilization: 80

  # PodGroup ç­–ç•¥é…ç½®ï¼Œç”¨äºå¯ç”¨ gang-schedulingï¼ˆå¯é€‰ï¼‰
  podGroupPolicy:
    # ä½¿ç”¨ Kubernetes scheduler-plugins çš„ coscheduling æ’ä»¶
    coscheduling:
      # gang-scheduling çš„æœ€å¤§è°ƒåº¦è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
      # å¦‚æœä¸º 0ï¼Œåˆ™ä½¿ç”¨é»˜è®¤å€¼
      # é»˜è®¤ä¸º 60 ç§’
      scheduleTimeoutSeconds: 120
    
    # æˆ–è€…ä½¿ç”¨ Volcano gang-scheduler
    # æ³¨æ„ï¼šcoscheduling å’Œ volcano åªèƒ½é…ç½®å…¶ä¸­ä¸€ä¸ª
    # volcano:
    #   # ç½‘ç»œæ‹“æ‰‘é…ç½®ï¼Œä¸ç½‘ç»œæ‹“æ‰‘ç‰¹æ€§å’Œ hyperNode CRD é…åˆä½¿ç”¨
    #   networkTopology:
    #     # é…ç½®å…·ä½“çš„ç½‘ç»œæ‹“æ‰‘ç­–ç•¥
    #     # è¯¦è§ Volcano æ–‡æ¡£

  # JobSet æ¨¡æ¿é…ç½®
  template:
    # JobSet çš„å…ƒæ•°æ®
    metadata:
      labels:
        runtime: pytorch
        version: v2.7
      annotations:
        description: PyTorch distributed training runtime
    
    # JobSet çš„è§„èŒƒ
    spec:
      # å¤åˆ¶çš„ Job åˆ—è¡¨
      replicatedJobs:
        # ä¸»è¦çš„è®­ç»ƒèŠ‚ç‚¹ Job
        - name: node
          # è¯¥ Job çš„å‰¯æœ¬æ•°é‡ï¼ˆèŠ‚ç‚¹æ•°é‡ï¼‰
          # æ³¨æ„ï¼šå®é™…çš„å‰¯æœ¬æ•°ä¼šè¢« mlPolicy.numNodes æˆ– TrainJob.trainer.numNodes è¦†ç›–
          replicas: 1
          
          # Job æ¨¡æ¿
          template:
            metadata:
              labels:
                # æ­¤æ ‡ç­¾æ ‡è¯†è¿™æ˜¯è®­ç»ƒå™¨æ­¥éª¤
                trainer.kubeflow.org/trainjob-ancestor-step: trainer
            spec:
              # Job å®Œæˆæ¨¡å¼
              # Indexed è¡¨ç¤ºæ¯ä¸ª Pod éƒ½æœ‰å”¯ä¸€çš„ç´¢å¼•
              completionMode: Indexed
              
              # Job çš„ Pod æ¨¡æ¿
              template:
                spec:
                  # å®¹å™¨åˆ—è¡¨
                  containers:
                    - name: node
                      # é»˜è®¤é•œåƒï¼Œä¼šè¢« TrainJob.trainer.image è¦†ç›–
                      image: pytorch/pytorch:2.7.1-cuda12.8-cudnn9-runtime
                      # é»˜è®¤å‘½ä»¤ï¼Œä¼šè¢« TrainJob.trainer.command è¦†ç›–
                      command:
                        - torchrun
                      # é»˜è®¤å‚æ•°
                      args:
                        - --nnodes=$(TRAINER_NNODES)
                        - --nproc_per_node=$(TRAINER_NPROC_PER_NODE)
                        - --node_rank=$(JOB_COMPLETION_INDEX)
                        - --rdzv_backend=c10d
                        - --rdzv_endpoint=$(TRAINER_NODE_0_HOSTNAME):29400
                        - --rdzv_id=$(TRAINER_JOB_ID)
                        - /workspace/train.py
                      # ç¯å¢ƒå˜é‡
                      env:
                        - name: LOGLEVEL
                          value: INFO
                        - name: NCCL_DEBUG
                          value: INFO
                      # èµ„æºé…ç½®
                      resources:
                        requests:
                          cpu: "2"
                          memory: 8Gi
                        limits:
                          cpu: "4"
                          memory: 16Gi
                      # å·æŒ‚è½½
                      volumeMounts:
                        - name: workspace
                          mountPath: /workspace
                  
                  # å·å®šä¹‰
                  volumes:
                    - name: workspace
                      emptyDir: {}
                  
                  # é‡å¯ç­–ç•¥
                  restartPolicy: OnFailure
      
      # å¤±è´¥ç­–ç•¥
      failurePolicy:
        # å…è®¸çš„æœ€å¤§é‡å¯æ¬¡æ•°
        maxRestarts: 3
      
      # æˆåŠŸç­–ç•¥
      successPolicy:
        # æ“ä½œç¬¦ï¼Œè¡¨ç¤ºå¦‚ä½•åˆ¤æ–­æˆåŠŸ
        # All è¡¨ç¤ºæ‰€æœ‰ç›®æ ‡ Job éƒ½å¿…é¡»æˆåŠŸ
        operator: All
        # ç›®æ ‡ Job åˆ—è¡¨
        targetReplicatedJobs:
          - node
      
      # ç½‘ç»œé…ç½®
      network:
        # æ˜¯å¦å‘å¸ƒæœªå°±ç»ªçš„åœ°å€
        # å¯¹äºåˆ†å¸ƒå¼è®­ç»ƒï¼Œé€šå¸¸è®¾ç½®ä¸º true
        publishNotReadyAddresses: true
        # æ˜¯å¦å¯ç”¨ DNS ä¸»æœºå
        enableDNSHostnames: true
```


### 3.2 é‡è¦å­—æ®µè¯´æ˜

#### 3.2.1 mlPolicy

`ML`ç­–ç•¥é…ç½®çš„äº’æ–¥è§„åˆ™ï¼š

| é…ç½® | äº’æ–¥è§„åˆ™ | è¯´æ˜ |
|------|----------|------|
| `numNodes` | ä¸èƒ½ä¸ `torch.elasticPolicy` åŒæ—¶ä½¿ç”¨ | å¼¹æ€§è®­ç»ƒä½¿ç”¨ `minNodes`/`maxNodes` ä»£æ›¿å›ºå®šèŠ‚ç‚¹æ•° |
| `torch` | ä¸èƒ½ä¸ `mpi` åŒæ—¶ä½¿ç”¨ | åªèƒ½é…ç½®ä¸€ç§è¿è¡Œæ—¶ç­–ç•¥ |
| `mpi` | ä¸èƒ½ä¸ `torch` åŒæ—¶ä½¿ç”¨ | åªèƒ½é…ç½®ä¸€ç§è¿è¡Œæ—¶ç­–ç•¥ |

#### 3.2.2 PyTorch å¼¹æ€§è®­ç»ƒ

å¯ç”¨`PyTorch`å¼¹æ€§è®­ç»ƒæ—¶çš„å…³é”®é…ç½®ï¼š

| å­—æ®µ | è¯´æ˜ |
|------|------|
| `maxRestarts` | æ’å…¥åˆ° `torchrun` çš„ `--max-restarts` å‚æ•°å’Œ`Job`çš„ `.spec.failurePolicy.maxRestarts` |
| `minNodes` | æ’å…¥åˆ° `torchrun` çš„ `--nnodes` å‚æ•°çš„æœ€å°å€¼ |
| `maxNodes` | æ’å…¥åˆ° `torchrun` çš„ `--nnodes` å‚æ•°çš„æœ€å¤§å€¼ |
| `metrics` | ç”¨äºåˆ›å»º`HPAï¼ˆHorizontal Pod Autoscalerï¼‰`è¿›è¡Œè‡ªåŠ¨ç¼©æ”¾ |

#### 3.2.3 MPI å®ç°ç±»å‹

æ”¯æŒçš„`MPI`å®ç°ï¼š

| ç±»å‹ | è¯´æ˜ |
|------|------|
| `OpenMPI` | `Open MPI` å®ç°ï¼ˆé»˜è®¤ï¼‰ |
| `Intel` | `Intel MPI` å®ç° |
| `MPICH` | `MPICH` å®ç° |


### 3.3 ç‰¹æ®Šæ ‡ç­¾å’Œæ³¨è§£

`Kubeflow Trainer`ä½¿ç”¨ä¸€äº›ç‰¹æ®Šçš„æ ‡ç­¾å’Œæ³¨è§£æ¥æ§åˆ¶è®­ç»ƒä»»åŠ¡çš„è¡Œä¸ºå’Œæ ‡è¯†èµ„æºå…³ç³»ã€‚

#### 3.3.1 ç³»ç»Ÿé¢„ç•™æ ‡ç­¾

| æ ‡ç­¾é”® | å¯èƒ½çš„å€¼ | ç”¨é€” | åº”ç”¨ä½ç½® |
|--------|---------|------|----------|
| `trainer.kubeflow.org/trainjob-ancestor-step` | `dataset-initializer`<br/>`model-initializer`<br/>`trainer` | æ ‡è¯†`Pod`æ¨¡æ¿åœ¨è®­ç»ƒæµç¨‹ä¸­çš„è§’è‰²ï¼Œç”¨äºå…³è”`TrainJob`çš„ä¸åŒé…ç½®é¡¹ä¸`Runtime`ä¸­çš„`Job`æ¨¡æ¿ | `TrainingRuntime/ClusterTrainingRuntime`çš„`replicatedJobs[].template.labels` |
| `trainer.kubeflow.org/framework` | `torch`<br/>`deepspeed`<br/>`mpi`<br/>`mlx`<br/>`torchtune` | æ ‡è¯† `Runtime` æ”¯æŒçš„è®­ç»ƒæ¡†æ¶ç±»å‹ | `TrainingRuntime/ClusterTrainingRuntime` çš„ `metadata.labels` |
| `trainer.kubeflow.org/support` | `deprecated` |æ ‡è¯†`Runtime`çš„æ”¯æŒçŠ¶æ€ï¼Œå½“å€¼ä¸º `deprecated` æ—¶ä¼šåœ¨åˆ›å»º `TrainJob`æ—¶å‘å‡ºè­¦å‘Š | `TrainingRuntime/ClusterTrainingRuntime` çš„ `metadata.labels` |

#### 3.3.2 æ ‡ç­¾ä½¿ç”¨è¯´æ˜

##### 3.3.2.1 trainer.kubeflow.org/trainjob-ancestor-step

è¿™æ˜¯æœ€é‡è¦çš„ç³»ç»Ÿæ ‡ç­¾ï¼Œç”¨äºå»ºç«‹`TrainJob`é…ç½®ä¸`Runtime`ä¸­`Job`æ¨¡æ¿ä¹‹é—´çš„æ˜ å°„å…³ç³»ï¼š

- **dataset-initializer**ï¼šå¸¦æœ‰æ­¤æ ‡ç­¾çš„`Job`æ¨¡æ¿ä¼šè¢«`TrainJob.spec.initializer.dataset`é…ç½®è¦†ç›–
- **model-initializer**ï¼šå¸¦æœ‰æ­¤æ ‡ç­¾çš„`Job`æ¨¡æ¿ä¼šè¢«`TrainJob.spec.initializer.model`é…ç½®è¦†ç›–  
- **trainer**ï¼šå¸¦æœ‰æ­¤æ ‡ç­¾çš„`Job`æ¨¡æ¿ä¼šè¢«`TrainJob.spec.trainer`é…ç½®è¦†ç›–

**æ˜¯å¦å¿…é¡»é…ç½®ï¼š**

è¯¥æ ‡ç­¾åœ¨`TrainingRuntime/ClusterTrainingRuntime`çš„`replicatedJobs`ä¸­**ä¸æ˜¯å¼ºåˆ¶è¦æ±‚**çš„ï¼Œä½†é€šå¸¸åº”è¯¥è¦é…ç½®ï¼Œä½†å…·æœ‰ä»¥ä¸‹é‡è¦ä½œç”¨ï¼š

1. **ä¸é…ç½®è¯¥æ ‡ç­¾**ï¼š
   - è¯¥`Job`æ¨¡æ¿å°†ä¸ä¼šè¢«`TrainJob`çš„ä»»ä½•é…ç½®é¡¹è¦†ç›–
   - é€‚ç”¨äºè¾…åŠ©æ€§çš„`Job`ï¼ˆå¦‚æ—¥å¿—æ”¶é›†ã€ç›‘æ§ç­‰ï¼‰ï¼Œè¿™äº›`Job`ä¸éœ€è¦`TrainJob`çº§åˆ«çš„å®šåˆ¶
   - `Job`å°†å®Œå…¨æŒ‰ç…§`Runtime`ä¸­å®šä¹‰çš„é…ç½®è¿è¡Œ

2. **é…ç½® `trainer` å€¼**ï¼š
   - **å¼ºçƒˆæ¨è**ä¸ºä¸»è®­ç»ƒèŠ‚ç‚¹é…ç½®æ­¤æ ‡ç­¾
   - å…è®¸ç”¨æˆ·é€šè¿‡`TrainJob.spec.trainer`å®šåˆ¶è®­ç»ƒé•œåƒã€å‘½ä»¤ã€å‚æ•°ã€èµ„æºç­‰
   - æä¾›äº†è®­ç»ƒä»»åŠ¡çº§åˆ«çš„çµæ´»æ€§ï¼Œæ˜¯`Kubeflow Trainer`çš„æ ¸å¿ƒåŠŸèƒ½ä¹‹ä¸€
   - ä¸é…ç½®æ­¤æ ‡ç­¾æ„å‘³ç€æ”¾å¼ƒäº†`TrainJob`çº§åˆ«çš„è®­ç»ƒé…ç½®èƒ½åŠ›

3. **é…ç½®åˆå§‹åŒ–å™¨æ ‡ç­¾**ï¼š
   - å¦‚æœéœ€è¦æ•°æ®é›†/æ¨¡å‹åˆå§‹åŒ–åŠŸèƒ½ï¼Œå¿…é¡»ä¸ºå¯¹åº”çš„`Job`é…ç½®ç›¸åº”çš„æ ‡ç­¾
   - ä¸é…ç½®åˆ™æ— æ³•ä½¿ç”¨`TrainJob.spec.initializer`åŠŸèƒ½

**æœ€ä½³å®è·µç¤ºä¾‹ï¼š**

```yaml
# æ¨èçš„é…ç½®æ–¹å¼
spec:
  template:
    spec:
      replicatedJobs:
        # å¯é€‰ï¼šæ•°æ®é›†åˆå§‹åŒ– Job
        - name: dataset-initializer
          template:
            metadata:
              labels:
                trainer.kubeflow.org/trainjob-ancestor-step: dataset-initializer
        
        # å¯é€‰ï¼šæ¨¡å‹åˆå§‹åŒ– Job
        - name: model-initializer
          template:
            metadata:
              labels:
                trainer.kubeflow.org/trainjob-ancestor-step: model-initializer
        
        # å¼ºçƒˆæ¨èï¼šä¸»è®­ç»ƒèŠ‚ç‚¹å¿…é¡»é…ç½®æ­¤æ ‡ç­¾
        - name: node
          template:
            metadata:
              labels:
                trainer.kubeflow.org/trainjob-ancestor-step: trainer  # æ¨èé…ç½®
        
        # å¯é€‰ï¼šè¾…åŠ© Job å¯ä»¥ä¸é…ç½®æ­¤æ ‡ç­¾
        - name: monitoring
          template:
            metadata:
              labels:
                app: monitoring  # ä¸é…ç½® trainjob-ancestor-step
```

ç¤ºä¾‹ï¼š
```yaml
# åœ¨ TrainingRuntime ä¸­å®šä¹‰
spec:
  template:
    spec:
      replicatedJobs:
        - name: dataset-initializer
          template:
            metadata:
              labels:
                # æ­¤æ ‡ç­¾æ ‡è¯†è¿™æ˜¯æ•°æ®é›†åˆå§‹åŒ–æ­¥éª¤
                trainer.kubeflow.org/trainjob-ancestor-step: dataset-initializer
        - name: node
          template:
            metadata:
              labels:
                # æ­¤æ ‡ç­¾æ ‡è¯†è¿™æ˜¯è®­ç»ƒå™¨æ­¥éª¤
                trainer.kubeflow.org/trainjob-ancestor-step: trainer
```

##### 3.3.2.2 trainer.kubeflow.org/framework

ç”¨äºæ ‡è¯†`Runtime`çš„æ¡†æ¶ç±»å‹ï¼Œä¾¿äºç”¨æˆ·ç­›é€‰å’Œç®¡ç†ã€‚

**æ ‡ç­¾ä½œç”¨ï¼š**

1. **èµ„æºåˆ†ç±»å’Œç®¡ç†**ï¼š
   - å¸®åŠ©å¹³å°ç®¡ç†å‘˜å¯¹ä¸åŒæ¡†æ¶çš„`Runtime`è¿›è¡Œåˆ†ç±»
   - ä¾¿äºé€šè¿‡æ ‡ç­¾é€‰æ‹©å™¨æŸ¥è¯¢ç‰¹å®šæ¡†æ¶çš„`Runtime`
   - æ”¯æŒåœ¨`UI`æˆ–`CLI`å·¥å…·ä¸­æŒ‰æ¡†æ¶ç±»å‹è¿‡æ»¤å’Œå±•ç¤º

2. **ç”¨æˆ·ä½“éªŒä¼˜åŒ–**ï¼š
   - ç”¨æˆ·å¯ä»¥é€šè¿‡ `kubectl get clustertrainingruntimes -l trainer.kubeflow.org/framework=torch` å¿«é€ŸæŸ¥æ‰¾`PyTorch`è®­ç»ƒä»»åŠ¡æ¨¡æ¿
   - åœ¨å¤šç§Ÿæˆ·ç¯å¢ƒä¸­ï¼Œå¯ä»¥åŸºäºæ¡†æ¶ç±»å‹å®ç°`RBAC`æƒé™æ§åˆ¶
   - ä¾¿äºç›‘æ§å’Œå®¡è®¡ç‰¹å®šæ¡†æ¶çš„ä½¿ç”¨æƒ…å†µ

3. **æ–‡æ¡£å’Œè‡ªåŠ¨åŒ–**ï¼š
   - ä½œä¸º`Runtime`çš„å…ƒæ•°æ®ï¼Œå¸®åŠ©ç”Ÿæˆæ–‡æ¡£å’Œä½¿ç”¨æŒ‡å—
   - æ”¯æŒè‡ªåŠ¨åŒ–å·¥å…·æ ¹æ®æ¡†æ¶ç±»å‹è¿›è¡Œé…ç½®æ¨è
   - ä¾¿äºé›†æˆåˆ°`CI/CD`æµç¨‹ä¸­è¿›è¡Œæ¡†æ¶ç›¸å…³çš„æ ¡éªŒ

**æ˜¯å¦å¿…é¡»é…ç½®ï¼š**

è¯¥æ ‡ç­¾**ä¸æ˜¯å¼ºåˆ¶è¦æ±‚**çš„ï¼Œä½†**å¼ºçƒˆæ¨è**é…ç½®ï¼š

- âœ… **æ¨èé…ç½®**ï¼šå¯ä»¥æä¾›æ›´å¥½çš„ç”¨æˆ·ä½“éªŒå’Œç®¡ç†ä¾¿åˆ©æ€§
- âš ï¸ **ä¸é…ç½®å½±å“**ï¼š`Runtime`åŠŸèƒ½å®Œå…¨æ­£å¸¸ï¼Œä½†ä¼šå¤±å»ä¸Šè¿°åˆ†ç±»å’Œç­›é€‰èƒ½åŠ›
- ğŸ“ **å‘½åçº¦å®š**ï¼šå»ºè®®ä½¿ç”¨å®˜æ–¹æ”¯æŒçš„æ¡†æ¶åç§°ï¼ˆ`torch`ã€`deepspeed`ã€`mpi`ã€`mlx`ã€`torchtune`ï¼‰

**æ”¯æŒçš„æ¡†æ¶ç±»å‹ï¼š**

| æ¡†æ¶å€¼ | å¯¹åº”æ¡†æ¶ | è¯´æ˜ |
|--------|---------|------|
| `torch` | `PyTorch` | æ ‡å‡† `PyTorch` åˆ†å¸ƒå¼è®­ç»ƒ |
| `deepspeed` | `DeepSpeed` | `Microsoft DeepSpeed` æ¡†æ¶ |
| `mpi` | `MPI` | åŸºäº `MPI` çš„åˆ†å¸ƒå¼è®­ç»ƒ |
| `mlx` | `MLX` | `Apple MLX` æ¡†æ¶ |
| `torchtune` | `TorchTune` | `PyTorch` å¾®è°ƒæ¡†æ¶ |


**ä½¿ç”¨ç¤ºä¾‹ï¼š**

```yaml
# ç¤ºä¾‹1ï¼šPyTorch Runtime
apiVersion: trainer.kubeflow.org/v1alpha1
kind: ClusterTrainingRuntime
metadata:
  name: torch-distributed
  labels:
    trainer.kubeflow.org/framework: torch  # æ ‡è¯†ä¸º PyTorch è¿è¡Œæ—¶

# ç¤ºä¾‹2ï¼šDeepSpeed Runtime
apiVersion: trainer.kubeflow.org/v1alpha1
kind: ClusterTrainingRuntime
metadata:
  name: deepspeed-distributed
  labels:
    trainer.kubeflow.org/framework: deepspeed  # æ ‡è¯†ä¸º DeepSpeed è¿è¡Œæ—¶

# ç¤ºä¾‹3ï¼šæŸ¥è¯¢ç‰¹å®šæ¡†æ¶çš„ Runtime
# kubectl get clustertrainingruntimes -l trainer.kubeflow.org/framework=torch
```

**æœ€ä½³å®è·µï¼š**

1. ä¸ºæ‰€æœ‰ç”Ÿäº§ç¯å¢ƒçš„`Runtime`é…ç½®æ­¤æ ‡ç­¾
2. ä¿æŒæ ‡ç­¾å€¼çš„ä¸€è‡´æ€§ï¼Œé¿å…ä½¿ç”¨è‡ªå®šä¹‰å€¼
3. ç»“åˆå…¶ä»–æ ‡ç­¾ï¼ˆå¦‚ç‰ˆæœ¬ã€ç¯å¢ƒï¼‰å®ç°æ›´ç»†ç²’åº¦çš„ç®¡ç†ï¼š

```yaml
apiVersion: trainer.kubeflow.org/v1alpha1
kind: ClusterTrainingRuntime
metadata:
  name: torch-distributed
  labels:
    trainer.kubeflow.org/framework: torch  # æ ‡è¯†è¿™æ˜¯ PyTorch è¿è¡Œæ—¶
```

##### 3.3.2.3 trainer.kubeflow.org/support

ç”¨äºæ ‡è¯†`Runtime`çš„åºŸå¼ƒçŠ¶æ€ï¼š

```yaml
apiVersion: trainer.kubeflow.org/v1alpha1
kind: ClusterTrainingRuntime
metadata:
  name: legacy-runtime
  labels:
    trainer.kubeflow.org/support: deprecated  # æ ‡è¯†æ­¤è¿è¡Œæ—¶å·²åºŸå¼ƒ
```

å½“å¼•ç”¨å¸¦æœ‰ `deprecated` æ ‡ç­¾çš„`Runtime`æ—¶ï¼Œ`TrainJob`åˆ›å»ºæ—¶ä¼šæ”¶åˆ°è­¦å‘Šï¼Œæç¤ºç”¨æˆ·è¯¥`Runtime`å°†åœ¨æœªæ¥ç‰ˆæœ¬ä¸­ç§»é™¤ã€‚è¯¦è§[è¿è¡Œæ—¶åºŸå¼ƒç­–ç•¥](https://www.kubeflow.org/docs/components/trainer/operator-guides/runtime/#runtime-deprecation-policy)ã€‚


#### 3.3.3 ç”¨æˆ·è‡ªå®šä¹‰æ ‡ç­¾å’Œæ³¨è§£

é™¤äº†ç³»ç»Ÿé¢„ç•™æ ‡ç­¾å¤–ï¼Œç”¨æˆ·å¯ä»¥åœ¨ä»¥ä¸‹ä½ç½®æ·»åŠ è‡ªå®šä¹‰æ ‡ç­¾å’Œæ³¨è§£ï¼š

1. **TrainJob.metadata.labels/annotations**ï¼šåº”ç”¨`TrainJob`èµ„æºæœ¬èº«
2. **TrainJob.spec.labels/annotations**ï¼šåº”ç”¨äºè¡ç”Ÿçš„`JobSet`å’Œ`Jobs`ï¼Œä¼šä¸`Runtime`ä¸­çš„æ ‡ç­¾/æ³¨è§£åˆå¹¶
3. **TrainJob.spec.podTemplateOverrides[].metadata.labels/annotations**ï¼šåº”ç”¨äºç‰¹å®š`Job`çš„`Pod`æ¨¡æ¿

æ ‡ç­¾å’Œæ³¨è§£çš„åˆå¹¶è§„åˆ™ï¼š
- `TrainJob`ä¸­å®šä¹‰çš„æ ‡ç­¾/æ³¨è§£ä¼šä¸`Runtime`ä¸­çš„æ ‡ç­¾/æ³¨è§£åˆå¹¶
- å½“å­˜åœ¨ç›¸åŒçš„é”®æ—¶ï¼Œ**`TrainJob`ä¸­çš„å€¼ä¼šè¦†ç›–`Runtime`ä¸­çš„å€¼**
- è¿™ç§è®¾è®¡å…è®¸ç”¨æˆ·åœ¨ä¸ä¿®æ”¹`Runtime`çš„æƒ…å†µä¸‹ä¸ºç‰¹å®šè®­ç»ƒä»»åŠ¡è‡ªå®šä¹‰æ ‡ç­¾å’Œæ³¨è§£



## 4. ClusterTrainingRuntime

`ClusterTrainingRuntime`æ˜¯é›†ç¾¤çº§åˆ«çš„è®­ç»ƒè¿è¡Œæ—¶æ¨¡æ¿ï¼Œå¯ä»¥è¢«ä»»ä½•å‘½åç©ºé—´ä¸­çš„`TrainJob`å¼•ç”¨ã€‚å…¶é…ç½®æ ¼å¼ä¸`TrainingRuntime`å®Œå…¨ç›¸åŒï¼Œå”¯ä¸€åŒºåˆ«æ˜¯èµ„æºä½œç”¨åŸŸã€‚

### 4.1 å®Œæ•´æ¨¡æ¿ç¤ºä¾‹

```yaml
apiVersion: trainer.kubeflow.org/v1alpha1
kind: ClusterTrainingRuntime
metadata:
  # ClusterTrainingRuntime çš„åç§°ï¼ˆé›†ç¾¤å”¯ä¸€ï¼‰
  name: torch-distributed
  # æ ‡ç­¾ï¼Œæ ‡è¯†æ¡†æ¶ç±»å‹
  labels:
    trainer.kubeflow.org/framework: torch
    version: v2.7
spec:
  # ML ç­–ç•¥é…ç½®ï¼ˆä¸ TrainingRuntime ç›¸åŒï¼‰
  mlPolicy:
    numNodes: 1
    torch:
      numProcPerNode: auto

  # PodGroup ç­–ç•¥é…ç½®ï¼ˆå¯é€‰ï¼‰
  podGroupPolicy:
    # Volcano gang-scheduler é…ç½®ç¤ºä¾‹
    volcano:
      # ç½‘ç»œæ‹“æ‰‘é…ç½®ï¼Œç”¨äºç½‘ç»œæ„ŸçŸ¥è°ƒåº¦
      networkTopology:
        # ç½‘ç»œæ‹“æ‰‘é”®ï¼Œç”¨äºæ ‡è¯†ç½‘ç»œåŸŸ
        # ä¾‹å¦‚ï¼štopology.kubernetes.io/zone
        topologyKey: topology.kubernetes.io/zone
        # ç½‘ç»œç­–ç•¥ï¼Œå®šä¹‰ Pod åº”è¯¥å¦‚ä½•åˆ†å¸ƒ
        # å¯é€‰å€¼ï¼šBest-effortï¼ˆå°½åŠ›è€Œä¸ºï¼‰ã€Strictï¼ˆä¸¥æ ¼æ¨¡å¼ï¼‰
        # Best-effortï¼šå°½é‡å°† Pod è°ƒåº¦åˆ°åŒä¸€ç½‘ç»œåŸŸï¼Œä½†ä¸å¼ºåˆ¶
        # Strictï¼šå¿…é¡»å°†æ‰€æœ‰ Pod è°ƒåº¦åˆ°åŒä¸€ç½‘ç»œåŸŸï¼Œå¦åˆ™è°ƒåº¦å¤±è´¥
        networkPolicy: Best-effort

  # JobSet æ¨¡æ¿é…ç½®
  template:
    metadata:
      labels:
        runtime-type: cluster-wide
        framework: pytorch
    
    spec:
      # å¤åˆ¶çš„ Job åˆ—è¡¨
      replicatedJobs:
        - name: node
          replicas: 1
          template:
            metadata:
              labels:
                # æ ‡è¯†è¿™æ˜¯è®­ç»ƒå™¨æ­¥éª¤
                trainer.kubeflow.org/trainjob-ancestor-step: trainer
            spec:
              # Job çš„ Pod æ¨¡æ¿
              template:
                spec:
                  containers:
                    - name: node
                      # é»˜è®¤ PyTorch é•œåƒ
                      image: pytorch/pytorch:2.7.1-cuda12.8-cudnn9-runtime
                      # torchrun å‘½ä»¤é…ç½®
                      command:
                        - torchrun
                      args:
                        - --nnodes=$(TRAINER_NNODES)
                        - --nproc_per_node=$(TRAINER_NPROC_PER_NODE)
                        - --node_rank=$(JOB_COMPLETION_INDEX)
                        - --rdzv_backend=c10d
                        - --rdzv_endpoint=$(TRAINER_NODE_0_HOSTNAME):29400
                        - --rdzv_id=$(TRAINER_JOB_ID)
                      # ç¯å¢ƒå˜é‡
                      env:
                        - name: LOGLEVEL
                          value: INFO
                        - name: PYTHONUNBUFFERED
                          value: "1"
                        - name: NCCL_DEBUG
                          value: INFO
                        - name: TORCH_DISTRIBUTED_DEBUG
                          value: INFO
                      # èµ„æºè¯·æ±‚å’Œé™åˆ¶
                      resources:
                        requests:
                          cpu: "4"
                          memory: 16Gi
                        limits:
                          cpu: "8"
                          memory: 32Gi
                  
                  # é‡å¯ç­–ç•¥
                  restartPolicy: OnFailure
      
      # å¤±è´¥ç­–ç•¥
      failurePolicy:
        maxRestarts: 3
      
      # æˆåŠŸç­–ç•¥
      successPolicy:
        operator: All
        targetReplicatedJobs:
          - node
      
      # ç½‘ç»œé…ç½®
      network:
        publishNotReadyAddresses: true
        enableDNSHostnames: true
```

### 4.2 é›†ç¾¤çº§æ•°æ®åˆå§‹åŒ–è¿è¡Œæ—¶ç¤ºä¾‹

```yaml
apiVersion: trainer.kubeflow.org/v1alpha1
kind: ClusterTrainingRuntime
metadata:
  name: torch-distributed-with-initializer
  labels:
    trainer.kubeflow.org/framework: torch
spec:
  mlPolicy:
    numNodes: 1
    torch:
      numProcPerNode: auto

  template:
    spec:
      replicatedJobs:
        # æ•°æ®é›†åˆå§‹åŒ– Job
        - name: dataset-initializer
          replicas: 1
          template:
            metadata:
              labels:
                trainer.kubeflow.org/trainjob-ancestor-step: dataset-initializer
            spec:
              template:
                spec:
                  containers:
                    - name: dataset-initializer
                      # æ•°æ®é›†åˆå§‹åŒ–é•œåƒ
                      image: ghcr.io/kubeflow/trainer/storage-initializer
                      # ç¯å¢ƒå˜é‡ä¼šè¢« TrainJob.initializer.dataset.env åˆå¹¶
                      env:
                        - name: STORAGE_TYPE
                          value: s3
                      # å·æŒ‚è½½
                      volumeMounts:
                        - name: dataset
                          mountPath: /mnt/dataset
                  
                  # å·å®šä¹‰
                  volumes:
                    - name: dataset
                      emptyDir: {}
                  
                  restartPolicy: OnFailure
        
        # æ¨¡å‹åˆå§‹åŒ– Job
        - name: model-initializer
          replicas: 1
          template:
            metadata:
              labels:
                trainer.kubeflow.org/trainjob-ancestor-step: model-initializer
            spec:
              template:
                spec:
                  containers:
                    - name: model-initializer
                      image: ghcr.io/kubeflow/trainer/storage-initializer
                      env:
                        - name: STORAGE_TYPE
                          value: s3
                      volumeMounts:
                        - name: pretrained-model
                          mountPath: /mnt/model
                  
                  volumes:
                    - name: pretrained-model
                      emptyDir: {}
                  
                  restartPolicy: OnFailure
        
        # è®­ç»ƒèŠ‚ç‚¹ Job
        - name: node
          replicas: 1
          template:
            metadata:
              labels:
                trainer.kubeflow.org/trainjob-ancestor-step: trainer
            spec:
              template:
                spec:
                  containers:
                    - name: node
                      image: pytorch/pytorch:2.7.1-cuda12.8-cudnn9-runtime
                      command:
                        - torchrun
                      args:
                        - --nnodes=$(TRAINER_NNODES)
                        - --nproc_per_node=$(TRAINER_NPROC_PER_NODE)
                        - --node_rank=$(JOB_COMPLETION_INDEX)
                        - --rdzv_backend=c10d
                        - --rdzv_endpoint=$(TRAINER_NODE_0_HOSTNAME):29400
                        - --rdzv_id=$(TRAINER_JOB_ID)
                        - /workspace/train.py
                      # æŒ‚è½½åˆå§‹åŒ–çš„æ•°æ®é›†å’Œæ¨¡å‹
                      volumeMounts:
                        - name: dataset
                          mountPath: /mnt/dataset
                        - name: pretrained-model
                          mountPath: /mnt/model
                  
                  volumes:
                    - name: dataset
                      emptyDir: {}
                    - name: pretrained-model
                      emptyDir: {}
                  
                  restartPolicy: OnFailure
      
      # æˆåŠŸç­–ç•¥ï¼šåªè¦è®­ç»ƒèŠ‚ç‚¹æˆåŠŸå³å¯
      successPolicy:
        operator: All
        targetReplicatedJobs:
          - node
      
      network:
        publishNotReadyAddresses: true
```

### 4.3 TrainingRuntime vs ClusterTrainingRuntime

ä¸¤ç§è¿è¡Œæ—¶çš„å¯¹æ¯”ï¼š

| ç‰¹æ€§ | TrainingRuntime | ClusterTrainingRuntime |
|------|----------------|------------------------|
| ä½œç”¨åŸŸ | å‘½åç©ºé—´çº§åˆ« | é›†ç¾¤çº§åˆ« |
| å¯è§æ€§ | åªèƒ½è¢«åŒä¸€å‘½åç©ºé—´çš„`TrainJob`å¼•ç”¨ | å¯ä»¥è¢«ä»»ä½•å‘½åç©ºé—´çš„`TrainJob`å¼•ç”¨ |
| ä½¿ç”¨åœºæ™¯ | å›¢é˜Ÿæˆ–é¡¹ç›®ç‰¹å®šçš„è¿è¡Œæ—¶é…ç½® | è·¨å›¢é˜Ÿå…±äº«çš„æ ‡å‡†è¿è¡Œæ—¶é…ç½® |
| æƒé™è¦æ±‚ | å‘½åç©ºé—´çº§åˆ«çš„æƒé™ | é›†ç¾¤çº§åˆ«çš„æƒé™ |
| é…ç½®æ ¼å¼ | å®Œå…¨ç›¸åŒ | å®Œå…¨ç›¸åŒ |

## 5. ç¯å¢ƒå˜é‡æ³¨å…¥

`Kubeflow Trainer`ä¼šæ ¹æ®ä½¿ç”¨çš„è®­ç»ƒæ¡†æ¶ï¼Œä¸ºè®­ç»ƒå®¹å™¨è‡ªåŠ¨æ³¨å…¥ç›¸åº”çš„ç¯å¢ƒå˜é‡ã€‚ä¸åŒæ¡†æ¶ä½¿ç”¨çš„ç¯å¢ƒå˜é‡ä¸åŒã€‚

### 5.1 PyTorchæ¡†æ¶ç¯å¢ƒå˜é‡

ä½¿ç”¨`PyTorch`ï¼ˆé€šè¿‡`torchrun`å¯åŠ¨ï¼‰æ—¶ï¼Œ`Torch Plugin`ä¼šè‡ªåŠ¨æ³¨å…¥ä»¥ä¸‹ç¯å¢ƒå˜é‡ï¼š

#### 5.1.1 PET_*ç³»åˆ—ï¼ˆPyTorch Elastic Trainingï¼‰

è¿™äº›æ˜¯`torchrun`ä½¿ç”¨çš„æ ‡å‡†ç¯å¢ƒå˜é‡ï¼Œç”±`Kubeflow Trainer`è‡ªåŠ¨æ³¨å…¥ï¼š

| ç¯å¢ƒå˜é‡ | è¯´æ˜ | ç¤ºä¾‹å€¼ | æ³¨å…¥æ¥æº |
|----------|------|--------|----------|
| `PET_NNODES` | è®­ç»ƒèŠ‚ç‚¹æ€»æ•° | `2` | `spec.trainer.numNodes` |
| `PET_NPROC_PER_NODE` | æ¯èŠ‚ç‚¹è¿›ç¨‹æ•° | `4` | `spec.mlPolicy.torch.numProcPerNode` |
| `PET_NODE_RANK` | å½“å‰èŠ‚ç‚¹ç¼–å· | `0-1` | `JOB_COMPLETION_INDEX` |
| `PET_MASTER_ADDR` | ä¸»èŠ‚ç‚¹åœ°å€ | `myjob-node-0-0.myjob` | `{trainjob-name}-node-0-0.{trainjob-name}` |
| `PET_MASTER_PORT` | ä¸»èŠ‚ç‚¹ç«¯å£ | `29400` | å›ºå®šå€¼ |

**è¯´æ˜**ï¼š
- `PET`ä»£è¡¨`PyTorch Elastic Training`ï¼Œæ˜¯`torchrun`çš„æ ‡å‡†ç¯å¢ƒå˜é‡å‰ç¼€
- è¿™äº›å˜é‡åœ¨`TrainingRuntime`çš„`command`ä¸­ä½¿ç”¨ï¼Œå¦‚ï¼š`torchrun --nproc_per_node=$(PET_NPROC_PER_NODE) ...`
- `PET_NODE_RANK`é€šè¿‡`Kubernetes`çš„`fieldRef`æœºåˆ¶è‡ªåŠ¨ä»`JOB_COMPLETION_INDEX`è·å–

#### 5.1.2 æ ‡å‡†åˆ†å¸ƒå¼è®­ç»ƒç¯å¢ƒå˜é‡

`torchrun`ä¼šæ ¹æ®`PET_*`å˜é‡ï¼Œä¸ºæ¯ä¸ªè¿›ç¨‹è®¾ç½®ä»¥ä¸‹æ ‡å‡†ç¯å¢ƒå˜é‡ï¼š

| ç¯å¢ƒå˜é‡ | è¯´æ˜ | è®¡ç®—æ–¹å¼ | ç¤ºä¾‹å€¼ |
|----------|------|----------|--------|
| `WORLD_SIZE` | æ€»è¿›ç¨‹æ•° | `PET_NNODES Ã— PET_NPROC_PER_NODE` | `8` |
| `RANK` | å…¨å±€è¿›ç¨‹ç¼–å· | è‡ªåŠ¨è®¡ç®— | `0-7` |
| `LOCAL_RANK` | æœ¬åœ°è¿›ç¨‹ç¼–å· | èŠ‚ç‚¹å†…è¿›ç¨‹ç´¢å¼• | `0-3` |
| `MASTER_ADDR` | ä¸»èŠ‚ç‚¹åœ°å€ | ç»§æ‰¿`PET_MASTER_ADDR` | `myjob-node-0-0.myjob` |
| `MASTER_PORT` | ä¸»èŠ‚ç‚¹ç«¯å£ | ç»§æ‰¿`PET_MASTER_PORT` | `29400` |

**è¯´æ˜**ï¼š
- è¿™äº›å˜é‡ç”±`torchrun`è‡ªåŠ¨è®¾ç½®ï¼Œæ— éœ€åœ¨`TrainingRuntime`ä¸­é…ç½®
- è®­ç»ƒä»£ç ä¸­å¯ç›´æ¥ä½¿ç”¨`torch.distributed.get_rank()`ç­‰`API`ï¼Œæˆ–é€šè¿‡`os.environ`è®¿é—®

### 5.2 OpenMPIæ¡†æ¶ç¯å¢ƒå˜é‡

ä½¿ç”¨`OpenMPI`ï¼ˆå¦‚`DeepSpeed`ï¼‰æ—¶ï¼Œä¼šæ³¨å…¥ä»¥ä¸‹ç¯å¢ƒå˜é‡ï¼š

| ç¯å¢ƒå˜é‡ | è¯´æ˜ | ç¤ºä¾‹å€¼ |
|----------|------|--------|
| `OMPI_MCA_orte_default_hostfile` | ä¸»æœºåˆ—è¡¨æ–‡ä»¶è·¯å¾„ | `/etc/mpi/hostfile` |
| `OMPI_MCA_plm_rsh_agent` | SSHä»£ç†ï¼ˆç¦ç”¨ï¼‰ | `/usr/bin/false` |
| `OMPI_MCA_orte_keep_fqdn_hostnames` | ä¿æŒå®Œæ•´ä¸»æœºå | `true` |

**è¯´æ˜**ï¼š
- è¿™äº›å˜é‡ç”¨äºé…ç½®`OpenMPI`è¿è¡Œæ—¶è¡Œä¸º
- é€šå¸¸ç”±`ClusterTrainingRuntime`çš„å®¹å™¨æ¨¡æ¿é…ç½®

### 5.3 é€šç”¨ç¯å¢ƒå˜é‡

æ‰€æœ‰æ¡†æ¶éƒ½å¯ä»¥ä½¿ç”¨ä»¥ä¸‹`Kubernetes`åŸç”Ÿç¯å¢ƒå˜é‡ï¼š

| ç¯å¢ƒå˜é‡ | è¯´æ˜ | ç¤ºä¾‹å€¼ |
|----------|------|--------|
| `JOB_COMPLETION_INDEX` | èŠ‚ç‚¹ç´¢å¼•ï¼ˆ`0`å¼€å§‹ï¼‰ | `0-1` |

**è¯´æ˜**ï¼š
- æ­¤å˜é‡æ¥è‡ª`Kubernetes Job`çš„ç´¢å¼•æœºåˆ¶ï¼Œè¡¨ç¤ºå½“å‰`Pod`åœ¨`Job`ä¸­çš„åºå·
- å¯ç”¨äºè·å–èŠ‚ç‚¹ç¼–å·æˆ–é…ç½®èŠ‚ç‚¹ç‰¹å®šè¡Œä¸º

### 5.4 ä½¿ç”¨ç¤ºä¾‹

#### 5.4.1 PyTorchè®­ç»ƒè„šæœ¬ç¤ºä¾‹

```python
import os
import torch.distributed as dist

# åˆå§‹åŒ–åˆ†å¸ƒå¼è¿›ç¨‹ç»„ï¼ˆtorchrunä¼šè‡ªåŠ¨è®¾ç½®æ‰€éœ€ç¯å¢ƒå˜é‡ï¼‰
dist.init_process_group(backend="nccl")

# è·å–åˆ†å¸ƒå¼ä¿¡æ¯
rank = dist.get_rank()           # ç­‰ä»·äº int(os.environ['RANK'])
world_size = dist.get_world_size()  # ç­‰ä»·äº int(os.environ['WORLD_SIZE'])
local_rank = int(os.environ['LOCAL_RANK'])
node_rank = int(os.environ.get('JOB_COMPLETION_INDEX', 0))

print(f"Node Rank: {node_rank}")
print(f"Global Rank: {rank}, World Size: {world_size}")
print(f"Local Rank: {local_rank}")
```

#### 5.4.2 TrainingRuntime commandé…ç½®ç¤ºä¾‹

```yaml
command:
  - torchrun
  - --nproc_per_node=$(PET_NPROC_PER_NODE) 
  - --nnodes=$(PET_NNODES)
  - --node_rank=$(PET_NODE_RANK)
  - --master_addr=$(PET_MASTER_ADDR)
  - --master_port=$(PET_MASTER_PORT)
  - /workspace/train.py
```

## 6. æœ€ä½³å®è·µ

1. **èµ„æºé…ç½®**
    - ä¸ºè®­ç»ƒä»»åŠ¡è®¾ç½®åˆç†çš„èµ„æºè¯·æ±‚ï¼ˆ`requests`ï¼‰å’Œé™åˆ¶ï¼ˆ`limits`ï¼‰
    - `GPU`èµ„æºé€šå¸¸è®¾ç½®ç›¸åŒçš„`requests`å’Œ`limits`
    - ä¸ºéœ€è¦å¤§é‡å†…å­˜çš„æ“ä½œï¼ˆå¦‚æ•°æ®åŠ è½½ï¼‰é¢„ç•™è¶³å¤Ÿçš„å†…å­˜

2. **å­˜å‚¨é…ç½®**
    - ä½¿ç”¨`PVC`æˆ–å¯¹è±¡å­˜å‚¨ï¼ˆ`S3`ã€`GCS`ï¼‰æ¥æŒä¹…åŒ–æ•°æ®é›†å’Œæ¨¡å‹
    - å¯¹äºéœ€è¦é«˜`I/O`æ€§èƒ½çš„åœºæ™¯ï¼Œè€ƒè™‘ä½¿ç”¨`hostPath`æˆ–`local volume`
    - ä½¿ç”¨`emptyDir`ï¼ˆ`medium: Memory`ï¼‰ä½œä¸ºå…±äº«å†…å­˜ï¼Œé¿å…`/dev/shm`ä¸è¶³

3. **ç½‘ç»œé…ç½®**
    - å¯ç”¨`publishNotReadyAddresses: true`ç¡®ä¿åˆ†å¸ƒå¼è®­ç»ƒçš„ç½‘ç»œè¿é€šæ€§
    - å¯¹äºå¤§è§„æ¨¡åˆ†å¸ƒå¼è®­ç»ƒï¼Œè€ƒè™‘ä½¿ç”¨é«˜é€Ÿç½‘ç»œï¼ˆå¦‚`InfiniBand`ï¼‰
    - é…ç½®é€‚å½“çš„ç½‘ç»œæ’ä»¶å’Œ`CNI`

4. **è°ƒåº¦ç­–ç•¥**
    - ä½¿ç”¨`gang-scheduling`ï¼ˆ`coscheduling`æˆ–`Volcano`ï¼‰ç¡®ä¿æ‰€æœ‰è®­ç»ƒèŠ‚ç‚¹åŒæ—¶å¯åŠ¨
    - ä½¿ç”¨èŠ‚ç‚¹äº²å’Œæ€§å’Œåäº²å’Œæ€§æ§åˆ¶`Pod`åˆ†å¸ƒ
    - å¯¹äº`GPU`è®­ç»ƒï¼Œä½¿ç”¨èŠ‚ç‚¹é€‰æ‹©å™¨ç¡®ä¿`Pod`è°ƒåº¦åˆ°`GPU`èŠ‚ç‚¹

5. **å®¹é”™é…ç½®**
    - è®¾ç½®åˆç†çš„`maxRestarts`å€¼ï¼Œé¿å…æ— é™é‡è¯•
    - ä½¿ç”¨`checkpoint`æœºåˆ¶å®šæœŸä¿å­˜è®­ç»ƒçŠ¶æ€
    - é…ç½®å¥åº·æ£€æŸ¥ï¼ˆ`readinessProbe`ã€`livenessProbe`ï¼‰

6. **è¿è¡Œæ—¶é€‰æ‹©**
    - ä½¿ç”¨`ClusterTrainingRuntime`å®šä¹‰ç»„ç»‡çº§åˆ«çš„æ ‡å‡†è¿è¡Œæ—¶
    - ä½¿ç”¨`TrainingRuntime`ä¸ºç‰¹å®šå›¢é˜Ÿæˆ–é¡¹ç›®å®šåˆ¶è¿è¡Œæ—¶
    - ä¿æŒè¿è¡Œæ—¶é…ç½®çš„ç‰ˆæœ¬åŒ–ç®¡ç†

## 7. å‚è€ƒèµ„æ–™

- [Kubeflow Trainer å®˜æ–¹æ–‡æ¡£](https://www.kubeflow.org/docs/components/trainer/)
- [Kubeflow Trainer GitHub ä»“åº“](https://github.com/kubeflow/trainer)
- [PyTorch Distributed æ–‡æ¡£](https://pytorch.org/tutorials/intermediate/ddp_tutorial.html)
- [Volcano ç½‘ç»œæ‹“æ‰‘è°ƒåº¦](https://volcano.sh/zh/docs/network_topology_aware_scheduling/)
- [Kubernetes JobSet](https://github.com/kubernetes-sigs/jobset)
