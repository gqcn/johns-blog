---
slug: "/ai/basic-terminology"
title: "AI领域常见基础术语梳理"
hide_title: true
keywords:
  [
    "AI术语",
    "机器学习术语",
    "深度学习术语",
    "大语言模型",
    "LLM",
    "神经网络",
    "模型训练",
    "模型微调",
    "Fine-tuning",
    "LoRA",
    "RLHF",
    "RAG检索增强生成",
    "损失函数",
    "梯度下降",
    "反向传播",
    "过拟合欠拟合",
    "监督学习",
    "强化学习",
    "模型评估",
    "数据并行",
    "模型并行",
    "张量并行",
    "流水线并行",
    "知识蒸馏",
    "模型压缩",
    "量化剪枝",
    "GPU加速",
    "PyTorch",
    "TensorFlow",
    "AI基础概念",
    "人工智能词汇",
    "AI入门教程",
  ]
description: "系统梳理AI核心术语，涵盖基础概念(大语言模型/多模态/RAG/思维链)、机器学习(监督/无监督/强化学习)、训练微调(梯度下降/反向传播/LoRA/RLHF/并行计算策略)、模型评估(准确率/精确率/召回率)、硬件工具(GPU/TPU/CUDA)五大模块。每个术语配有中英对照、原理解释和生动类比，通俗易懂，助力AI新人快速入门，建立完整知识体系。"
---


> 不定期更新完善。


## 基础概念

### 大语言模型
大语言模型(`Large Language Model, LLM`)：参数量巨大(数十亿到数万亿)的语言模型，通过在海量文本数据上训练，掌握语言的深层规律和广泛知识。能理解和生成自然语言，完成问答、写作、翻译、代码生成等多种任务。代表模型有`GPT`系列、`Claude`、`Llama`等。就像博览群书的学者，阅读了互联网上的大量文本后具备了广泛的知识和语言能力。参数越多模型越强大，但训练和运行成本也越高。

### 基础模型
基础模型(`Foundation Model`)：在大规模、多样化数据上预训练的通用模型，可以作为基础适配到各种下游任务。不针对特定任务，而是学习通用的表示和能力，然后通过微调或提示工程应用到具体场景。大语言模型就是基础模型的典型代表。就像通识教育打好基础，然后可以选择不同专业方向深造。一个基础模型可以派生出无数应用。

### 多模态模型
多模态模型(`Multimodal Model`)：能同时处理和理解多种类型数据(文本、图像、音频、视频等)的模型，打破单一模态的限制。可以根据图片回答问题、根据文本生成图片、理解视频内容等。代表模型有`GPT-4V`、`Claude 3`、`Gemini`等。就像人类用眼睛看、耳朵听、嘴巴说综合理解世界，多模态模型模拟这种综合感知能力，比单一处理文字更强大。

### 思维链
思维链(`Chain of Thought, CoT`)：引导大模型逐步推理的提示技术，让模型"展示思考过程"。在提示中加入"让我们一步步思考"或提供推理示例，模型会先输出中间推理步骤，再给出最终答案。能显著提高数学、逻辑等复杂问题的准确率，因为分步骤降低了出错概率，也让推理过程可解释。就像考试要求写解题步骤，一步步推导比直接写答案更不容易错。

### 检索增强生成
检索增强生成(`Retrieval-Augmented Generation, RAG`)：结合信息检索和文本生成的技术，先从知识库检索相关信息，再基于检索结果生成回答。弥补大模型知识更新滞后、容易产生幻觉的问题，用实时准确的外部信息增强生成质量。就像开卷考试，可以查资料再作答，答案更准确可靠。广泛应用于企业问答系统、文档助手等场景。


### 提示调优
提示调优(`Prompt Tuning`)：不改变模型参数，只优化输入提示词的方法。通过精心设计提示内容、格式、示例来引导模型输出期望结果。相比微调，提示调优无需训练，成本极低，灵活性高，但效果可能不如微调稳定。就像问问题的方式不同得到的答案质量不同，找到最佳问法就是提示调优。提示工程(Prompt Engineering)是相关的实践技能。


### 幻觉
幻觉(`Hallucination`)：大模型生成看似流畅合理但实际错误或编造的内容，是当前的主要局限。模型基于统计规律生成文本，可能"一本正经地胡说八道"，编造不存在的事实、引用、数据等。就像侃侃而谈但实际信口开河的人。应对方法包括检索增强(`RAG`)、增加引用、多模型验证、用户提醒等。使用大模型时需要批判性验证其输出。

### 温度
温度(`Temperature`)：控制生成文本随机性的参数，影响输出的创造性和确定性。温度值通常在`0`到`2`之间，默认`1`。温度高(如`1.5-2`)输出更随机、多样、有创意，但可能不连贯；温度低(如`0.1-0.5`)输出更确定、保守、一致，但可能枯燥。温度0接近贪婪搜索，总选概率最高的词。就像做菜的火候，大火爆炒(高温度)有锅气但容易糊，小火慢炖(低温度)稳定但可能寡淡。






## 机器学习

### 机器学习
机器学习(`Machine Learning, ML`)：让计算机从数据中自动学习规律和模式的技术，无需显式编程告诉它每一步该怎么做。传统编程是人写规则让计算机执行，而机器学习是让计算机自己从数据中总结规律。就像教小孩认水果，不用告诉他"红色圆形带梗的是苹果"，只要给他看够多的苹果样例，他自己就能总结出苹果的特征。

### 监督学习
监督学习(`Supervised Learning`)：机器学习的方式之一，从已标注好的数据中学习的方法，每条数据都有明确的"答案"(标签)。模型通过学习大量"问题-答案"对，掌握从输入到输出的映射关系。就像学生做习题，每道题都有标准答案供对照学习。典型应用包括图片分类(给照片标注类别)、垃圾邮件识别(标注邮件是否垃圾)、房价预测(给出历史成交数据)。

### 无监督学习
无监督学习(`Unsupervised Learning`)：机器学习的方式之一，从未标注的数据中自动发现隐藏的模式和结构，数据没有预定义的"正确答案"。模型要自己摸索数据的内在规律和分组方式。就像让你整理一堆照片，没人告诉你分类标准，你可能按人物、地点或时间自己归类。常见任务包括客户分群、异常检测、数据降维等。

### 半监督学习
半监督学习(`Semi-supervised Learning`)：机器学习的方式之一，结合少量标注数据和大量未标注数据进行学习的方法，介于监督学习和无监督学习之间。现实中标注数据成本高昂(需要人工逐个标注)，而未标注数据容易获取。半监督学习用少量标注数据指明方向，再利用大量未标注数据提升模型性能。就像老师批改了几份作业示范，然后让学生参考着互相学习。

### 强化学习
强化学习(`Reinforcement Learning, RL`)：机器学习的方式之一，通过与环境不断交互、试错来学习最优决策策略的方法。智能体(Agent)在环境中采取行动，根据获得的奖励或惩罚反馈来调整策略。就像训练宠物或玩游戏升级，做对了给奖励(加分)，做错了给惩罚(扣血)，反复尝试找到得分最高的玩法。`AlphaGo`下围棋、机器人学走路都用到强化学习。



## 训练微调

### 微调
微调(`Fine-tuning`)：在预训练大模型基础上，用特定任务的数据继续训练，让模型适应具体场景。预训练提供通用能力，微调定制专业能力。比如用医疗对话数据微调通用模型，让它成为医疗助手。微调所需数据量远小于从头训练，成本更低效果更好。就像大学毕业生(预训练)到公司后针对性培训(微调)成为专业人才。

### 张量
张量(`Tensor`)：多维数组，是深度学习框架中的基本数据结构，用于表示和存储数据。标量是`0`维张量(一个数)，向量是`1`维张量(一串数)，矩阵是`2`维张量，更高维的统称张量。神经网络的输入、输出、权重都用张量表示，计算本质是张量运算。`PyTorch`、`TensorFlow`等框架的核心就是张量及其运算。就像乐高积木是基本单元，张量是搭建AI模型的基础组件。

### TensorFlow

`Google`开发的开源深度学习框架，提供完整的端到端机器学习平台。功能强大，支持从研究到生产部署的全流程，有丰富的工具生态(`TensorBoard`可视化、`TF Serving`部署等)。但学习曲线较陡，API复杂度高。适合大规模工业应用和生产环境。就像工业级全套装备，功能齐全但上手需要时间。

### PyTorch

`Facebook(Meta)`开发的深度学习框架，以灵活易用著称，是当前学术研究界最流行的框架。采用动态计算图，调试方便，代码简洁直观，接近原生`Python`风格。社区活跃，论文复现多用`PyTorch`。适合快速原型开发和研究实验。就像轻便的瑞士军刀，灵活好用易上手。


### 损失函数
损失函数(`Loss Function`)：衡量模型预测值与真实值差距的函数，训练目标是最小化损失。就像考试的扣分标准，告诉模型哪里做得不好、扣了多少分。不同任务用不同损失函数：分类常用交叉熵损失，回归常用均方误差。损失函数的选择直接影响模型学到什么。训练过程就是不断调整参数让损失函数的值越来越小。



### 梯度
梯度(`Gradient`)：指示每个参数应该如何调整的信号，是损失函数相对于参数的变化率（导数）。梯度告诉模型两件事：调整方向（增大还是减小参数）和调整幅度（变化快慢）。就像猜数字游戏，我心中目标数字是`10`，猜`7`时告诉你"往大了猜"（方向），并且"差得还挺远"（幅度），下次就该往更大的方向猜。梯度大说明参数对损失影响大，需要大步调整；梯度小说明接近最优，小步微调即可。

### 梯度下降
梯度下降(`Gradient Descent`)：一种优化算法，通过计算梯度(斜率)来调整参数，让损失函数逐步减小。梯度指向函数上升最快的方向，沿着负梯度方向走就能下降。就像蒙眼下山，摸索脚下的坡度，朝最陡的方向往下走，最终到达山谷最低点。有多种变体:批量梯度下降(用全部数据)、随机梯度下降(`SGD`，每次一个样本)、小批量梯度下降(`Mini-batch`，折中方案)。

### 反向传播
反向传播(`Backpropagation`)：神经网络的核心训练算法，从输出层反向逐层计算每个参数的梯度，用于更新参数。前向传播计算输出和损失，反向传播利用链式法则将误差从后往前传，算出每个权重对损失的影响(梯度)，然后用梯度下降更新权重。就像考试后分析错题，从最终错误倒推，找出每个步骤的问题。这是让深度网络可训练的关键技术。

### 过拟合
过拟合(`Overfitting`)：模型在训练数据上表现很好，但在新数据上表现差的现象。模型记住了训练数据的细节和噪声，而没有学到泛化的规律，导致泛化能力弱。就像学生死记硬背标准答案，考原题满分，题目稍有变化就不会做了。解决方法包括：增加数据、正则化、简化模型、`Dropout`、提前停止训练等。

### 欠拟合
欠拟合(`Underfitting`)：模型太简单，连训练数据都学不好的现象。模型复杂度不足以捕捉数据中的模式，预测误差大。就像用小学知识应对高考题，压根没学懂知识点。训练集和测试集上表现都很差。解决方法:增加模型复杂度、增加训练轮次、减少正则化、添加更多特征等。

### 超参数
超参数(`Hyperparameter`)：训练前需要人工设定的参数，控制模型结构和学习过程，如学习率、批量大小、网络层数、神经元数量等。与训练过程中自动学习的模型参数(权重、偏置)不同，超参数不通过梯度下降更新。超参数的设置显著影响模型性能，需要通过实验或自动化方法寻找最优值。就像做菜前定好火候和时间，不是边做边调的。

### 超参数调优
超参数调优(`Hyperparameter Tuning`)：寻找最优超参数组合的过程，也叫超参数搜索。常用方法有:网格搜索(穷举组合，计算量大但全面)、随机搜索(随机采样，效率更高)、贝叶斯优化(根据历史结果智能选择下一组参数)、自动化工具(如Optuna、Ray Tune)等。就像调试配方找最佳比例，需要反复实验。

### 参数高效微调
参数高效微调(`Parameter-Efficient Fine-Tuning, PEFT`)：只更新少量参数实现微调的方法，而非更新全部参数。大幅降低计算和存储成本，同时保持接近全量微调的效果。常见方法有`LoRA`、`Adapter`、`Prefix Tuning`等。比如在百亿参数模型上只训练几百万参数就能适配新任务。就像装修房子不全部重建，只改局部就达到新效果，省时省力。

### LoRA
`LoRA(Low-Rank Adaptation)`：一种参数高效微调技术，通过在模型权重旁边添加低秩矩阵来适配新任务。只训练这些小矩阵(占原参数1%左右)，冻结原模型权重。训练快、显存占用小，可以为不同任务训练多个LoRA切换使用。就像给西装配不同领带，不用买多套西装，换领带就能适配不同场合。是当前最流行的高效微调方法。

### 指令微调
指令微调(`Instruction Tuning`)：用"指令-响应"格式的数据微调模型，让它更好地理解和遵循人类指令。训练数据包含各种任务指令和对应的理想输出。指令微调后的模型更易用，能准确理解用户意图，按要求完成任务。GPT系列、Claude等模型都经过大量指令微调。就像培训客服人员理解各种客户需求，按规范服务。

### RLHF
`RLHF(Reinforcement Learning from Human Feedback)`：用人类反馈的强化学习训练模型，让输出更符合人类偏好和价值观。收集人工对模型输出的排序或评分，训练奖励模型，再用强化学习优化生成策略。能让模型输出更有帮助、更安全、更符合人类期望。`ChatGPT`的成功很大程度归功于`RLHF`。就像通过用户评价持续改进产品，让AI更懂人心。

### Top-k采样
`Top-k`采样(`Top-k Sampling`)：生成每个词时只从概率最高的k个候选词中采样，过滤掉低概率词。平衡输出质量和多样性，k值越大越多样但可能出现低质量词，`k`值越小越保守。常见`k`值为`40-100`。就像选秀节目只在前k名选手中投票，保证基本水准。相比贪婪搜索(只选最高概率)更灵活，相比完全随机采样更可控。

### Top-p采样
`Top-p`采样(`Nucleus Sampling`)：也叫核采样，从累计概率达到p的最小候选词集合中采样。动态确定候选集大小，概率分布陡峭时集合小(确定性高)，平缓时集合大(多样性高)。比`Top-k`更灵活自适应。p通常设为0.9-0.95。就像按实力动态划分候选人范围，而不是固定名额。Top-p和温度常配合使用，是现代文本生成的标准配置。

### 模型压缩
模型压缩(`Model Compression`)：减小模型大小和计算量的技术集合，让大模型能在资源受限设备上运行。主要方法包括剪枝(删除冗余参数)、量化(降低精度)、知识蒸馏(训练小模型模仿大模型)、低秩分解等。压缩后模型体积更小、推理更快、耗电更少，但可能略微损失性能。就像压缩文件或精简装备，在保持核心功能的同时减轻负担。

### 剪枝
剪枝(`Pruning`)：删除神经网络中不重要的参数、连接或神经元，减小模型规模。通过分析参数重要性(如权重大小、梯度等)，移除贡献小的部分，再重新训练恢复性能。可以减少50%-90%参数，速度提升明显，精度略降。就像修剪树枝，去掉冗余枝叶，树木更健壮高效。结构化剪枝(整个通道或层)比非结构化剪枝(零散参数)更利于加速。

### 量化
量化(`Quantization`)：降低模型参数的数值精度，从32位浮点数(FP32)降到16位(FP16)、8位整数(INT8)甚至更低。减少内存占用(可达4-8倍)和计算量，加快推理速度。量化感知训练(训练时模拟量化)效果更好，训练后量化(直接转换)更简单。就像照片从高清压缩成标清，文件小很多，视觉效果差别不大。是部署大模型到移动设备的关键技术。

### 知识蒸馏
知识蒸馏(`Knowledge Distillation`)：用大模型(教师)的知识训练小模型(学生)，让小模型获得接近大模型的能力。学生模型学习教师的输出分布(软标签)而非原始标签(硬标签)，包含更丰富信息。蒸馏后的小模型运行更快、成本更低，适合部署。就像名师指导徒弟，传授经验技巧，徒弟虽然水平不及师傅但远超自学。是获得高效模型的重要途径。

### 模型集成
模型集成(`Model Ensemble`)：组合多个模型的预测结果，综合它们的优势以获得更好的性能。可以投票(分类)、平均(回归)或加权组合。不同模型犯的错误往往不同，集成可以互补，通常比单个模型更准确稳定，但推理成本成倍增加。就像专家会诊或评委打分，集体决策比个人更可靠。竞赛中常用，生产中权衡成本和收益。

### 数据并行
数据并行(`Data Parallelism`)：将训练数据分成多份，在多个`GPU`上同时训练相同模型的副本，每个`GPU`处理不同批次数据。训练完一个批次后，各`GPU`计算的梯度汇总求平均，然后同步更新所有副本的参数。最常用的并行策略，实现简单效果好。就像工厂多条流水线同时生产相同产品，最后统一质检改进工艺。适合模型能放进单个GPU、但数据量大训练慢的场景。

### 模型并行
模型并行(`Model Parallelism`)：将单个大模型拆分到多个`GPU`上，每个`GPU`只存储和计算模型的一部分。当模型太大单个`GPU`放不下时必须使用。分为层间并行(不同层放不同`GPU`)和层内并行(单层切分到多`GPU`)。就像建大楼，一层楼太大一个工地放不下，要分多个区域分别施工，但各区域要协调配合。实现复杂，通信开销大，但能训练超大模型。

### 流水线并行
流水线并行(`Pipeline Parallelism`)：模型并行的优化版，将模型按层切分成多个阶段(`stage`)放到不同`GPU`，像流水线一样依次处理不同批次数据。当第一个`GPU`处理完第一批数据传给第二个`GPU`后，不是等待而是立即处理第二批数据，让所有`GPU`尽可能同时工作。就像工厂流水线，切菜、炒菜、装盘同时进行，提高效率。减少了`GPU`空闲时间，提升了模型并行的资源利用率。

### 张量并行
张量并行(`Tensor Parallelism`)：在单个算子(层)内部进行并行，将矩阵运算切分到多个`GPU`协同计算。比如一个大矩阵乘法，把矩阵按行或按列切分，多个`GPU`各算一部分再合并结果。粒度更细，通信更频繁但能充分利用多`GPU`算力。就像搬大柜子，一个人搬不动，多人一起抬，每人出一份力。常与流水线并行组合使用，是训练超大模型(如`GPT-3`、`GPT-4`)的关键技术。


## 模型评估

### 训练集
训练集(`Training Set`)：用于训练模型、调整模型参数的数据集，模型通过学习这部分数据掌握规律。占数据集的主要部分(通常`60%-80%`)。模型会反复"看"训练集数据，不断优化参数以减小预测误差。就像学生的练习题集，用来学习知识和方法。训练集的质量和数量直接影响模型学习效果。

### 验证集
验证集(`Validation Set`)：用于调整超参数和模型选择的数据集，不参与模型训练但指导训练过程。训练时定期在验证集上评估性能，用于决定何时停止训练(防止过拟合)、对比不同模型、调整超参数。占数据集`10%-20%`。就像学生的模拟考试，用来检验学习效果和调整复习策略，但不是最终考核。

### 测试集
测试集(`Test Set`)：用于最终评估模型性能的数据集，模型从未见过，也不用于任何训练决策。只在模型完全训练好后使用一次，模拟真实应用场景。占数据集`10%-20%`。就像正式考试，是对学习成果的最终评判。测试集性能代表模型在未知数据上的真实表现，是向外界报告的指标。

### 准确率
准确率(`Accuracy`)：预测正确的样本数占总样本数的比例，最直观的评估指标。公式：`准确率 = 正确预测数 / 总样本数`。适用于类别平衡的数据。但在类别不平衡时会误导，比如`100`个样本中`99`个负例`1`个正例，模型全预测为负也有`99%`准确率，实际没学到任何东西。此时需要看精确率、召回率等指标。

### 精确率
精确率(`Precision`)：在所有预测为正例的样本中，真正是正例的比例。公式：`精确率 = 真正例(TP) / (真正例(TP) + 假正例(FP))`。衡量"查准率"或"准确性"，关注预测的可靠性。高精确率意味着误报少。比如垃圾邮件过滤，精确率高说明标记为垃圾的邮件确实是垃圾，正常邮件不会被误杀。

### 召回率
召回率(`Recall`)：在所有真实正例中，被正确预测为正例的比例。公式：`召回率 = 真正例(TP) / (真正例(TP) + 假负例(FN))`。衡量"查全率"或"覆盖率"，关注是否把正例都找出来。高召回率意味着漏报少。比如疾病诊断，召回率高说明患病的人都被检测出来了，不会漏诊。精确率和召回率通常此消彼长，需要权衡。



## 硬件工具

### GPU
`GPU(Graphics Processing Unit)`：图形处理器，原本为图形渲染设计，但其强大的并行计算能力使其成为训练深度学习模型的主力硬件。包含数千个计算核心，擅长同时处理大量简单计算，非常适合神经网络的矩阵运算。`NVIDIA`的`GPU`(如`RTX`、`A100`、`H100`系列)占据AI训练市场主导地位。就像工厂流水线，虽然每个工人(核心)能力有限，但数千人同时工作效率惊人。没有`GPU`，深度学习不可能有今天的发展。

### TPU
`TPU(Tensor Processing Unit)`：`Google`专门为深度学习设计开发的AI专用芯片，针对张量运算深度优化。比通用`GPU`更高效，功耗更低，专为`TensorFlow`等框架优化。`Google`内部大量使用，也通过云服务对外提供。就像专业工具比瑞士军刀在特定任务上更高效，`TPU`在AI训练和推理上比`GPU`更专精。代表了AI硬件专用化的趋势。

### CUDA
`CUDA(Compute Unified Device Architecture)`：`NVIDIA`开发的并行计算平台和编程模型，让开发者能用`GPU`加速通用计算任务。提供`C/C++`扩展和丰富的库(`cuDNN`、`cuBLAS`等)，深度学习框架底层大多依赖`CUDA`。掌握了`GPU`市场的事实标准，但只支持`NVIDIA GPU`。就像`iOS`和`iPhone`的关系，`CUDA`把`NVIDIA GPU`的硬件能力开放给软件开发者，是深度学习生态的关键基础设施。
